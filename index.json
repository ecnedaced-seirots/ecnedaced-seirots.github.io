[{"content":" たまたま以下の記事を拾った。\nAI駆動開発とは？次世代の主流となる最新開発スタイルをわかりやすく解説\nAI駆動開発（AI-Driven Development/AIDD）に関する詳細説明である。親切にいろいろ書いてくれているのだが\u0026hellip;、仕事中にふらっとたどり着いて、「一応読んどこ」と軽く読み始めたら、長いのなんのって。さわりだけでやめておいて、業務後にゆっくり読もうとしたが、それでも記事が長すぎて途中下車した。\nこの記事自体AIが書いたのか、またはAIが生成したのを人間が校正したのか、または人間が一から書いたのかわからんが、いずれにせよ、長すぎる記事はWebページとして適切でないこと、その根拠としてWeb UI上の文章を人間が読む時に集中可能な時間の基準がある、だから脱落しないように基準内に収めるべき、ということを予測または判断できなかったのだろうか、とか思ってしまうんだな。（そういう自分も過去に長すぎる記事かいてますが、すみません）\n\u0026hellip;.と、そんなことを考えていると、AI駆動開発はパラダイスというよりパラドックスに足を踏み入れてしまっている未来を予測してしまうんだが、記事の続きは明日読みますよ。\nまぁなんにせよ、人間は退屈には耐えられない存在だから、パラダイスに行けたとしても永住はしないだろうね。（AI駆動開発 -＞ 新たな課題 -＞ 新たなソリューション\u0026hellip;のループ）\n","permalink":"https://ecnedaced-seirots.github.io/post/e/aidd/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eたまたま以下の記事を拾った。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.i3design.jp/in-pocket/15348\"\u003eAI駆動開発とは？次世代の主流となる最新開発スタイルをわかりやすく解説\u003c/a\u003e\u003c/p\u003e","title":"AI駆動開発はエンジニアをパラダイスに導いてくれるのか"},{"content":"AWSでリージョン別に利用可能なサービスを調べたい時は、以下ページを見ればよい。\nリージョン別に利用可能な AWS サービスのリスト\nただし、上記ページは利用可能サービスの検索が可能だがサービス内の個別の機能まではカバーしていないため、別途調査が必要。といってもシンプルに、特定の機能リリースがあったタイミングで発表される公式ページに「すべてのリージョンでご利用いただけます」みたいな文言があったりする。（リージョン別に利用可能なEC2インスタンスを検索するTips記事が結構あるけど、今時踏み台以外にEC2使う要件ってほぼないしなぁ）\nあとサービス内の特有の機能について、その機能自体はどのリージョンでも使えるが、APIによる構築はできないケースもあった。つまり、マネコンから手動構築やCLIなら設定可能だが、CFn(CloudFormation)では設定できなかったのだ。ここまでマニアックなケースだとほぼ公開情報入手不可能で、実際やってみてエラーにぶちあたる ＆ サポートに聞いてNGと判明するしかないという。\n※本当は他にも書いておきたい技術ネタがいくつかあるんだけど、時間なくてこんなネタしか書けん\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/e/aws-region-specific-service/","summary":"\u003cp\u003eAWSでリージョン別に利用可能なサービスを調べたい時は、以下ページを見ればよい。\u003c/p\u003e","title":"AWSでリージョン別に利用可能なサービスを調べる"},{"content":" システムエンジニアによるフラワーエッセンスPoC（Proof of Concept）記録。前回から1ヶ月ほど経過してしまったが\u0026hellip;、前回記事で書いたオーストラリアンブッシュ Cognis（現：Focus）を、親の認知症対策に有効かどうかを検証してみた件について書く。\n前回記事\nオーストラリアンブッシュ Cognis（現：Focus）で脳活動底上げを図ってみる\n実際試してみたのは今年5月の3週間くらい。認知・記憶力に何かと懸念がある自分の親父に飲んでもらった。10年くらい前からサプリはいろいろとってもらってて、当時は若干改善したものの、ここ数年はサプリでは解決不能な状態だった。一応、ギリギリ日常生活はできているが、ここで歯止めかけないとまずいな、というような。\nちなみに病院連れて行くつもりはない。薬を飲むことが有効な解決方法とは考えられないし、そもそも現代西洋医学の認知症診断自体を、俺は信頼していない。\nで、エネルギー的に深い働きかけの作用を持つフラワーエッセンスに望みを託し、いつも親父が使っている水筒にCognis（現：Focus）を混ぜて飲んでもらったのだ。\n結論から言うと、記憶力にはさほど改善は見られなかったが、何よりも、親父の「ソウル」が変化した。これはすごいと思った。どういうことかと言うと、本来の本人の魂を取り戻したという作用があった。別にそれまで、魂の抜け殻みたいにボーッとしていたわけじゃないよ。でも明らかに意欲が減退して、喜びを感じることも少なくなっている印象だった。\nそれが、エッセンスを開始してから、笑うことが増えたし、「以前の親父」に戻った印象が強くなった。俺の親父の「以前の親父」がどんなやつかなんて俺にしか説明できないが、説明しても伝わらないだろうからパス。（どっちにしても上手く説明できない）しかしとにかく、「そういえば、親父がこんな風に笑うのを見たのは久しぶりだな。でも以前はこれは普通だったよな」と感銘を受けたのだ。\nここで俺は重要なことに気づいた。今まで親の認知症予防・対策として、脳の機能にばかりフォーカスしていたが、そうじゃないんだと。そっちも重要だけど、本人の「ソウル（魂）」にもフォーカスしてやらないとダメなんだと。本人が、自らのソウルとともに生きること。それが最重要なのだと。\nちなみにCognis（現：Focus）は以下エッセンスのコンビネーションとなっている。\nBush Fuchsia（ブッシュフューシャ） Isopogon（アイソポゴン） Jacaranda（ジャカランダ） Paw Paw（ポーポー） Sundew（サンデュー） 俺の想像では、「ソウル」に作用したのは上記のうちPaw Paw（ポーポー）の力が大きいのではないかと思う。このエッセンスには「ハイヤーセルフに働きかける」作用がある、という指標があるからだ。「ハイヤーセルフ」って表現はスピ界隈でよく聞くものであまりこの場には書きたくないのだが\u0026hellip;、現実的な言葉で言うなら「自分自身の奥底にあるソウル」と解釈しておけばいいと思う。テキトーに言ってますけど。\n話戻って、現代社会では認知症関係なく、若い世代でも肉体とソウルが乖離している人は大勢いると思うよ。俺自身もそんな時期があったし、気をつけていないと再発しちまう、という自覚はある。そう言う時は、ただ生きているだけの「オートマシン」なんだ。知力や認知機能に問題がなくても、オートマシンじゃ意味がない。\nまずはソウルを取り戻せ。本人がソウルをしっかり保持できていれば、認知力や記憶力なんて多少衰えてもいい。日常生活に支障をきたさない範囲で、少しでも改善できれば、その程度でOKだよ。（俺的目標）\nそして思った。常日頃、自分自身にも「俺は今、本当に自分のソウルとともに生きているのだろうか？」と問いかける必要があるな、と。\n\u0026hellip;と、ここまでが今回の大雑把な検証結果である。\nCognisはもっと継続したかったが、希釈不可で一回7適だからなくなるのが早くてね\u0026hellip;（500mlの水筒には15〜20適ほど入れていた）、最初のボトルが終わった時点で次の検証に移った。しかし、国内で普通に購入するとそこそこ高価ではあるが、個人輸入でお得に仕入れることができると知ったから、後ほどオーストラリア直送で仕入れましたよ。他に検証したいのがあるから、そっちが落ち着いたらまた再開しようと思う。\n作用には当然個人差があるし、認知症の程度や周囲の環境も人それぞれだから、「絶対効果あるよ！」などとは言えない。しかし、老親の認知症対策に取り組んでいる人にとって、フラワーエッセンスはひとつの選択肢になりえるだろう、とは言っておきたい。\n最後に、以下リンクのブログは、認知症チャレンジとしてフラワーエッセンス（アロマ等その他のリソースも併用）を使用した経緯を書いたもの。これは素晴らしい記録である。10年ほど前の記事だが、このブログを消さずに残してくれているのは本当ににありがたい。同じ立場にいる人にはぜひ一読を勧める。\nご機嫌な脳ミソ\n","permalink":"https://ecnedaced-seirots.github.io/post/e/australian-bush-cognis-focus-2/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eシステムエンジニアによるフラワーエッセンスPoC（Proof of Concept）記録。前回から1ヶ月ほど経過してしまったが\u0026hellip;、前回記事で書いたオーストラリアンブッシュ Cognis（現：Focus）を、親の認知症対策に有効かどうかを検証してみた件について書く。\u003c/p\u003e","title":"オーストラリアンブッシュ Cognis（現：Focus）で認知症予防をPoCしてみた"},{"content":" システムエンジニアによるフラワーエッセンスPoC（Proof of Concept）記録、第一弾はオーストラリアンブッシュフラワーエッセンスのCognis。\nCognis（認知）である。このストレートなネーミングセンスに痺れる。タイトルの通り、全く発展著しくない俺様の脳活動上げ底\u0026hellip;じゃなくて底上げを期待して購入した。\nちなみに現在の名称はFocus（集中）となっている。購入したのがちょうど狭間の時期だった模様。国内販売分は、まだCognisが現存している。Focusは個人輸入で購入する時「あ、変わったんだ」と知った。Focusでもいいけど、語感的にはCognisの方が好きだなぁ\u0026hellip;。まぁでも、Cognis（認知）よりFocus（集中）の方が製品の役割を的確に表しているということなんだろう。\nCognis（認知） Focus（集中） 前置きはさておきといいつつ軽くオーストラリアンブッシュの説明。一言で言うと、わかりやすくて強力。オーストラリアといえば厳しい自然環境の中で独自の進化を遂げてきた動物が知られているが、植物もまた同様なわけで。その独自の環境で育ったユニークな植物からつくられたエッセンスもまた強力なパワーを保持していることは、想像に難くない。（初心者のくせに知ったか説明してます）\nなかでも「ドロップス」と呼ばれるコンビネーションエッセンスはおすすめである。コンビネーションエッセンスは特定の目的に沿って複数のエッセンスをブレンドしたものだが、ブッシュのは特に、繰り返すが「わかりやすく」「強力」だからだ。\nわかりやすいと言うのは、その目的であったり効果の出方であったり、なんだが。魂の気づきだのインナーチャイルドだの、そういう世界にはまったく「お呼びでない」俺様でも、「お、これよさげ。使ってみたい！」とそそられるラインナップが揃っているのだ。カラーバリエーションで揃えたラベルのデザインもシンプルでかっこいい。（ちなみに黄色は「知性」を表す色）\n現状の世の中、男子とフラワーエッセンスはほぼ結びつかないと思われるが、こんなボトルだったらメンズの部屋に置いてあってもまったく違和感がない。ダークトーンのインテリアの本棚やデスクの片隅にさりげなく置いてあったら、「違和感ない」を通り越して「ちょっと特別感あるセンス」を醸し出したてくれそうだ。独身男子だったら、招いた女子の注目を引くかもしれない\u0026hellip;て、俺の狭くてゴチャゴチャな部屋に置いたところでセンスもへったくれもないけどね。\nくだらない能書はこれくらいにして、本題。実際Cognis（現：Focus）エッセンスをとってみてどうだったか。自分の場合取り始めて数日で、以下の変化を感じた。（言うまでもなく個人的な感想で、結果には個人差があります）\n・メンタルがニュートラルになる。\n・情報をスムーズに取り入れて、処理することができる。\n・思考が自然に整理される。\nメンタルがニュートラルというのは「感情の安定」に近いが、それだけではなく、思考、感情、直感、あらゆる精神的な活動全般をニュートラルに近づけてくれる、という印象を持った。\nところでこのエッセンスに対して頭脳活動の底上げを期待しているんだから、実験するなら実際に思い切り頭脳を使うタイミングで使うのが一番である。一応自分はSEである。だったらプログラム書く時に試すのがベストだろう、と一瞬は思った。がしかし、最近仕事はコーディングから離れているし、プライベートでも、まったく書く気がしない。頭脳活動底上げの前に、そもそも頭を使う意欲がないという、このグダグダなやる気のなさ加減をどうにかすべきかもしれない。\nとはいえ、プログラムは書かないし、大したことはやってないが、一応仕事で少しは頭を使うことも、あるっちゃあるんで。仕事中でCognisをとっている期間は、いつもより思考がスムーズで、内部で情報が自然にうまく処理されているような、あるいはそれをサポートしてもらえているような実感があった。仕事以外でプライベートでも、たとえば旅行に出かけた時に想定外の事象に出くわしても、メンタルが乱れることなく、ストレスもあまり感じることなく、次のプランをサッと思いついてスムーズに行動できる、という印象があった。かつそのネクストプランの選択も、選んで正解！という感じだったから快適に旅の時間を過ごすことができた。\nそんな感じで自分の場合ガチな頭脳活動はしていなかったが、そんな中でもそれなりにパワフルな効果を実感できた。以下の要件に向いている製品だと思う。\n・資格取得を目指して勉強中\n・試験を受ける予定がある\n・効率よく学習したい\n・集中力を高めたい\n・思考のノイズやモヤモヤをスッキリさせたい\n価格はフラワーエッセンス取り扱いサイトで4,490円。1人なら1ヶ月くらいで使い切るか。継続的に購入するには躊躇する価格だが、ブッシュは効き目が早いのと、目的からして長期継続ではなくオンデマンド的に使ってもいい。もし気に入って使用継続したければ、個人輸入すれば大分割安になる。（これについては別途書く予定）ちなみにこの製品はAmazonでも購入可能。Amazonならポイント使えば少しは安くなるし、サクッと買えるのはありがたいね。\n最後にエッセンスのとり方は、ブッシュの場合はスポイト7適を1日2回、直接舌下に垂らす、または水や飲み物に入れて飲む。よく「水やハーブティーに入れてお飲みください」とか書かれているが、世の中には「ハーブティー」という単語やそこから連想される世界観に忌避感を抱く人間もいる。俺みたいに。ハーブティーには何の恨みもないが、俺はそういうのを飲む習慣などないから、いつもの飲み物に入れるだけだ。コーヒー、ジュース、ビール、何ならカップラーメンにでもガンガン入れてまっせ！！\nま、別にカップラーメンにまで入れなくてもいいけど。フラワーエッセンスなんてメンズはもちろん女子でも馴染みがない人が多いと思うが、変に構えずに、フツーに日常に取り入れてみればいいんだよ、と言いたいわけだ。（後で思い出したが炭酸飲料に混ぜるのは何かの理由でNGだった。効果は薄れるだろうが特に害はない）\nそんなクールでナイスなCognis(Focus)エッセンス、これはほぼ初期認知症フェーズな自分の親にとってもらってもいいんじゃないか？と思ったのでそれもPoCしてみた。（続く）\n","permalink":"https://ecnedaced-seirots.github.io/post/e/australian-bush-cognis-focus/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eシステムエンジニアによるフラワーエッセンスPoC（Proof of Concept）記録、第一弾はオーストラリアンブッシュフラワーエッセンスのCognis。\u003c/p\u003e\n\u003cp\u003eCognis（認知）である。このストレートなネーミングセンスに痺れる。タイトルの通り、全く発展著しくない俺様の脳活動上げ底\u0026hellip;じゃなくて底上げを期待して購入した。\u003c/p\u003e","title":"オーストラリアンブッシュ Cognis（現：Focus）で脳活動底上げを図ってみる"},{"content":"唐突だが「フラワーエッセンス」である。そしてPoCと言えば\u0026hellip;、しばらく前に職場で、若手A(ほぼド新人）との会話。システム開発におけるフェーズについて軽く説明していた。\n俺：「要件定義の次に設計に入るけど、その前にPoC（ポック）というのをやる場合があるよ」\n若手A: 「は？」（ポカン）\n俺：「PoC（ピーオーシー）。英語で\u0026quot;Proof of Concept\u0026quot;なんだけど、略してPcC（ポック）て言うことが多いね」\n若手A: 「は？」（ポカン）\n俺：「えーと、\u0026ldquo;Proof\u0026quot;は『実証』、\u0026ldquo;Concept\u0026quot;は、『コンセプト』。」\n若手A: 「は？」（ポカン）\nProof of Concept,略してPoC。アプリケーション/システム開発で、ある機能を実現したい要件があるとして、これこれこういう方式でやればできるだろうというアイディアがあったとする。しかし、頭の中ではできてもリアルな世界で本当に実現できるのか、実用に耐えうるかの確証がない。確証を得るために（実証する）、そのアイディアを用いた「コンセプト」が問題なく実現できるかどうか、手を動かして検証することを示す。\nおそらく若手Aには、「実証」と「コンセプト」が全く結びつかなかったのだろう（それぞれの単語の意味を理解していなかった可能性もあり）。\nIT業界以外の人とか業界でも新人なら知らなくて当然だからいいのだが、この時の俺には丁寧に説明する時間も心の余裕もなかったので、「あとは自分で調べといて」で締めた。若手Aとの会話のやり取りを、スローモーションのように感じていたのだ。数ヶ月後、若手Aは遁走した。いいんだけど、頼むから転職先は別の業界にしてくれよな、と思った。\n前置きが長くなったが、フラワーエッセンスのPoC（実証検証）。\n「フラワーエッセンス」なるものがある。花の周波数を水に転写したものだ。これを用いた「フラワーエッセンス療法」というものがあり、おもに感情的・精神的な課題に効果があると言われる。で、「xxxxな課題に、このエッセンスが効果がありそうだけど実際どうなのか？」をPoCした記録、を書こうとしているわけである。\nなぜ書くかというと、情報があまりに少ないからだ。「実際どーなのよ？」て情報集めたいけど、非常に情報が少ない、かつ、ヒットしたとしてもあまりに「ゆるふわ」または「エモーショナル」な内容が多いもんで\u0026hellip;\nまぁ、こう言っちゃなんだけど、「フラワーエッセンス」なんていかにも「女子向け」なイメージだし、実際利用者も女子がほとんど。自分自身、そういうものがあるのは知っていたけど、印象だけとらえて「俺には関係ねぇ」ものだと思っていた。\n「お花の波動が詰まったエッセンスが〜、潜在意識に〜\u0026hellip;、魂の気づきが〜\u0026hellip;」とか言われても、いかにも「ゆるふわ」、軟弱っぽいイメージじゃないすか。記事書いてる人がいかにも「お花畑」だったりするし。こんなこと言うと、本物の花畑に失礼だけどね。あと深掘りしていくと実は「フラワー」以外のエッセンスも多々あったりするのだが、「エッセンス」って単語だけとっても、語感がフェミニンな印象だしね。\nそんな風にイメージだけでとらえていた自分に誤りがあったのは認めるが、世の中の社会人メンズが積極的にこの療法に関心を持つことはまずないだろうと想像する。それは、「フラワーエッセンス」という単語の語感の問題もあるが、流通している情報が、基本ほぼ女子による、女子向けの内容に偏っているせいもあると俺は思った（マーケットとしてもその範囲だけで閉じてしまってる感あり）。あとスピリチュアル調強めな記事が多いのも、スピに関心がない、または忌避感を抱く一般人を遠ざけているよな〜、と思ったり。\nある情報を的確に伝えるためには、言葉を選ぶ必要がある。ゆるふわ記事や女子向けの情報が悪い、適切ではないと言うことでなく、他のアプローチがあっていいじゃないかと思うのだ。実際自分はふとしたきっかけでフラワーエッセンスを使ってみて、「これは面白い」と思った。だから、一部のスピ愛好家やゆるふわ女子だけに流通し、それ以外の大多数が知らない、または知っていても避けているのは、非常にもったいないと思う。\n\u0026hellip;つーのが、フラワーエッセンスPoC記録をちょっくら書いてみようと思った経緯っすね⭐︎\n「システムエンジニアによる」ってのは、まぁ「釣り」ってわけじゃないけど、一応自分はSEの端くれだから、論理的整合性を最重要とする世界に浸ってるんで。日常生活でもリアリスティック、ロジカル \u0026amp; サイエンティフィックな視点を重要視してるわけですよ。エンジニアだから、というより元々そういう性格。スピな世界を否定はしないが、スピも現実のひとつとして認知する立場なんで。ちょっとその辺りを主張したかった。\n要するにフラワーエッセンス使ってみた記録を、スピ的視点は脇において、「フツーに現実的な視点で役に立ちそうな内容」を基準として書いてみようと。ま、役に立つかどうかはわからないが、メンズはもちろん、レディースでも、スピに興味ない人とか、リアリスト、合理主義者、科学的視点を重要視する人も関心を持ってくれたらいいと思いつつ。（続く）\n","permalink":"https://ecnedaced-seirots.github.io/post/e/essence-poc/","summary":"\u003cp\u003e唐突だが「フラワーエッセンス」である。そしてPoCと言えば\u0026hellip;、しばらく前に職場で、若手A(ほぼド新人）との会話。システム開発におけるフェーズについて軽く説明していた。\u003c/p\u003e","title":"システムエンジニアによるフラワーエッセンスPoC記録（序章）"},{"content":"「引き寄せの法則」（ポジティブ・シンキングを兼ねる）の限界を示す分かりやすい説明。\nポジティブ面だけを見るのはどう考えても無理がある ポジティブな側面だけを見る、ネガティブな側面を見て見ぬふりする作戦がなぜ徒労に終わるかと言えば、ネガティブな面を無視し続ければいずれ器が満杯になり崩壊するからです。これも有名な話ですがコップの水の話、コップに水が少なくなった状態をまだこれだけあると言い聞かす、ゼロじゃないことにフォーカスするというのがポジティブシンキングだとすれば登山で死んでしまいます。水が少ないと判断し水を補充しなければ登山者は皆死にます。少ししか水がないと焦るから水をさらに補充するのであってただポジティブに捉えるという考え方は無理があるため崩壊します。この崩壊した時が引き寄せの法則の限界点です。\n引き寄せの法則の本当の意味（算命学的解釈）\nこの説明は非常に現実的で、自分にとっては納得感がある。\nこれに似た概念として「思考の現実化」というのがある。「思考したことは必ず現実化する（できる）」、あなたの目の前にある現実はすべてあなたの思考が作り出したものである」という捉え方だ。個人的には6割程度は納得できる。しかし全面的には受け入れない。これも「引き寄せの法則」と同様に限界があると思うからだ。限界の理由も上記とほぼ同様である。\n「そのようにしてあなたは自ら制限を作り出しているのです」とか言ってきそうだが無視。俺はリアリストなのだ。そもそも、この手の発言をする輩が、俺の人生に責任とってくれるわけじゃないし。\nさて、「思考の現実化」をスピリチュアル的に延長し、すべてを「魂の学び」とする考え方がある。\n「あなたが経験しているすべての現実は、あなたの魂が選択しているのです」「すべては魂の学びのためなのです」的なやつ。スピ系のサイトでよく目にする。これをさらに延長して「あなたか生まれてきた家系（自分を産んだ両親も）はあなたの魂が選んだのです」というのも目にすることがある。\nこれについては、控えめに言って、「うぜーな、知ったこっちゃねぇよ！」という感想だ。\n「あなたに起こったことは、すべては魂の学びなのです」と宣う人物は、例えば子供を通り魔に殺された親に、同じことを言えるのだろうか？\nまたは凄惨な児童虐待を受けている子供、またはそのような過去を持つ人に「あなたの親はあなたの魂が選んだのです」と言えるのだろうか？\n「3次元の思考から離れてください。魂の世界ではそうなのです」なんつう返答が返ってくるかもしれない。非常に控えめに言って、「バーロー、クソ喰らえ！！」ってとこだ。\n魂の世界がどうのじゃなくてな、こちとら地球上で3次元の肉体を持って生きてる存在なんだ。地球上では3次元ルールが最優先。（アセンションがどーたら、という話もここでは無視）どちらが真実かってことじゃなくて、「ヒトとして、そりゃーあり得ねぇよ」となった時点が、限界点なのである。\n","permalink":"https://ecnedaced-seirots.github.io/post/e/limits-of-spiritual-idea/","summary":"\u003cp\u003e「引き寄せの法則」（ポジティブ・シンキングを兼ねる）の限界を示す分かりやすい説明。\u003c/p\u003e","title":"「引き寄せの法則」「思考の現実化」および「魂の学び」の限界点"},{"content":" タイトルのまんま。Lambdaの実行時間を、CloudWatch Logs Insightsで集計したい。\nで、以下記事参考にさせてもらった。おぉぉ、これは便利！！\nCloudWatch LogsInsightsでLambdaの速度を計測してみよう\n対象のロググループと時間帯をセット後、以下のクエリにより95パーセンタイル、中央値、平均値、最小値、最大値を集計できる。\nfilter @type = \u0026#34;REPORT\u0026#34; | stats count(*) as `count`, pct(@duration, 95) as pct95, pct(@duration, 50) as pct50, avg(@duration) as avgtime, min(@duration) as mintime, max@duration) as maxtime 上記記事からの引用だが、デフォルトで以下のフィールドが用意されている。ということは\u0026hellip;\n@ingestionTime @logStream @message @requestId @timestamp @type @billedDuration @duration @initDuration @maxMemoryUsed @memorySize メモリ使用値を集計するなら、これでいけるってことか。\nfilter @type = \u0026#34;REPORT\u0026#34; | stats count(*) as `count`, avg(@maxMemoryUsed) as avgmem, min(@maxMemoryUsed) as minmem, max(@maxMemoryUsed) as maxmem 無関係だけど時事ネタなど。「JA民営化」要注意キーワードね。\n【時事問題】米価高騰の犯人は？ 仕組まれた価格操作の可能性？ 農林中金が狙われている？\n","permalink":"https://ecnedaced-seirots.github.io/post/e/logsinsights-lambda-duration/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eタイトルのまんま。Lambdaの実行時間を、CloudWatch Logs Insightsで集計したい。\u003c/p\u003e","title":"Lambdaの実行時間をCloudWatch Logs Insightsで集計"},{"content":"約10ヶ月ぶりの投稿。ずっと放置してたけど、改めて自分の過去記事見ると何か新鮮だなぁ〜⭐︎\nさてゴッドクリーナーが何かというのはあまり時間をとれないため省略するが、このタイトルに少しでもピンと来た人なら説明不要だろう。\n本題だけズバリ言うと、以下の記事がすべてを語っている。これを見つけた時、「すげぇ、俺の言いたいこと完全に言語化してくれている！」と感動した。\n高校レベルの化学とゴッドクリーナー\nゴッドクリーナーなるものを耳にしたのは、2022年春頃。旧Twitterのある界隈で何人か利用者がいたからだ。ゴッドクリーナーが何なのか知らなかったし調べる気もしなかったが、「今日はめちゃくちゃシェディングくらったのに全然色が変わらなかったなー」といったつぶやきを何度か目にしており、どうでもいいものだと思った。そしてその通りだった。\n自分を「覚醒者です！」「気づいています！」と自負していいる人間が、ゴッドクリーナーを信望していたりする。そしてあっち側について「なんで気づかないのかな〜」とぼやくのだが、ゴッドクリーナーの嘘に気づけよ、と思う。ただのいかさまだよ。\n","permalink":"https://ecnedaced-seirots.github.io/post/e/cheat-of-god-cleaner/","summary":"\u003cp\u003e約10ヶ月ぶりの投稿。ずっと放置してたけど、改めて自分の過去記事見ると何か新鮮だなぁ〜⭐︎\u003c/p\u003e\n\u003cp\u003eさてゴッドクリーナーが何かというのはあまり時間をとれないため省略するが、このタイトルに少しでもピンと来た人なら説明不要だろう。\u003c/p\u003e","title":"ゴッドクリーナーの嘘にいいかげん気づいて欲しい"},{"content":"AWS EventBridgeのルールからターゲットを呼び出す時は常にIAMロールもセットにするもんだと思っていたら、違っていた。TerraformでEventBridgeのルール + ターゲットを作成しようとしてターゲットのパラメータとしてrole_arnを指定したところ、以下のエラーで失敗した。\nValidationException: RoleArn is not supported for target arn:aws:lambda:ap-northeast-1:[アカウントID]:function:lambda-hoge-func\nTerraformのドキュメントでもオプション扱いで、ロール指定が必要なサービスは以下の通りらしい。\nrole_arn (Optional) The Amazon Resource Name (ARN) of the IAM role to be used for this target when the rule is triggered. Required if ecs_target is used or target in arn is EC2 instance, Kinesis data stream or Step Functions state machine.\nResource: aws_cloudwatch_event_target\nちなみに上記には書かれていないが、CodePipelineのイベント検知として利用する場合もIAMロールが必要である。通常パイプライン作成時のオプションによって自動でルールが生成されるから、放置してると気が付かないかもしれない。（コンソールまたはAPIから個別にルールを作成することも可能である）\n冒頭の件はtfコードのパラメータからrole_arnを削除したら解消した。結論として、以下でも言及されているようにLambdaがターゲットの場合はLambda側でLambdaパーミッションがセットされていればよい。（設定したEventBridgeルールがLambdaを実行することを、Lambdaが許可する）\n参考\nAdding lambda target role to AWS Eventbridge rule in Cloudformation fails\n（これは2022年1月のネタなのだがすっかり忘れていて、2024年夏になってCFnで再び同じエラーに遭遇した）\n","permalink":"https://ecnedaced-seirots.github.io/post/d/aws-eventbridge-lambda-target/","summary":"\u003cp\u003eAWS EventBridgeのルールからターゲットを呼び出す時は常にIAMロールもセットにするもんだと思っていたら、違っていた。TerraformでEventBridgeのルール + ターゲットを作成しようとしてターゲットのパラメータとしてrole_arnを指定したところ、以下のエラーで失敗した。\u003c/p\u003e","title":"EventBridgeからLambdaを呼び出す時はIAM Roleの指定は不要"},{"content":" Gitでリモート追跡ブランチを削除。基本的なことだけど、改めて。\nGitでリモートブランチを削除しても、ローカルに「リモート追跡ブランチ」が残るケースがある。\ngit branch -aの結果で以下のように表示される。\nremotes/origin/ブランチ名 削除する方法。対象のブランチにcheckout（切り替え）後、以下実行\n$ git remote prune origin この後 git branch -aすると、「remotes/origin/ブランチ名」は消えているはずだ。\n対象のブランチのローカルブランチ自体も削除したい場合は、masterブランチ等にcheckoutしてから以下実行する。\n$ git branch -D [ブランチ名] ちなみに、リモートブランチ及びリモート追跡ブランチ両方が存在する状態で、ともに削除したい場合は以下コマンドを実行。\n$ git push --delete origin [ブランチ名] （2022年執筆記事の焼き直しです）\n","permalink":"https://ecnedaced-seirots.github.io/post/d/git-delete-remote-tracking-branch/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eGitでリモート追跡ブランチを削除。基本的なことだけど、改めて。\u003c/p\u003e","title":"Gitでリモート追跡ブランチを削除する"},{"content":" Gitで強制的にpullを実行したい時。とりあえず以下実行すればよいだろう。\n$ git fetch origin [ブランチ名] $ git reset --hard origin/[ブランチ名] やってることは、指定した対象ブランチの状態をfetchで実質ダウンロードして、それをcheckout中のブランチにセットするイメージ。これが実行された時点で、それまでのcheckout中ブランチの状態は消滅する。\ngit pull origin/[ブランチ名] して、何故か期待値と違う状況になることもあるから\u0026hellip;「細かい話はいいからとにかくpullできりゃいいんだよ！」てな時に。\nTipsその2。Gitで、意図せぬコミットをしてしまった場合。そもそも不要なリソースなら$ git rm [ファイル名]で削除すればよい。が、「git管理下には起きたくないが必要なリソース」の場合はどうするか。\n例えば本来なら.gitignoreに書いておくべきだが、それがない段階でやってしまうケースとか。絶対ありえる状況だけど、いざとなったら「あれ、どうするんだっけ」と詰まったのでメモ。\n以下により、対象リソースが「git管理外だがOS上には残る」状態にできる。\n$ git rm --cached [ファイル名] $ git rm --cached -r [ディレクトリ名] git add（追加）しただけの段階で気づいたら、以下実行。\n$ git reset [ファイル名] $ git reset /ディレクトリ名/ しかし一番最初に実行した追加を取り消すには、コミット取り消しと同様に git rm --cached を使う、とのこと。\ngit レポジトリを作成した直後、一番最初のに実行した git add を取り消したい場合、まだ HEAD の参照が存在しないため、上記の git reset を使った取消方法が利用できません。（これは、新規追加したファイルを初めての git add した場合も同様です。）レポジトリ内にリセット対象があってはじめてリセットできるのです。\nさて、そのような場合の git add の取り消しは、インデックスのファイルを直接削除するコマンド「git rm \u0026ndash;cached」を利用するしかありません。\ngit add の取り消し方法と、関連コマンドまとめ\n無事クリーンにした後は、.gitignoreへ書いておくのを忘れずに。\nこのテーマ、他にも追加・コミットの段階や戻したい状態により対応内容が異なってくる様子だが、追いすぎると際限なくなるので今回はこれだけにしておく。\n（2022年執筆記事の焼き直しです）\n","permalink":"https://ecnedaced-seirots.github.io/post/d/how-to-force-gt-pull/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eGitで強制的にpullを実行したい時。とりあえず以下実行すればよいだろう。\u003c/p\u003e","title":"Gitで強制的にpullを実行したい時と、commitを取り消したい時"},{"content":" masterブランチに別の作業ブランチの変更が取り込まれていて、それを現在の作業ブランチに取り込みたい時。\n以下コマンド実行。\n$ git checkout master $ git pull origin master $ git checkout [作業ブランチ] $ git merge master $ git push origin [作業ブランチ] 参考\nGit】作業ブランチに最新のmasterを反映させる方法\n合わせてこれも。mergeのタイミングで画面が切り替わってこんなメッセージが表示される場合がある。\nPlease enter a commit message to explain why this merge is necessary.\nこれはコミットメッセージ残せよ、と言ってるのはわかるけど入力しようにも画面が反応しないし、戸惑う人も多いと思う。簡潔に言うと、コミットメッセージ残さない場合は、「esc押下 + :q」で抜ける。コミットメッセージ残すならi押下でメッセージを入力。(vimと同じ)。\n環境によってはターミナルがGNU nanoエディタのケースもある。その場合は「Ctrl + X」で抜ける。\n参考\n【Git】マージする時に「Please enter a commit message to explain why this merge is necessary」と表示された時の対処法\n次に、他の作業ブランチの変更を取り込むケース。想定する場面としては、他の作業ブランチの変更がmasterにマージされていれば自分の作業ブランチでmasterをマージすればよいのだが、何らかの事情でそれができないタイミングでは他ブランチの変更を直接取り込むことになる。\n現在のブランチtest1に、test2ブランチの差分を取り込む例。（ブランチtest1にて実施）\ntest2ブランチをfetchする\n$ git fetch origin test2 差分を確認\n$ git diff test1 origin/test2 mergeで取り込む\n$ git merge origin/test2 先に書いたようにコミットメッセージ残しなさい、とvim画面が開いたら:qで抜ける。\n参考\n【Git】git mergeコマンドで異なるブランチの更新分を取り込む\n（元ネタは2023年執筆記事）\n","permalink":"https://ecnedaced-seirots.github.io/post/d/git-merge-branch/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003emasterブランチに別の作業ブランチの変更が取り込まれていて、それを現在の作業ブランチに取り込みたい時。\u003c/p\u003e","title":"Gitで現在の作業ブランチにmasterや他の作業ブランチの変更を取り込む"},{"content":" Pythonの時間の扱い、何度書いても忘れてしまう。そしてタイムゾーンの変換は、python3.9以降はzoneinfoが便利と最近知る。\n\u0026gt;\u0026gt;\u0026gt; from datetime import datetime \u0026gt;\u0026gt;\u0026gt; from zoneinfo import ZoneInfo # 現在時刻をTokyoのタイムゾーンとしてセットする \u0026gt;\u0026gt;\u0026gt; tz = ZoneInfo(\u0026#34;Asia/Tokyo\u0026#34;) \u0026gt;\u0026gt;\u0026gt; now = datetime.now(tz) \u0026gt;\u0026gt;\u0026gt; print(now) 2024-06-12 22:12:59.704388+09:00 # ミリ秒までいらない。replaceで切り捨てる。 \u0026gt;\u0026gt;\u0026gt; now2 = now.replace(microsecond = 0) \u0026gt;\u0026gt;\u0026gt; print(now2) 2024-06-12 22:12:59+09:00 # 日付/時間だけ取得する \u0026gt;\u0026gt;\u0026gt; day = now2.date() \u0026gt;\u0026gt;\u0026gt; print(day) 2024-06-12 \u0026gt;\u0026gt;\u0026gt; time = now2.time() \u0026gt;\u0026gt;\u0026gt; print(time) 22:12:59 時刻を任意のタイムゾーンに変換するにはastimezoneを利用できるが、元の値がnaiveかawareかで意味が変わってくるらしい。\nnaiveから：ローカルタイムとみなしてタイムゾーン変更します。 awareから：タイムゾーン変更します。 dt_jst = dt.astimezone(tz) ちなみにzoneinfoは、\nWindows環境では「tzdata」をpipで入れておかないとエラーになる。\nとのことだ。確かにWindowsでは動かなかった。\n参考\nLambda(Python3.9)でzoneinfoを使ってタイムゾーン設定するとかんたん\nPython 標準ライブラリ zoneinfo IANAタイムゾーン\npython datetimeの切り捨て\n[Python]datetimeから日付のみを取得するには？\n【Python datetime】naiveとawareの変換\n","permalink":"https://ecnedaced-seirots.github.io/post/d/python-datetime-timezone/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003ePythonの時間の扱い、何度書いても忘れてしまう。そしてタイムゾーンの変換は、python3.9以降はzoneinfoが便利と最近知る。\u003c/p\u003e","title":"Pythonのdatetime, zoneinfo周辺など"},{"content":" S3上のCSVファイルをRDS(PostgreSQL)にインポートするという「あるある」パターンのLambda。（Python3.9, エラー処理抜き）\nRDSのデータをS3にエクスポートする逆パターンについては以下記事参照。\nRDS(PostgreSQL)のデータをS3にエクスポートするLambda\nS3イベントがトリガーでLambdaが起動し、S3バケット内のCSVを一時領域にダウンロードしてRDSにインポートという流れ。DB認証情報はSecretManagerに格納して取得している。（認証取得は環境変数セットでもいけるけど昨今の流れ的にはSecret格納が優勢ということで）\n前提条件\nRDSに接続するため、Lambdaの配置はVPCとする。 PostgreSQL接続時に外部ライブラリのpsycopg2が必要となる。Lambdaのレイヤーに登録してからコード内で定義する。（今回詳細手順は割愛） import json import boto3 import psycopg2 # SecretManagerからRDS/DB認証情報取得 # secret_name は実際に作成したシークレットを指定 def getCredentials(): credential = {} secret_name = \u0026#34;secretname\u0026#34; region_name = \u0026#34;ap-northeast-1\u0026#34; client = boto3.client( service_name=\u0026#39;secretsmanager\u0026#39;, region_name=region_name ) get_secret_value_response = client.get_secret_value( SecretId=secret_name ) secret = json.loads(get_secret_value_response[\u0026#39;SecretString\u0026#39;]) credential[\u0026#39;username\u0026#39;] = secret[\u0026#39;username\u0026#39;] credential[\u0026#39;password\u0026#39;] = secret[\u0026#39;password\u0026#39;] credential[\u0026#39;host\u0026#39;] = \u0026#34;RDS endpoint URL\u0026#34; credential[\u0026#39;db\u0026#39;] = \u0026#34;databasename\u0026#34; return credential def lambda_handler(event, context): #イベント全体の定義 data = event s = json.dumps(data) e = json.loads(s) #イベントデータからS3部分抽出 record = e[\u0026#39;Records\u0026#39;] s3_event_record = (record[0][\u0026#39;s3\u0026#39;] #バケット名の定義 bucket = s3_event_record[\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] print(\u0026#39;bucket name:\u0026#39; + bucket) #オブジェクト名の定義（prefixを含む） key = s3_event_record[\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;] print(\u0026#39;prefix:\u0026#39; + key) #オブジェクトのファイル名のみ抽出（ダウンロード時に使用） path = key.split(\u0026#39;/\u0026#39;) file = path[-1] #区切り文字で区切った最後の文字列を取得 tmpfile = \u0026#39;/tmp\u0026#39; + file #バケット上のCSVを/tmp/ファイル名.csvとして一時領域にダウンロード s3 = boto3.resource(\u0026#39;s3\u0026#39;) s3.Bucket(bucket).download_file(key, tmpfile) # DB接続 credential = getCredentials() connection = psycopg2.connect(user=credential[\u0026#39;username\u0026#39;], password=credential[\u0026#39;password\u0026#39;], host=credential[\u0026#39;host\u0026#39;], database=credential[\u0026#39;db\u0026#39;]) cursor = connection.cursor() #ダウンロードしたCSVをDBにインポート。sepは区切り文字指定。 with open(tmpfile, \u0026#39;r\u0026#39;) as f: cursor.copy_from(f, \u0026#39;data_tbl\u0026#39;, sep=\u0026#39;,\u0026#39;) connection.commit() 参考\n・SecretManager経由の接続\nPostgreSQL with AWS Lambda using Python\n・インポート部分\ncopy data from csv to postgresql using python\n","permalink":"https://ecnedaced-seirots.github.io/post/d/s3-csv-import-to-rds-lambda/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eS3上のCSVファイルをRDS(PostgreSQL)にインポートするという「あるある」パターンのLambda。（Python3.9, エラー処理抜き）\u003c/p\u003e","title":"S3上のCSVをRDS(PostgreSQL)にインポートするLambda"},{"content":" RDSのデータをS3にエクスポートするLambdaという「あるある」パターン。DBはPostgreSQL、Python3.9、エラー処理抜き。\n前提条件\nRDSに接続するため、Lambdaの配置はVPCとする。\nPostgreSQL接続時に外部ライブラリのpsycopg2が必要となる。レイヤーに登録してから定義すればよいがちょっとハマりどころがある。\n上記に加えてaws_s3拡張機能のインストールが必要。\nDBに接続して以下コマンドを実行する。\nCREATE EXTENSION aws_s3CASCADE;\nRDS用のIAMロール作成 実行するLambda用のIAMロールとは別に、RDSにアタッチするロールを作成する。\n必要なアクション\n・s3.PutObject\n・s3.AbortMultipartUpload\nresourceとして格納先バケットを指定（arn:aws:s3:::バケット名/*）\nロールを作成したらDBインスタンスにアタッチする。RDSの対象DBの画面で「接続とセキュリティ」タブをスクロールして、「IAMロールの管理」を表示。作成したIAMロールと、機能：s3Exportを指定して「ロールの追加」。（簡単にできそうだと思ってたけど前提が結構面倒くさかった\u0026hellip;）\nここまできて本題のコード。前回同様、認証情報はシークレットマネージャに格納して取得する方式。スキーマやテーブル名他名称部分は適宜置き換えで。あとDB接続時は本来with構文にする方が望ましい。\nimport json import boto3 import psycopg2 from datetime import datetime, date, time, timedelta # 認証情報をシークレットマネージャーから取得 def getCredentials(): credential = {} secret_name = \u0026#34;postgres/mysecretname\u0026#34; region_name = \u0026#34;ap-northeast-1\u0026#34; client = boto3.client( service_name=\u0026#39;secretsmanager\u0026#39;, region_name=region_name ) get_secret_value_response = client.get_secret_value( SecretId=secret_name ) secret = json.loads(get_secret_value_response[\u0026#39;SecretString\u0026#39;]) credential[\u0026#39;username\u0026#39;] = secret[\u0026#39;username\u0026#39;] credential[\u0026#39;password\u0026#39;] = secret[\u0026#39;password\u0026#39;] credential[\u0026#39;host\u0026#39;] = \u0026#34;RDS endpoint URL\u0026#34; credential[\u0026#39;db\u0026#39;] = \u0026#34;databasename\u0026#34; return credential def lambda_handler(event, context): # バケットとテーブル定義 bucket = \u0026#39;my bucket name\u0026#39; tbl = \u0026#39;mytbl\u0026#39; # 日付情報取得 yesterday = datetime.combine(date.today()-timedelta(1),time()) today = datetime.combine(date.today(),time()) # s3パス定義 key1 = yesterday.strftime(\u0026#34;%Y\u0026#34;) key2 = yesterday.strftime(\u0026#34;%m\u0026#34;) key3 = yesterday.strftime(\u0026#34;%%d\u0026#34;) s3_path = key1 + \u0026#34;/\u0026#34; + key2 + \u0026#34;/\u0026#34; + key3 + \u0026#39;tbl-export.txt\u0026#39; # DB接続 credential = getCredentials() connection = psycopg2.connect(user=credential[\u0026#39;username\u0026#39;], password=credential[\u0026#39;password\u0026#39;], host=credential[\u0026#39;host\u0026#39;], database=credential[\u0026#39;db\u0026#39;]) cursor = connection.cursor() # クエリ定義 query = f\u0026#39;\u0026#39;\u0026#39;\u0026#39;select * from aws_s3.query_export_to_s3( \u0026#39;select * from public.{tbl}\u0026#39;, aws_commons.create_s3_uri( \u0026#39;{bucket}\u0026#39;, \u0026#39;{s3_path}\u0026#39;, \u0026#39;ap-northeast-1\u0026#39; ) ))\u0026#39;\u0026#39;\u0026#39;[1:-1] # クエリ実行（エクスポートが実行される） cursor.excute(query) # 接続クローズ cursor.close() connection.commit() 参考までに、以下はDBから直接クエリ実行する場合。コードではpythonから実行するため、query変数を定義してヒアドキュメントでクエリを記述。また、f-stringsによる変数展開を行うため記述が多少異なる形になった。\nselect * from aws_s3.query_export_to_s3( \u0026#39;select * from public.data_tbl\u0026#39;, aws_commons.create_s3_uri( \u0026#39;bucketname\u0026#39;, \u0026#39;2023/09/01/rds_export_data.csv\u0026#39;, \u0026#39;ap-northeast-1\u0026#39; ) ); ちなみにここではテーブルデータ全部を引っこ抜いているが、一定の時刻範囲で抽出したい場合はクエリを調整すればよいかと。（当然timestamp列が存在する前提）\n","permalink":"https://ecnedaced-seirots.github.io/post/d/rds-export-to-s3-lambda/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eRDSのデータをS3にエクスポートするLambdaという「あるある」パターン。DBはPostgreSQL、Python3.9、エラー処理抜き。\u003c/p\u003e","title":"RDS(PostgreSQL)のデータをS3にエクスポートするLambda"},{"content":" （2020年10月の検証記事です）\nKubernetesのCronJobは、Job同様にオプション設定によってPodの扱いが変わってくるようなので試してみた。実行環境はMacOS上のminikube。\n気になっていた設定は以下。\nsuccessfulJobsHistoryLimit（成功時のPod履歴数。デフォルト3）\nfailedJobsHistoryLimit（失敗時のPod履歴数。デフォルト1）\nrestartPolicy (NeverかOnFailureか）\nbackoffLimit （失敗時のリトライ数。デフォルト6だが0にする必要があるか）\n上の2つは履歴数といっても実際にPodがその数だけ残るので、リソースが逼迫気味なワーカーノードでは気にしたいところ。\n以下サンプルマニフェスト。dateコマンド結果を吐き出すだけの無意味なタスク。\ncron_test_never.yaml\napiVersion: batch/v1beta1 kind: CronJob metadata: name: cron-test spec: schedule: \u0026#34;*/1 * * * *\u0026#34; concurrencyPolicy: Forbid successfulJobsHistoryLimit: 2 failedJobsHistoryLimit: 2 jobTemplate: spec: template: spec: containers: - name: cron-test image: busybox command: [\u0026#34;/bin/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo $(date -u) \u0026gt; /tmp/date.log\u0026#34;] restartPolicy: Never 今回は深追いしていないが、concurrencyPolicy: Forbid は同時実行を抑止するため設定。backofflimit:0 はこの段階では設定しない。\n実行結果\n$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE cron-test */1 * * * * False 0 \u0026lt;none\u0026gt; 7s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603592640-58wdq 0/1 Completed 0 54s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603592640-58wdq 0/1 Completed 0 84s cron-test-1603592700-8wlrx 0/1 Completed 0 24s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603592700-8wlrx 0/1 Completed 0 77s cron-test-1603592760-jdbcn 0/1 Completed 0 17s 指定通り、Podが2世代まで残る。次にsuccessfulJobsHistoryLimit: 0 にしてapply。\n$ kubectl get po No resources found in default namespace. $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603593300-vv7zd 0/1 ContainerCreating 0 1s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603593300-vv7zd 0/1 ContainerCreating 0 4s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603593300-vv7zd 0/1 Completed 0 7s $ kubectl get po No resources found in default namespace. 上記の繰り返しとなる。Podは実行中のみ存在し、Pod生成後10秒まではステータス取得可能らしい。restartPolicy: OnFailureでも同様のパターンでapplyしてみたが、正常時の動作はNeverと変わらなかった。\nCronJobではsuccessfulJobsHistoryLimit: 0にしておけば、backofflimit:0 設定は必要ない？と考えたが、失敗時の動作も見ておく必要があるのでそれも試してみた。\nエラーパターンではcommandの命令を以下のようにして、存在しないパスを指定した。\ncommand: [\u0026#34;/usr/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo $(date -u) \u0026gt; /tmp/date.log\u0026#34;] restartPolicy: Never エラーケース\nrestartPolicy: Never\nfailedJobsHistoryLimit: 2\nbackokfflimit指定なし\n$ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603596240-srrjj 0/1 ContainerCreating 0 4s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603596240-kwk4q 0/1 ContainerCannotRun 0 6s cron-test-1603596240-srrjj 0/1 ContainerCannotRun 0 11s (snip) $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603596240-dxvt2 0/1 ContainerCannotRun 0 58s cron-test-1603596240-kwk4q 0/1 ContainerCannotRun 0 68s cron-test-1603596240-m69th 0/1 ContainerCannotRun 0 38s cron-test-1603596240-srrjj 0/1 ContainerCannotRun 0 73s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603596240-7b42n 0/1 ContainerCannotRun 0 7s cron-test-1603596240-dxvt2 0/1 ContainerCannotRun 0 107s cron-test-1603596240-kwk4q 0/1 ContainerCannotRun 0 117s cron-test-1603596240-m69th 0/1 ContainerCannotRun 0 87s cron-test-1603596240-srrjj 0/1 ContainerCannotRun 0 2m2s failedJobsHistoryLimit: 2に関わらず、backofflimitのデフォルト値6(実際は5)の分だけPodが残ってしまう！\nここで、backokfflimit:0をセットしてapply。\napiVersion: batch/v1beta1 kind: CronJob metadata: name: cron-test spec: schedule: \u0026#34;*/1 * * * *\u0026#34; concurrencyPolicy: Forbid successfulJobsHistoryLimit: 2 failedJobsHistoryLimit: 2 jobTemplate: spec: backoffLimit: 0 template: spec: containers: - name: cron-test image: busybox command: [\u0026#34;/usr/sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;echo $(date -u) \u0026gt; /tmp/date.log\u0026#34;] restartPolicy: Never $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603596900-2fgfp 0/1 ContainerCannotRun 0 2m10s cron-test-1603596960-rtvj2 0/1 ContainerCannotRun 0 69s cron-test-1603597020-mhgm8 0/1 ContainerCannotRun 0 9s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597020-mhgm8 0/1 ContainerCannotRun 0 96s cron-test-1603597080-548zl 0/1 ContainerCannotRun 0 36s backokfflimit:0により、failedJobsHistoryLimit: 2の指定通りに世代が残った。\n次にfailedJobsHistoryLimit: 0にしてapply。すると、Podが存在するのはタスク実行時のみとなった。\n$ kubectl get po No resources found in default namespace. $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597320-8kk2g 0/1 ContainerCannotRun 0 5s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597320-8kk2g 0/1 ContainerCannotRun 0 8s $ kubectl get po No resources found in default namespace. 確かに余分なリソースは食わないが、エラー調査がまったくできない。そこを考慮するならば、failedJobsHistoryLimit: 1が理想的かもしれない。\nrestartPolicy: OnFailure エラーケース\nrestartPolicy: OnFailure\nfailedJobsHistoryLimit: 2\nbackokfflimit指定なし\n$ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597980-swr2d 0/1 RunContainerError 0 19s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597980-swr2d 0/1 RunContainerError 1 32s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597980-swr2d 0/1 RunContainerError 2 42s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597980-swr2d 0/1 RunContainerError 3 66s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603597980-swr2d 0/1 CrashLoopBackOff 4 2m15s failedJobsHistoryLimit: 2は影響せず、同一podでリスタートを繰り返す。Neverパターンではステータスが\u0026quot;ContainerCannotRun\u0026quot;だったが、OnFailureでは\u0026quot;RunContainerError\u0026quot;となる。途中からCrashLoopBackOffになった。\n次にbackokfflimit:0をセットしてapply。\n$ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603598820-vnrfr 0/1 ContainerCreating 0 2s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603598820-vnrfr 0/1 RunContainerError 0 6s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603598820-vnrfr 0/1 RunContainerError 0 22s $ kubectl get po No resources found in default namespace. $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603598880-l2jmx 0/1 RunContainerError 0 12s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603598880-l2jmx 0/1 Terminating 1 23s $ kubectl get po No resources found in default namespace. 起動されるPodは常に1つだが、異なるPodが起動された。次にfailedJobsHistoryLimit: 0にしてapplyしたところ、動作としては上記と変わらず、起動の都度Podが変化した。Podがわずかな時間しか存在しないため調査が困難と想定する。\n結局どうすればいいか\n成功時も失敗時も余分なPodを起動させないようにしたい。ただしエラー発生時は調査可能にしておきたい。であれば、以下の設定が妥当かと思われる。\nsuccessfulJobsHistoryLimit: 0\nfailedJobsHistoryLimit: 1\nbackoffLimit: 0\nrestartPolicy: Never\n上記ステータスで改めてapply。\n$ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603600380-t8jgq 0/1 ContainerCreating 0 3s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603600380-t8jgq 0/1 ContainerCannotRun 0 57s $ kubectl get po NAME READY STATUS RESTARTS AGE cron-test-1603600440-pzf5r 0/1 ContainerCannotRun 0 24s #1分後は次のPodが起動 PodはCron実行時間単位で新たに起動されるので、1分毎に実行の場合はその間にログを取得する必要がある\u0026hellip;といっても次に起動したPodで取得してもいいんだから、まぁどうにかなるか。\n","permalink":"https://ecnedaced-seirots.github.io/post/d/kubernetes-cronjob/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003e（2020年10月の検証記事です）\u003c/p\u003e\n\u003cp\u003eKubernetesのCronJobは、Job同様にオプション設定によってPodの扱いが変わってくるようなので試してみた。実行環境はMacOS上のminikube。\u003c/p\u003e","title":"Kubernetes - CronJobオプションの検証"},{"content":" CloudWatch Logs Insightsのクエリを、マネジメントコンソールからではなく、AWS CLI及びPython SDK(boto3)から投げてみる。\n（この記事は2021年10月に他のブログで書いた記事です）\n結論を先に言ってしまうと、CLIで取得可能な出力は限定的な様子。このためバリエーションとなるクエリを投げるにはSDKから行う必要がありそうだ。\nLogs InsightsのクエリをCLIで実行する際は、最初にクエリIDを取得し、そのIDを指定して結果を取得する2段階となる。\n参考\nAWS CLI - logs\nAmazon CloudWatch Logs InsightsをCLIから使ってみた #reinvent\nクエリID取得。ロググループとスキャン対象とする時間範囲をUNIXタイムスタンプで指定する。以下は単純に指定のロググループ・時刻範囲から10レコードを降順で取得するだけのクエリ。 $ aws logs start-query \\ --log-group-name \u0026#39;/ec2/var/log/messages\u0026#39; \\ --start-time 1629558000 \\ --end-time 1629644399 \\ --query-string \u0026#39;fields @timestamp, @message | sort @timestamp desc | limit 10\u0026#39; 以下のようなクエリIDが返される。後続のコマンドでこのIDを指定する。\n{ \u0026#34;queryId\u0026#34;: \u0026#34;8e1d5b49-b83b-4b84-a32f-4aadf8ce3d11\u0026#34; } クエリ結果を取得する。 $ aws logs get-query-results \\ --query-id \u0026#39;8e1d5b49-b83b-4b84-a32f-4aadf8ce3d11\u0026#39; すると実行結果として、JSON形式でメッセージやタイムスタンプ、メタデータが出力される。ちなみにここで出力される項目「@ptr」はログイベントのメタデータとなるもの。get-log-record実行時はこの値を指定する。\nここまでは簡単にできた。が、冒頭に書いたように、クエリを若干アレンジすると期待値にならないのだ。以下はメッセージに「\u0026ldquo;count_number_is\u0026quot;を含む」というフィルタをかけた例。（面倒だからIDを変数に格納）\n$ query=`aws logs start-query \\ --log-group-name \u0026#39;/ec2/var/log/messages\u0026#39; \\ --start-time 1629558000 \\ --end-time 1629644399 \\ --output text \\ --query-string \u0026#39;fileds @timestamp, @message | filter @message like /count_number_is/ | sort @timestamp desc\u0026#39; $ aws logs get-query-results --query-id $query 出力結果はこうなる。同じクエリをマネジメントコンソールから投げれば値が得られるのに、CLIでは結果が空になってしまう。ちなみに先のフィルタなしクエリでは\u0026quot;recordsMatched\u0026rdquo;: 221.0,だった。今度は0。recordsScanned,bytesScannedの値は同じ。\n{ \u0026#34;results\u0026#34;: [], \u0026#34;statistics\u0026#34;: { \u0026#34;recordsMatched\u0026#34;: 0.0, \u0026#34;recordsScanned\u0026#34;: 1404.0, \u0026#34;bytesScanned\u0026#34;: 167578.0 }, \u0026#34;status\u0026#34;: \u0026#34;Complete\u0026#34; } ドキュメントを見ても制約らしきことは書かれていないが、他で検索しても適当な情報が見つからないのでPython SDKで試してみた。rubyでカスタムクエリを実行している例があったからきっとできるだろう、と。\n以下のクエリは最初のCLIでの成功例とまったく同じものである。\u0026ldquo;response\u0026quot;の出力結果は当然期待値となる。（インタラクティブモードで実行）\nimport boto3 from datetime import datetime, timedelta import time client = boto3.client(\u0026#39;logs\u0026#39;) query = \u0026#34;fields @timestamp, @message | sort @timestamp desc | limit 10\u0026#34; log_group = \u0026#39;/ec2/var/log/messages\u0026#39; start_query_response = client.start_query( logGroupName=log_group, startTime=1629558000, endTime=1629644399, queryString=query, ) query_id = start_query_response[\u0026#39;queryId\u0026#39;] response = None while response == None or response[\u0026#39;status\u0026#39;] == \u0026#39;Running\u0026#39;: print(\u0026#39;Waiting for query to complete ...\u0026#39;) time.sleep(1) response = client.get_query_results( queryId=query_id ) print(response) 次にフィルタを追加してみる。queryを以下のように変更。\nquery = \u0026#34;fields @timestamp, @message | sort @timestamp desc | filter @message like /count_number_is/\u0026#34; すると、クエリのresponseは期待値になった！以下はサマリの出力だが、92レコードマッチという値がとれている。マネジメントコンソールでも同じクエリを投げてみると、同じく92レコードだった。この値だけ抜き出したい場合は別処理から抽出すればいい。\n\u0026#39;statistics\u0026#39;: {\u0026#39;recordsMatched\u0026#39;: 92.0, \u0026#39;recordsScanned\u0026#39;: 1404.0, \u0026#39;bytesScanned\u0026#39;: 167578.0} というわけでSDKなら自由にクエリを構成できた。CLIでクエリのバリエーションが効かないのは謎のままであるが、こういうのを運用する場合はどうせLambdaでやるわけだから今今無理に追求しないでおく。\n参考\nAPI reference(get_query_results)\nPythonコードは以下参考\nHow to query cloudwatch logs using boto3 in python\nGo SDKの例\nGoを使ってCloudWatch Logs Insightsでクエリを実行する\nRuby SDKの例\nCloudWatch Logs Insightsで始める簡単！！ログ集計\n","permalink":"https://ecnedaced-seirots.github.io/post/d/aws-logs-insights-boto3/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cp\u003eCloudWatch Logs Insightsのクエリを、マネジメントコンソールからではなく、AWS CLI及びPython SDK(boto3)から投げてみる。\u003c/p\u003e","title":"AWS Logs InsightsをCLIまたはPython(boto3)から実行"},{"content":"テレワーク、リモートワーク、在宅ワーククソ喰らえ的な立場ではあるが\u0026hellip;.。\nリモートデスクトップ上のTeams会議で音声を有効にする設定なんぞ。\nリモートデスクトップ接続時の設定で、画面下の「オプションの表示」を開く。\nローカルリソースタブを選択。\n「リモートオーディオ」セクションの「設定」を押下。以下にチェックする。（上はデフォルトで有効）\nリモートオーディオ再生：このコンピュータで再生する\nリモートオーディオ録音：このコンピュータで録音する\n本郷、2016年\n","permalink":"https://ecnedaced-seirots.github.io/post/d/remote-desktop-audio-setting/","summary":"\u003cp\u003eテレワーク、リモートワーク、在宅ワーククソ喰らえ的な立場ではあるが\u0026hellip;.。\u003cbr\u003e\nリモートデスクトップ上のTeams会議で音声を有効にする設定なんぞ。\u003c/p\u003e","title":"リモートデスクトップのオーディオ設定"},{"content":"S3レプリケーションのポイントとして重要なのが、ソース/レプリケート先両方のバケットでバージョニングを有効にすること。異なるアカウントへのレプリケーションの場合、レプリケート先のバケットポリシーでソースバケットからのアクセスを許可すること。\nレプリケート先アカウントのバケポリでは、ソースバケット所有者の AWSアカウントIDとレプリケート先バケット名を指定する。\n大前提の設定\nソース/レプリケート先両方のバケットで以下の設定とする。\n・ バージョニング：有効\n・ ACL ：　無効\n・ パブリックアクセス ：ブロック　※要件次第\n基本的な構成\n(1) ソースバケット\n・ バケット名：source-bucket-name\n・ AWS リージョン：ap-northeast-1\n・ バケットのバージョニング：有効にする\n(2) レプリケーションバケット\n・ バケット名：replication-bucket-name\n・ AWS リージョン：ap-northeast-1 ※クロスリージョンの設定も可能。\n・ バケットのバージョニング：有効にする\nレプリケーションルール\n対象バケットの「管理」タブから、レプリケーションルールを作成する。\nレプリケーションルール名：TestRule\nステータス：有効（デフォルト）\n優先順位：1 （デフォルト）\n「ソースバケット」セクション\nルールスコープを選択：「このルールは、バケット内のすべてのオブジェクトに適用されます」を選択\n送信先セクション\n「別のアカウントのバケットを指定する」にチェック\n送信先のバケット名を入力\n送信先リージョン：（想定するリージョン名になっていること）\nIAMロール\nレプリケーション設定時に新しいIAMロールの自動作成が可能だが、要件に応じて予め作成しておく。\nレプリケーションロール用の信頼ポリシー\n{ \u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;:[ { \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;:{ \u0026#34;Service\u0026#34;:\u0026#34;s3.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;:\u0026#34;sts:AssumeRole\u0026#34; } ] } IAMロールにアタッチするIAMポリシー。（ソースAWSアカウントで設定）\n{ \u0026#34;Version\u0026#34;:\u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;:[ { \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;:[ \u0026#34;s3:GetObjectVersionForReplication\u0026#34;, \u0026#34;s3:GetObjectVersionAcl\u0026#34; ], \u0026#34;Resource\u0026#34;:[ \u0026#34;arn:aws:s3:::ソースS3バケット名/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;:[ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetReplicationConfiguration\u0026#34; ], \u0026#34;Resource\u0026#34;:[ \u0026#34;arn:aws:s3:::ソースS3バケット名\u0026#34; ] }, { \u0026#34;Effect\u0026#34;:\u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;:[ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetReplicationConfiguration\u0026#34;, \u0026#34;s3:GetObjectVersionForReplication\u0026#34;, \u0026#34;s3:GetObjectVersionAcl\u0026#34;, \u0026#34;s3:GetObjectRetention\u0026#34;, \u0026#34;s3:ReplicateObject\u0026#34;, \u0026#34;s3:GetObjectVersionTagging\u0026#34;, \u0026#34;s3:GetObjectLegalHold\u0026#34;, \u0026#34;s3:ReplicateDelete\u0026#34;, \u0026#34;s3:ObjectOwnerOverrideToBucketOwner\u0026#34;, \u0026#34;s3:ReplicateTags\u0026#34; ], \u0026#34;Resource\u0026#34;:\u0026#34;arn:aws:s3:::レプリケート先S3バケット名/*\u0026#34; } ] } オプション設定\nデフォルトのレプリケーション設定は、ソースバケット側のオブジェクト削除をレプリケート先では反映しない。このため、削除をレプリケート先で反映させたい場合はルールを変更する必要がある。レプリケーションルール\u0026ndash;＞追加のレプリケーションオプション-＞「削除マーカーのレプリケーション」にチェックを入れる。\n上記は要件に応じてやればよいが、「レプリケーション時間のコントロール(RTC)」「レプリケーションメトリクスと通知」はほぼ有効にしておくべきと思われる。\n所有者の変更\nデフォルトでソース元アカウントがレプリカの所有権を持つが、レプリケート先のアカウントが所有権を保持するように設定することも可能。実現するには、送信先S3バケットのバケットポリシーに、オブジェクト所有者を変更できる権限(ObjectOwnerOverrideToBucketOwner)を追加する。\n以下、所有者変更権限を付与したバケポリ。（レプリケート先アカウントのバケットに設定）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;destination_bucket_policy_sid\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::ソースAWSのアカウントID:role/service-role/ソースAWSアカウントのIAMロール\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ReplicateObject\u0026#34;, \u0026#34;s3:ReplicateDelete\u0026#34;, \u0026#34;s3:ObjectOwnerOverrideToBucketOwner\u0026#34;, \u0026#34;s3:ReplicateTags\u0026#34;, \u0026#34;s3:GetObjectVersionTagging\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::レプリケート先S3バケット名/*\u0026#34; ] } ] } 暗号化の対応\nレプリケート元バケット内のオブジェクトが SSE-S3、AWS KMSキーによるサーバー側の暗号化 (SSE-KMS)、または AWS KMS キーによる二層式サーバー側の暗号化 (DSSE-KMS) を使用して暗号化されている場合、レプリケート先バケットのレプリカオブジェクトはレプリケート元オブジェクトと同じタイプの暗号化を使用する。レプリケート先バケットのデフォルトの暗号化設定は使用されない。\nデフォルトでは、Amazon S3 はAWS KMSキーによるサーバー側の暗号化 (SSE-KMS) を使用して暗号化されたオブジェクトをレプリケートしない。SSE-KMSで暗号化されたオブジェクトをレプリケートするには、別途設定が必要。\n重要ポイント。KMSキーはレプリケート先バケットと同じAWSリージョン内で作成されている必要がある。\n以下事例は同一リージョン内の設定となるが、非常に重要な参考例。KMKSキーは送信元・送信先両方で作成する必要がある模様。\nSSE-KMSで暗号化したS3バケット同士のクロスアカウントレプリケーションでは、S3バケットキーの有無に注意してほしい ※classmethodブログ\nそれからレプリケート先でKMS CMKを設定することは可能な様子であるが、異なるリージョンでも設定可能かどうかは不明。以降、同一リージョン間レプリケーションと想定して\u0026hellip;、レプリケート先でCMKを使用する場合、キーポリシーの「\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;Allow use of the key\u0026rdquo;,」、「\u0026ldquo;Sid\u0026rdquo;: \u0026ldquo;Allow attachment of persistent resources\u0026rdquo;」のPrincipalにソースAWSアカウントのIAMロールARNを追加する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34;, \u0026#34;kms:GenerateDataKey\u0026#34;, \u0026#34;kms:ReEncryptTo\u0026#34;, \u0026#34;kms:GenerateDataKeyWithoutPlaintext\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKeyPairWithoutPlaintext\u0026#34;, \u0026#34;kms:GenerateDataKeyPair\u0026#34;, \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ReEncryptFrom\u0026#34;, \u0026#34;kms:ListGrants\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:ap-northeast-1:ソースAWSアカウントID:key/CMKキーID\u0026#34; } ] ソースAWSアカウントのIAMロールでも、CMKによる暗号化を可能とするIAMポリシーを設定する必要がある。\n参考\nレプリケート元バケットとレプリケート先バケットが異なるアカウントによって所有されている場合での、レプリケーションの設定\nソースとレプリケート元とレプリケート先のバケットが異なるアカウントによって所有されている場合のレプリカの所有者の変更\nサーバー側の暗号化 (SSE-C、SSE-S3、SSE-KMS、DSSE-KMS) で作成されたオブジェクトをレプリケートする\nクロスアカウントによるS3レプリケーションのパターン別設定方法 ※classmethodブログ\n暗号化 + クロスアカウントパターン\nSSE-KMS暗号化したS3バケットのクロスアカウントレプリケーションをやってみた\nSSE-KMSで暗号化したS3バケット同士のクロスアカウントレプリケーションでは、S3バケットキーの有無に注意してほしい ※classmethodブログ\nCRR(クロスリージョンレプリケーション)用の設定 ※やることはほぼ同じ。\n【備忘録】AWS S3 クロスリージョンレプリケーション(CRR)の設定方法\nS3クロスリージョンレプリケーションをやってみた\nレプリケーションに限らず、「カスタムKMSキーで暗号化したバケット + クロスアカウント」のS3操作は何かとハマりどころがある。必要な設定など以下参考。\n他のアカウントのユーザーに KMS キーの使用を許可する\nクロスアカウントユーザーがカスタム AWS KMS キーで暗号化された S3 オブジェクトにアクセスしようとするときに Access Denied エラーが発生するのはなぜですか?\nKMS Not found Exception in AWS Cross Account S3 PutObject encrypted by AWS Managed Key\n","permalink":"https://ecnedaced-seirots.github.io/post/d/s3-cross-account-replication/","summary":"\u003cp\u003eS3レプリケーションのポイントとして重要なのが、ソース/レプリケート先両方のバケットでバージョニングを有効にすること。異なるアカウントへのレプリケーションの場合、レプリケート先のバケットポリシーでソースバケットからのアクセスを許可すること。\u003c/p\u003e","title":"異なるアカウント間のS3レプリケーション設定"},{"content":"EC2またはクライアントPCから簡単にRDSへ疎通確認したい時に便利なコマンドがある。（長年この業界にいながら最近知ったという）\nクライアントでちゃんと接続する前に、TCPレイヤーでいいから疎通確認しておきたい時なんかめっちゃ便利。\nWindowsの場合\nPowerShellのターミナルから以下コマンド実行。接続先がMySQL/MariaDB前提で書いているが、他のDBの場合はポート番号を置き換える。\n\u0026gt; Test-NetConnection [エンドポイントURL] -Port 3306 成功時は「TcpTestSucceeded」の結果が「True」で返される。あとこれはもちろんEC2じゃなくてWindowsのクライアントPCからでも実行可能。\nLinuxの場合\ncurlにtelnetかますコマンドもあるが、libcurlのエラー出たりする。ncatで同じことがやれる。（入ってなかったらnmapをインストールする）\n$ ncat -v -z [エンドポイントURL] 3306 成功時は Connected to [ホストIPアドレス]:3306. が出力される。\n","permalink":"https://ecnedaced-seirots.github.io/post/c/rds-connection-check-from-ec2/","summary":"\u003cp\u003eEC2またはクライアントPCから簡単にRDSへ疎通確認したい時に便利なコマンドがある。（長年この業界にいながら最近知ったという）\u003c/p\u003e","title":"EC2からRDSへ簡単な疎通確認するコマンド(Windows/Linux)"},{"content":"AWS VPCエンドポイントに対応するサービス一覧。いざという時に見つからなくて困るのでここにリンク貼っておく。\nAWS PrivateLink と統合する AWS のサービス\nそれだけ\u0026hellip;。\n","permalink":"https://ecnedaced-seirots.github.io/post/c/aws-vpc-endpoint-service/","summary":"\u003cp\u003eAWS VPCエンドポイントに対応するサービス一覧。いざという時に見つからなくて困るのでここにリンク貼っておく。\u003c/p\u003e","title":"AWS VPCエンドポイントサービス一覧"},{"content":"前回投稿でやったOpenCV(Python)の画像連結を少し応用。高さが異なる画像をリサイズして結合させてみた。これもめっちゃ簡単にできて感動。\nサンプル画像。cruise_001.JPGの高さは1200px、cruise_002.JPGの高さは1190pxである。\ncruise_001.JPG\ncruise_002.JPG\nエラー処理も何もないが、取り急ぎコードはこんなんで。ここでは小さい方のcruise_002に合わせてcruise_001をリサイズして結合する。ついでに読込み画像ファイルと出力ファイルを引数で指定するようにした。\nresize_horizontal_join.py\nimport sys import cv2 import numpy as np args = sys.argv # 画像ファイル名定義（第一、第二引数） f1 = args[1] f2 = args[2] #Join出力ファイル名（第三引数） outfile = args[3] #画像読み込み img1 = cv2.imread(f1) img2 = cv2.imread(f2) #画像の高さを揃える関数 def hconcat_resize_min(im_list, interpolation=cv2.INTER_CUBIC): h_min = min(im.shape[0] for im in im_list) im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation) for im in im_list] return cv2.hconcat(im_list_resize) #画像を結合して出力 img_h_resize = hconcat_resize_min([img1, img2]) cv2.imwrite(outfile, img_h_resize) 実行コマンド。\n$ python3 resize_horizontal_join.py cruise_001.JPG cruise_002.JPG cruise_join.JPG すると、\u0026hellip;おぉ、あっさりやってくれた。画像の高さはcruise_002に合わせたため、1190pxになっている。(投稿時は手動で縮小）\ncruise_join.JPG\nやってることは単純なんだが\u0026hellip;、楽しい！こんな気持ち久しぶりだな〜\n参考\nPython, OpenCVで画像を縦・横に連結 (hconcat, vconcat, np.tile)\n","permalink":"https://ecnedaced-seirots.github.io/post/c/opencv-horizontal-join-resize/","summary":"\u003cp\u003e前回投稿でやったOpenCV(Python)の画像連結を少し応用。高さが異なる画像をリサイズして結合させてみた。これもめっちゃ簡単にできて感動。\u003c/p\u003e","title":"OpenCVで画像をリサイズして横に連結する"},{"content":"画像を横に連結したい事情があり、OpenCVでできそうだなと軽く調べたら、すごく簡単にできた。\nこんな画像があるとする。これらを横に繋げたい。\nBCN_001.JPG\nBCN_002.JPG\nコードはめっちゃ単純だけどこんなんで。\nopencv_horizontal_join.py\nimport cv2 import numpy as np #画像読み込み img1 = cv2.imread(\u0026#39;BCN_001.JPG\u0026#39;) img2 = cv2.imread(\u0026#39;BCN_002.JPG\u0026#39;) #画像を横に連結 img_h = cv2.hconcat([img1, img2]) cv2.imwrite(\u0026#39;BCN_join.JPG\u0026#39;, img_h) 画像を格納したディレクトリでコードを実行すると、同じディレクトリに結合された画像（BCN_join.JPG）が出力される。\nBCN_join.JPG\n画像はもちろん縦に連結したり、タイル状に並べることもできる。縦に結合する場合はcv2.vconcat()を使う。\nそれから今回はサイズが最初から揃っている前提でやっているが、異なるサイズの画像をリサイズして実行させたりもできる。詳細は参考リンクに。あとファイル名は引数で処理したいが、どうにでもなるのでまた今度。\n参考\nPython, OpenCVで画像を縦・横に連結 (hconcat, vconcat, np.tile)\nいやはや、どうってことない処理だけどこれがやりたかったんだよ、ツールとか入れたくなかったから、簡単にできて本当によかった。(大昔にImageMagickで散々やってたけど）\n","permalink":"https://ecnedaced-seirots.github.io/post/c/opencv-horizontal-join/","summary":"\u003cp\u003e画像を横に連結したい事情があり、OpenCVでできそうだなと軽く調べたら、すごく簡単にできた。\u003c/p\u003e","title":"OpenCVで画像を横に連結する"},{"content":"API GatewayのバックエンドとしてはLambdaが王道ではあるが、他のサービスと連携させたいときに何が選べて、どうすれば実現できるのかいまいち不明だったので軽く調べてみた。\n特にECSと直接連携できるのか気になった。間にALBまたはサービスディスカバリ（ECSの機能）を挟む必要があるらしい。あとこの場合RESTではなくHTTP APIになる模様。それともどっちでもいける？ あといずれのパターンでも、GatewayがVPC内のリソースにアクセスするためにVPCリンクを作成する必要がある。\nチュートリアル: Amazon ECS サービスへのプライベート統合を使用した HTTP API の構築 ※間にALBを挟む例 ECSをAPI Gatewayと組み合わせる ※サービスディスカバリ事例\nAPI Gateway 統合を使用して Fargate で実行されているマイクロサービスを呼び出す ※Step Functions使用例\n以下は若干古い記事なので現在の仕様と異なる可能性あり。つまり過去は制約があってこの構成になったが、今なら先のリンクのような別のソリューションがある。一応参考までに貼っておく。\nAPI Gateway経由でのみアクセス可能なAPIをECSで構築する\nAPI GatewayとAPIサーバの連携\nこれも貼っておく。REST APIの事例も欲しい。\nAPI Gateway の HTTP API が 5つのAWSサービスとの統合をサポート\n","permalink":"https://ecnedaced-seirots.github.io/post/c/aws-api-gateway-service/","summary":"\u003cp\u003eAPI GatewayのバックエンドとしてはLambdaが王道ではあるが、他のサービスと連携させたいときに何が選べて、どうすれば実現できるのかいまいち不明だったので軽く調べてみた。\u003c/p\u003e","title":"ECSをAmazon API Gatewayのバックエンドにするケース"},{"content":"約1年前の記事 CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(2) の改良版の話。\nログ監視用コードはループさせない\n上記投稿を書いた当時はログイベント全てをメール通知する方式だったが、これだと類似の通知メールが大量に飛んでしまい、抑止した方がいいのでは\u0026hellip;という流れになった。通知は最初の一回だけ、に変更した。運用上はこれで要件は満たせるという判断。これが正しいということではなく、現場の方針次第。以下記事のコメント欄で指摘されている対応は、逆にやめることになった。 cloudwatchlogs -\u0026gt; lambda -\u0026gt; SNSを試してみた\nLambda自体のログにトリガー元を記録する\n別途Lambda自体のログについて。Lambda自体のログはエラーが出たか否かと発生時刻くらいしか情報を吐かない。設計上複数のイベントを一つのLambda関数に連携する想定なので、そのままだとLambda関数のInvoke時のトリガーが不明で調査が困難になる（ログ監視でもリソース、メトリクス監視でも） そのため、Lambdaコード自体のログに、トリガー元のロググループ名を出力させることにした。（アラームならアラーム名）\nメッセージ全量を吐かせてもいいがそうするとLambda自体に問題がなくてもLambdaのログにErrorなどの文字が含まれてしまい、ややこしくなる。ログも肥大化する。（大した量ではないとはいえ）このためメッセージ全量については「普段はコメントしておいて、デバッグ時のみコメントを外す」運用とした。\n追加した内容\nデバッグ用に、メッセージ全量出力。必要時だけコメントを外す\nlog_message= log_json[\u0026#39;message\u0026#39;] #print(\u0026#39;LogMessage: \u0026#39;, log_message) ロググループ名を出力。これは常時適用\nlog_group = data_json[\u0026#39;logGroup\u0026#39;] print(\u0026#39;LogGroup: \u0026#39;,log_group) アラーム用コード例。件名に投入するためアラーム名を取得しているが、printでLambda自体のログにも吐かせる。\nalm_list = alarm[0].split(\u0026#39;:\u0026#39;) alm_name = alm_list[-1] print(\u0026#39;AlarmName: \u0026#39;, alm_name) コード全体。\n修正前\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): # ロググループ名取得 log_group = data_json[\u0026#39;logGroup\u0026#39;] # ログストリーム名取得 log_stm = data_json[\u0026#39;logStream\u0026#39;] # LogEvents取得 log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) #UNIX時間→時刻/JST変換 datetime_utc = log_json[\u0026#39;timestamp\u0026#39;] / 1000.0 datetime_utc = datetime.datetime.fromtimestamp(datetime_utc).strftime(\u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_utc = datetime.datetime.strptime(datetime_utc, \u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_jst = datetime_utc + datetime.timedelta(hours = 9) # メール件名整形 subject_str = \u0026#34;本番環境 - ログアラート \u0026#34; + log_group # メッセージ本文整形 fix_msg = \u0026#34;以下のアラートが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; log_group_msg = \u0026#34;ロググループ名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_group log_stm_msg = \u0026#34;ログストリーム名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_stm time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + str(datetime_jst) log_msg = \u0026#34;メッセージ:\u0026#34; + \u0026#34;\\n\u0026#34; + log_json[\u0026#39;message\u0026#39;] msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + log_group_msg + \u0026#34;\\n\\n\u0026#34; + log_stm_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + log_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 修正後\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): # ログメッセージ定義 data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) # ログイベント全体を出力（デバッグ用） #print(log_entire_json) # ロググループ名取得 log_group = data_json[\u0026#39;logGroup\u0026#39;] print(\u0026#39;LogGroup: \u0026#39;,log_group) # ログストリーム名取得 log_stm = data_json[\u0026#39;logStream\u0026#39;] # LogEvents取得。ログイベント数に関わらず最初の１ログイベントのみ取得する。（大量通知抑止のため） log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][0], ensure_ascii=False)) #UNIX時間→時刻/JST変換 datetime_utc = log_json[\u0026#39;timestamp\u0026#39;] / 1000.0 datetime_utc = datetime.datetime.fromtimestamp(datetime_utc).strftime(\u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_utc = datetime.datetime.strptime(datetime_utc, \u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_jst = datetime_utc + datetime.timedelta(hours = 9) # ログメッセージ取得 log_message = log_json[\u0026#39;message\u0026#39;] #print(\u0026#39;LogMessage: \u0026#39;, log_message) # メール件名整形 subject_str = \u0026#34;本番環境 - ログアラート \u0026#34; + log_group # メッセージ本文整形 fix_msg = \u0026#34;以下のアラートが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; log_group_msg = \u0026#34;ロググループ名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_group log_stm_msg = \u0026#34;ログストリーム名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_stm time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + str(datetime_jst) log_msg = \u0026#34;メッセージ:\u0026#34; + \u0026#34;\\n\u0026#34; + log_json[\u0026#39;message\u0026#39;] msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + log_group_msg + \u0026#34;\\n\\n\u0026#34; + log_stm_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + log_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) ","permalink":"https://ecnedaced-seirots.github.io/post/b/cloudwatchlogs-send-filter-mail-3/","summary":"\u003cp\u003e約1年前の記事 \u003ca href=\"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail-2/\"\u003eCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(2)\u003c/a\u003e の改良版の話。\u003c/p\u003e","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(3)"},{"content":"AWSアイコンのURL。間が空くと最新のが入れ替わってることがあるからメモ。\nAWSアーキテクチャアイコン\nこれだけ。書きたいことはやまやまあるけど時間が\u0026hellip;。\nそもそも7月、8月と全然ポストできなかった。でも龍quotesのポストなんか後で読み返すと勇気付けられる。やっぱりコツコツ投稿続けるべきだな。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-icon/","summary":"\u003cp\u003eAWSアイコンのURL。間が空くと最新のが入れ替わってることがあるからメモ。\u003c/p\u003e","title":"AWSアーキテクチャアイコンのURL"},{"content":"「すべては振動であり、エネルギーである」という概念が浮上してきているが、最近そのシンクロ具合をひしと感じるんだよなぁ。\n「バイオレゾナンス」とかね。今後絶対重要なキーワード。当然、広まって欲しくない勢力もいるだろうけど。\n元々は、以下の記事を読んだのがきっかけだった。\nこの世の全ては振動でできている？特定の周波数や波長が持つ特別な力と効能とは？\nこのライターさんは他にも類似の興味深い記事をいくつか書いている。そして\u0026hellip;\n根源を突き詰めれば、素粒子（エネルギー）に行き着く、\n要するに、量子物理を生体医学に応用したわけで、\nもう、これだけで、バイオレゾナンスのファンになりソー、\n実際、各臓器が固有の周波数を持つのは聞いたことがある、\nバイオレゾナンス「すべては振動である」 (2) 量子物理学は、世界は見かけほど一定ではないことを教えてくれます。\nむしろ、私たち個人や集団の思考が構築し、壊し、再構築し続ける、絶え間ない動きの場なのです。永久に動き続ける場所なのです。\n（略）\n私たちは、最も美しく知的な構成を持つエネルギーの光にすぎません。\nそのエネルギーは水面下で絶えず変化しており、そのすべては私たちの強力な精神によってコントロールされているのです。\nあなたは、ひとつの大きな力強い人間なのです。\nもしあなたが強力な電子顕微鏡の下で見ることができ、それについて他の実験をすることができれば、あなたは電子、中性子、光子、その他の素粒子の形をした永遠に変化するエネルギーのクラスターで構成されていることがわかるでしょう。\nあなたの周りにあるすべてのものもそうです。\n量子物理学では、物体を観察するという行為が、その物体をそこに存在させるものであると説いています。\n物体は観察者と無関係に存在しているわけではないのです。\n（略）\nあなたの世界は、魂、心、身体で構成されています。\n（略）\n身体は、ある原因によって生み出された結果です。\nその原因を「思考」と呼びます。\n身体は生産することができません。ただ経験すること、経験されることだけができる・・・それは唯一無二の能力です。\n一方、思考は経験することができない・・・作ること、創造すること、解釈することはできます。\nそれは経験されるために相対性の世界（物理的世界、ボディ）を必要とします。\n魂はすべてであり、生命に思考と肉体を与えるものです。\nすべてはエネルギー\n上記の元ネタ\nEverything Is Energy And We Control It With The Power Of Our Thoughts\n以下はバイオレゾナンスを実践している歯科医院さんの記事より。\nドイツの理論物理学者マックス・プランク（Max Planck、1918年熱放射の研究によりノーベル物理学賞）は次のように言っています。\n全ては振動であり、その波紋である。 現実には何の物質も存在しない。 あらゆるすべてのものは振動から構成されている。 たとえば電磁波を遮断するファラデーゲージにウサギを入れておくとします。その一方で生命維持に必要なものつまり餌、水、空気充分に与え、運動も充分行えるようにしておいても、ウサギは平均3～6週間で死んでしまうのです。この実験から放射エネルギー、電磁波なしで生物の生存は不可能であるということが推測されます。 つまり電磁場は生命形成に不可欠なだけでなく、病気の発生とも深く関わりをもち、生物体にはエネルギー源を体外の電磁場から僅かながらでも受け、宇宙電磁場からも刺激を受ける必要があるということです。\n外から電磁場が形成された後、体内で新しい電磁場が形成されます。個々の臓器及び細胞は固有の電磁スペクトルを有しておりますが、それはそれぞれの電磁場の持つ特徴及び周波数によって決定されます。これらの電磁場の存続には細胞、臓器組織、すなわち全身の共鳴力が関与します。つまりこの共鳴力が乱れたり欠けたりすると、身体に合わない病気の原因となる電磁場が生じるのです。\n全ての生物に本来備わっている自然治癒力、正確に言えば自己調整能力のメカニズムが、これらの病理波を破壊できなくなったときに病気が引き起こるのです。この病理波は常時生物体内にあり、自己調整能力のメカニズムが壊れると、病気の症状として現れます 。治療手段としては患者の体内にあるこの電磁場を利用します。\nバイオレゾナンスメソッド\n「放射エネルギー、電磁波なしで生物の生存は不可能である」と。そして人間は心臓を中心に数メートルの磁界を形成している生き物。これは前回記事に書いた。\nなんかいろいろ繋がってきたな\u0026hellip;！シューマンレゾナンスとの関連もおさえておきたい。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/everything-is-energy/","summary":"\u003cp\u003e「すべては振動であり、エネルギーである」という概念が浮上してきているが、最近そのシンクロ具合をひしと感じるんだよなぁ。\u003c/p\u003e","title":"「すべては振動であり、エネルギー」概念の共鳴"},{"content":"ヒューマン・エネルギー・フィールド（HEF）は心臓から発生している。\u0026hellip;といってもまだ全然生齧りでよくわかっていないので、備忘として知るきっかけになった記事をあげておく。\n最新の研究では、心臓には、脳の5000倍～1万倍の磁場＝フィールドがあり事が解明されています。\n心臓こそが臓器の王様であることが分かってきたのです。\n◎心臓には\n・未来予知の能力がある\n・脳より早くより多くの情報を認知している\n・無限の創造性の源である\n・記憶がある\n・脳の5000倍?1万倍の磁場（フィールド）がある\nこの脳の5000倍?1万倍の磁場＝フィールドとは、ヒューマン・エネルギー・フィールド（HEF）のことであり、ミスマルノタマのことでもあります。\n（略）\n太陽→地球→人間\n太陽の子供は地球で、地球の子供は人間ですから、人間は太陽の孫になります。\n太陽の周りにある層は、虹として目で見ることが出来ます。\nそれと同じく地球の周りにも層があります。\n地球の周りにはヴァン・アレン帯という電離層があります。\n虹は七色ですが、それは太陽の周りにある7つの層が反映しているのです。\n地球にも同じように層があり、たぶん太陽と同じように7つの層があると思いますが、現代の科学では、やっと、2層になっているヴァン・アレン帯が分かっているだけです。\nヴァン・アレン帯には電子の層があります。\nその中には、アカシック・レコードがあるという説もあります。\nアカシック・レコードとは、虚空蔵のことですから、この虚空蔵と一体になるために、空海は、虚空蔵の真言＝能望を100万遍以上も唱えたのです。\nつまり「地球の脳波」「地球の鼓動」と共鳴するために、そして、宇宙の電子の層と一体になるために唱えたのです。\n地球の鼓動も、宇宙の虚空蔵も、本来の自分の振動（周波数）も同じだからです。\n奇跡を起こす数字の5・6・7と言えば・・・\n類似のことが以下の記事にも書いてある。\n実際心臓を中心とした人体の数メートルの 範囲に電磁界が形成されている事が観測 されています。これがつまり宇宙の基本 エネルギー形態であるトーラスの電磁界で あり、人体のオーラ場なのです。\n（略）\n心臓はチャクラの 中心で、高次元と当然つながっている 最大のゲートになります。そのため 高次元から無尽蔵に電磁気エネルギーを 得て、体内に血液を循環させるという 大作業を行えるわけです。\n（略）\n確かに心臓と脳は人体の最も主要な器官 だといえますし、脳と心臓間の神経の量、 血液の量がともに人体の中で最大です。 ただし、心臓と脳をつないでいる神経の 量は、心臓から脳へ送り込まれる方が 多いのです。つまり心臓が脳の司令塔 なのであって、逆ではないということ なのです。\n我々は、頭から血の気が引いたという ように、恐怖で頭が働かなくなる状態に なる事がありますが、それは心臓から 血液が脳に送り込まれなくなるという 事で、心臓が司令塔になっているの です。\n確かに脳は心臓から血液が供給される事 によって初めて働きますからね。 そして心臓からの脳に送り込まれる神経の 量の方が圧倒的に多いことも含めて、 心臓が主人である事は確かなようです。 心臓には、脳細胞によく似たニューロン が約４０，０００個もあり、やはり 心臓も思考できるという事を示しています。\n（略）\n心臓は、電磁界としても脳とは比べものに ならないくらい強大なエネルギーの ゲートになっていて、心臓は脳の１０万倍の 電気を生みだし、５０００倍の磁界を生み 出している事が、確かめられています。\n心臓（ハートチャクラ）から松果体へつながる経路が最重要だった！\nヒューマン・エネルギー・フィールド。ヴァン・アレン帯。トーラスの電磁界\u0026hellip;この辺りはこれから調べよう。\nそれにしてもこれらの記述を読んで、今まで不思議だったことがほぼ解明できた気がする。ヒトとヒトが物理的に一定の近い空間にいる時に感じる「気」の正体は、これだったのか！すっげぇ\u0026hellip;！\n","permalink":"https://ecnedaced-seirots.github.io/post/b/human-energy-field/","summary":"\u003cp\u003eヒューマン・エネルギー・フィールド（HEF）は心臓から発生している。\u0026hellip;といってもまだ全然生齧りでよくわかっていないので、備忘として知るきっかけになった記事をあげておく。\u003c/p\u003e","title":"ヒューマン・エネルギー・フィールド（HEF）周辺のこと"},{"content":"バルセロナの花屋。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/how-to-spent-june-2022/","summary":"\u003cp\u003eバルセロナの花屋。\u003c/p\u003e","title":"バルセロナストリート"},{"content":"例の注射に含まれている成分の、ヒトの霊性への介入。人の意識や精神における、物理的な振動・周波数との関係。この辺が気になる。\n「人間の霊性を奪うこと」「神との繋がりを断ち切ること」が「彼ら」の第一の目的である、という説がある。これは一理あると思っている。\nどのような作用機序で、ワクチンがヒトの霊性を奪うのか、詳細どころか概要もわからんよ。でも最近一部SNSの投稿とかブログ記事を読んでいるうちに、「そういうことか！」とうっすら面影が見えてきた気はする。そういうことって言っても他人に「こういうことなんだ！」と説明できるほど掴み切れてないけどね。\n参考\nワクチンが人から霊性あるいは精神性を奪うのだとすれば\n上記の参照先など\nコロナとそのワクチンが世界を席巻する勝利の日に立ち尽くしたりして\n人類が「究極的な汚れた血」を持つに至るまで\nまだこのテーマもやもやしてるけど、一言で言うとこういうことなんだろうなと思っている。（記事内引用）\n後でご紹介しますが、現実的に最先端の医学の分析では、「体内の《分子の振動》が意思も感情も支配している」ことがわかっているのです。\nこのワクチンは、人間が魂のこもった存在から魂のないロボットに変身することを意味します。コロナワクチンを接種された人は、もはや振動することができず、生涯を通じて低周波の振動範囲にとどまります。\nそう、「身体における分子の振動が、人の意思決定や感情を支配している」ということ。であるならば、ある物質を身体に注入する、さらにその物質に干渉する周波数を当てる。これだけで、いかようにも人間の精神をコントロールできてしまう想定。実際それは現実に起こっていることでもある。なにせ周囲を見渡すだけでも、昨年後半辺りから覇気がなくなった、影が薄くなった、意思の核らしきものが消えてしまった、違う人間になったみたいだ\u0026hellip;という人が多くなった。以前にはなかった冷たさを感じることもある。それは無関心に基づいているのと、他者との共感性を失っているのが主な要因と想像する。\nで、このことってまさに、以下のワクチン全く無関係な記事の内容と合致するのだ。\nこの世の全ては振動でできている？特定の周波数や波長が持つ特別な力と効能とは？\nドイツの物理学者であり、ノーベル賞受賞者であるマックス・プランク博士は、過去にこのような旨の発言を残しています。\n｢この世のすべては振動であり、その影響である。つまり、現実には何の物質も存在していない。私たちが認識している全ての物質は、振動によって構成されているものだ。また、全ての物質や事象には“それ固有の振動数”がある｣\nこの言葉を額面通り受け取るとすれば、私たちの目の前に広がっている現実社会、ここに存在している“あらゆる物質が実は振動によって作られている”ということになります。\n物体は果たして何から構成されているのか、原子を構成する素粒子はどのようにコントロールされているのか。その原理を辿っていけば、最後に出てくるのは｢振動｣であり、｢波の力｣なのではないかと考えることができるのです。\nまた、｢波の力｣に関して、科学的な側面からの情報がもっと欲しいと言う方は、物理学者・保江邦夫教授の著書などを参考にされると良いかもしれません。\n世の中とは不思議なもので、基本的に｢あなたの持っているもの（振動）｣と近いもの、あるいは関係のあるものが周囲に寄ってくる傾向があります。つまり、何らかの形で共振・共鳴するようなものが近づいてくるわけです。\n引用が続くが、以下はとりわけ重要な箇所と思われ\u0026hellip;\n私たちは物理的な肉体を持ちこの世に存在していますが、同時に振動する存在であり、更に言えば光（生体光子=バイオフォトン）を放つことが分かっています。\nバイオフォトンは私たちのDNAから放出されていますが、太陽光などと違い、微弱なエネルギーのために｢基本的には目で見ることができない｣ため、今では専用の機器などを用いて測定されています。また、このバイオフォトンと呼ばれる光は、私たちの意識等によってコントロールが可能であることも分かっていますが、同時に｢人の持つ意識の力は、光あるいは何らかの形で現れている｣ということも分かります。\n意識の力と言えば、世界中で研究されている祈りの力もそうですが、中でも特に大切にして頂きたいのは｢ありがとう｣という言葉の持つ力や、感謝の気持ちです。\n（略）\n｢ありがとう｣という言葉、感謝の意が｢水に綺麗な六角形の結晶を生みだす｣という事象もありますが、このような時代だからこそ、何かに対する｢ありがとう、ありがたい｣と感じる気持ちを大切にして、｢ポジティブな波長に共振しながら｣生きていきたい所です。\n人間は振動することで光を放つ存在である。しかし何かのきっかけで、これまで共振していたエネルギー（波長）を寸断されたらどうなるか。肉体的な命はまだ在るものの、代わりに別の低周波なエネルギーとしか共振できなくなったら、これまでと同じ光を放たなくなるだろう。\nその人たちは、かつての光を取り戻せるだろうか？ その人たちが再び高い波長に共振できるようになる道はあるだろうか？どのようにすれば可能なのだろうか？ それは今はわからないが、周りを見渡すと、ワクを打っても光を失っていない人もいる。だから希望は捨てたくない。\n身近に、どうにか光を取り戻して欲しいと思うロボット\u0026hellip;じゃなかった、人間もいる。しかし自分にやれることは、もうないのだ。\n少なくとも自分が今後やるべきことは、高い波長に共振しながら生きること、またそのような存在と繋がるようにすること、なんだよな。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/vax-frequency-spirituality/","summary":"\u003cp\u003e例の注射に含まれている成分の、ヒトの霊性への介入。人の意識や精神における、物理的な振動・周波数との関係。この辺が気になる。\u003c/p\u003e","title":"振動、周波数、霊性"},{"content":"タイトルの件、CloudWatchアラーム作るとかAWS Configをかますとか必要と思っていたけど、なくてもできると知る。\n参考\nEC2インスタンスの３つの死活監視\nさらに詳細\nEC2 インスタンスの状態が変化したときに、カスタマイズした E メール通知を受信するにはどうすればよいですか?\n上記例の場合指定する状態が「任意の状態」なのでanyとなる。（どの状態でも通知がくる）\n「特定の状態」にチェックしてプルダウンからshutting-down,stopping,stopped,terminatedなどを選択すれば、これらの状態になった時のみ通知がくる。（試してないから断言できないけどそのはず）\n「イベントソース」で設定する内容 サービスプロバイダー：AWSのサービス AWSのサービス：EC2 イベントタイプ：EC2 instance State-change Notification 任意の状態 or 特定の状態を選択 任意のインスタンス or 個別のインスタンスIDを選択 他の事例と同様に、上記をポチポチやると設定内容のJSONが生成されるので、それを見ると何をやるのか分かりやすい。\nまた上記の例では入力トランスフォーマーによりSNSに直接連携しているが、件名・本文をカスタマイズするなら、別途用意したLambda関数と連携するよう設定する。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ec2-node-monitor-eb/","summary":"\u003cp\u003eタイトルの件、CloudWatchアラーム作るとかAWS Configをかますとか必要と思っていたけど、なくてもできると知る。\u003c/p\u003e","title":"EC2のノード監視はEventBridgeだけで可能だった"},{"content":"「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より。\n\u0026ldquo;Hold on, Hashi,\u0026rdquo; Kiku murmured. An image of Hashi beset by demons of some kind floated in to his mind. \u0026ldquo;I\u0026rsquo;m comming!\u0026rdquo;\n“Coin Locker Babies” by Ryu Murakmi(page 490)\nキクがTokyoへ向かうため、ヘリコプターで島を出発するシーン。ここんとこめっちゃ好き。\n\u0026ldquo;I\u0026rsquo;m comming!\u0026rdquo;\n痺れるぜ★\n英語メモ\nbeset : (〜を) 困らせる、苦しませる、取り囲む、四方から襲う\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-13/","summary":"\u003cp\u003e「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より。\u003c/p\u003e","title":"Coin Locker Babies-3, Ryu Murakami "},{"content":"TerraformでCodePipeline作成時のオプション、PollForSourceChangesの注意点を深堀り。\n本件については以下の過去記事にも書いたけれども、改めて判明したことがあり。PollForSourceChanges = \u0026ldquo;false\u0026rdquo; or \u0026ldquo;true\u0026quot;により、トリガーとなるEventBridgeルール（以降EBルール）がAWSマネージドにより自動作成されるか否かという問題なのだが。\nTerraformでCodePipeline - PollForSourceChangesの注意\nマネージド側でEBルールが自動生成されるかどうかは、状況により異なる。\n(1) 初回apply時でflase -＞ EBルールが自動生成される\n(2) (1)の後に、新規パイプライン追加時 -＞ 新規追加リソースに対するEBルールは自動生成されない\n(3) 元はtrueだったのをfalseに変更 -＞ EBルールは自動生成されない\n検証結果だとこうなったが仕様としてどうなのかはっきりさせたくてサポートに聞いてみたが、明確な回答は得られなかった。つまりやってる側も知らん、と。\nマネコンからパイプライン作るケースとCLIでも挙動が異なる、というのは教えてもらったが。CLIとTerraformが利用するAPIでは若干異なるかもしれない。\nちなみに(1)で自動生成された場合、関連するIAMリソースも同時に自動生成される。EBルールを実行用のIAMロールとそのポリシーだ。（EBルールに対して1:1:1で都度作成される）\n東京リージョンの場合\nIAMロール名規則：cwe-role-ap-northeast-1-[パイプライン名]\nIAMポリシー名規則：start-pipeline-execution-ap-northeast-1-[パイプライン名]\n(1)のケースでは、「EBルール + IAMロール + IAMポリシー」のセットが自動生成されるが、独自にEBルールを作成してこれをトリガーとしたい場合これらのリソースは完全に不要のため、手動で削除する。\nちなみに独自EBルールの場合、これに紐づくIAMロール/ポリシーはパイプライン毎に用意する必要はなく、ひとつでいい。（対応リソースは*で指定）\nまったくもって重箱の隅的小ネタではあるが、Terraformで環境構築 ＆ 運用していくには、いろんなことを考慮しないといけないな、と改めてしみじみするなど。\n追記（2024年5月）\nPollForSourceChangesパラメータは公式ドキュメントに記載がなく、設定してもエラーになるという記事を見つけた。代わりにDetectChangesで期待値になったと。\nTerraformでCodepipelineの検出オプションを変更する\n確かに現時点でTerraform公式にPollForSourceChangesの記載がないんだけどDetectChangesも記載がない。 Resource: aws_codepipeline\n当該パラメータはconfiguration内で定義する。\nconfiguration - (Optional) A map of the action declaration\u0026rsquo;s configuration. Configurations options for action types and providers can be found in the Pipeline Structure Reference and Action Structure Reference documentation.\n先の記事にある通り、以下のリファレンスにはPollForSourceChangesの記載あり。DetectChangesの記載なし。\nCodePipeline pipeline structure reference\nTerraform公式とAWS間でパラメータがアンマッチなのかもしれない。ま、もういいや。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-codepipeline-memo3/","summary":"\u003cp\u003eTerraformでCodePipeline作成時のオプション、PollForSourceChangesの注意点を深堀り。\u003c/p\u003e","title":"TerraformでCodePipeline - PollForSourceChangesの注意(2)"},{"content":"AWSで、SNSトピックを送信先として監視を行っていて、SNSが配信に失敗していないかどうかを監視するケース。\nsns-metric.tf\n############################### # SNS metric alarm resource ############################### resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;metric_alarm_001\u0026#34; { alarm_name = \u0026#34;cw-metric-alarm\u0026#34; comparison_operator = \u0026#34;GreaterThanOrEqualToThreshold\u0026#34; evaluation_periods = \u0026#34;1\u0026#34; metric_name = \u0026#34;NumberOfNotificationFailed\u0026#34; namespace = \u0026#34;SNS\u0026#34; period = \u0026#34;60\u0026#34; statistic = \u0026#34;Average\u0026#34; threshold = \u0026#34;1\u0026#34; alarm_description = \u0026#34;SNS Notification Monitor\u0026#34; datapoints_to_alarm = \u0026#34;1\u0026#34; treat_missing_data = \u0026#34;notBreaching\u0026#34; dimentions = { TopicName = \u0026#34;sample-topic\u0026#34; } } treat_missing_dataの値は監視の条件により全く異なってくるので注意。ここでは「アラームが発生したら失敗」と見なすので\u0026quot;notBreaching\u0026quot;。\nしかしこの監視で人為的にアラームを発生させるのはほぼ無理だから、テストはできないと思われ。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-cwl-metric-alarm/","summary":"\u003cp\u003eAWSで、SNSトピックを送信先として監視を行っていて、SNSが配信に失敗していないかどうかを監視するケース。\u003c/p\u003e","title":"SNSメトリクスの監視を作成するTerraformコード"},{"content":"最近の身の回りの問題を突き詰めていくと、周波数、波長、波動、振動、といったものが重要なタームになってくる気がしている。「量子物理学」の領域で語られるようなやつ。\nそれは、例えば以下の記事を読むとつくづく実感するのである。\nこの世の全ては振動でできている？特定の周波数や波長が持つ特別な力と効能とは？\nわかりやすい事例として、例えば言葉も周波数である、とか。（「言霊」という振動）\n今まで馴染みがなかったが、人体が放つ光の波長「バイトフォトン」とか。\n私たちは物理的な肉体を持ちこの世に存在していますが、同時に振動する存在であり、更に言えば光（生体光子=バイオフォトン）を放つことが分かっています。\nすべての物質は振動エネルギーを放出している。世界はその振動で成り立っているという思想は、単純に面白いと思うし、自分的には十分納得できる。あらゆる問題を、これまでの3次元レベルでのみ捉える時代ではなくなってきている。そんな傾向は一部のSNS投稿を見ていても感じる。「波動」という言葉はどうもスピ寄りに引っ張られがちだが、頭ごなしにトンデモ扱いするのではなく、物理の視点から淡々と冷静に捉えて知識を深めたいものだ。\nこのライターさんの文章自体、とてもいい波動を出している。高次なエネルギーを持った人なんだろうなぁ、と捉えている。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/quantal-physics-frequency/","summary":"\u003cp\u003e最近の身の回りの問題を突き詰めていくと、周波数、波長、波動、振動、といったものが重要なタームになってくる気がしている。「量子物理学」の領域で語られるようなやつ。\u003c/p\u003e","title":"周波数・量子物理学周辺に注目したい"},{"content":"村上龍「愛と幻想のファシズム」より。\nただ、俺だけは、変わっていない。強固なイデオロギーをもつシステムは、そこに参加する者を拘束して、変化することを強要するのだろう。彼らは、ある情報を受け取り、支配されたのだ。俺がメッセージを造り出した。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-12/","summary":"\u003cp\u003e村上龍「愛と幻想のファシズム」より。\u003c/p\u003e","title":"「愛と幻想のファシズム」より(8)"},{"content":"Gitで、例えば間違えて管理下におきたくないファイルをコミットしてしまった場合に、ファイルを残したまま管理外にしたいとする。\nこの段階で.gitignoreに書いても反映されないので、以下で対処。\n1. コミット済みのリソースを管理対象外にする リポジトリ内で以下コマンド実行。\n$ git rm -cached ファイル名 $ git rm -cached -r ディレクトリ名 この後コミットする。もちろん.gitignoreにも書いておこう。\n2. git addの取り消し まだコミットはしておらず、git addしただけのタイミングでは以下で対処。\n$ git reset ファイル名 $ git reset /ディレクトリ名/ ただし、一番最初に実行したgit addを取り消すには 1.と同様に git rm --cached xxxx を使うことになる。（レポジトリ内にリセット対象が存在しないため）\n気をつけているつもりでも、特に一番最初のタイミングは「うっかり」やっちゃいがちなんだよな。\n参考\ngit add の取り消し方法と、関連コマンドまとめ\nついでに.gitignoreの書き方。\n.gitignore\n# ディレクトリを無視 /ディレクトリ名/ # ファイルを無視 /ファイル名 先頭のスラッシュなしでファイル名のみ記述した場合、どのディレクトリかは問わない。スラッシュをつけた場合、.gitignoreが存在するディレクトリ内のファイルが対象となる。ワイルドカードや正規表現も使用可能。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/git-reset-tips/","summary":"\u003cp\u003eGitで、例えば間違えて管理下におきたくないファイルをコミットしてしまった場合に、ファイルを残したまま管理外にしたいとする。\u003c/p\u003e","title":"Gitで所定のリソースを管理対象外にする"},{"content":"TerraformでCodePipeline作成時、追加で必要な作業がある。全然意味わかってないけど、とにかくやるものらしい。\nAWSで、マネコンからリソース作成する時は必要なコネタ系リソースが裏で自動で設定されるが、API経由だとやってもらえないから関連する設定を記述する必要がある、というのはこれに限らずよくあること。これもそのひとつ。\nで、やることは。\nTerraformによりCodePipeline作成後：\nマネコン画面でパイプラインを選択 画面上部「編集」押下 何もせずに、画面上部「保存」押下 「パイプラインの変更を保存する」ポップアップ画面にて、「保存」押下\n#画面上部に「パイプラインが正常に保存されました。」メッセージが表示される。 これをパイプラインの数だけ繰り返す。ということで意味不明なんだが、とにかくやるんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-codepipeline-memo2/","summary":"\u003cp\u003eTerraformでCodePipeline作成時、追加で必要な作業がある。全然意味わかってないけど、とにかくやるものらしい。\u003c/p\u003e","title":"TerraformでCodePipeline - 要追加作業"},{"content":"TerraformでCodePipeline作成する時のオプション\u0026quot;PollForSourceChanges\u0026quot;の注意点。\nソースとなるCodeCommitの所定のブランチに変更がpushされたらパイプラインが走る、という前提。PollForSourceChangesは、ソースステージに対する変更をCodePipelineがポーリングするか or EventBridgeに検知させるかの定義。マネコンから作る場合は自動的に後者になる（関連リソースも自動で作成される）。Terraformの場合は明示的に指定する必要があり、EventBridgeに検知させるならfalseにしなければいけない。\n以下は以前の投稿 Terraform loop処理の応用編(2) - CI/CD にも載せたソース一部。PollForSourceChangesの値だけ変えてる。前回はEventBridgeの設定抜きにしていたから、trueだった。\n#################################### # CodePipeline #################################### resource \u0026#34;aws_codepipeline\u0026#34; \u0026#34;pipeline\u0026#34; { for_each = var.pipeline_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) role_arn = var.pipeline_role artifact_store { location = var.bucket type = \u0026#34;S3\u0026#34; } stage { name = \u0026#34;Source\u0026#34; action { category = \u0026#34;Source\u0026#34; configuration = { BranchName = \u0026#34;master\u0026#34; PollForSourceChanges = \u0026#34;false\u0026#34; #ここに注意！ RepositoryName = lookup(each.value, \u0026#34;repository_name\u0026#34;) } input_artifacts = [] name = \u0026#34;Source\u0026#34; namespace = \u0026#34;SourceVariables\u0026#34; output_artifacts = [\u0026#34;SourceArtifact\u0026#34;] owner = \u0026#34;AWS\u0026#34; provider = \u0026#34;CodeCommit\u0026#34; region = var.region run_order = 1 version = \u0026#34;1\u0026#34; } } stage { name = \u0026#34;Deploy\u0026#34; action { category = \u0026#34;Deploy\u0026#34; configuration = { ApplicationName = lookup(each.value, \u0026#34;app_name\u0026#34;) DeploymentGroupName = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) } input_artifacts = [\u0026#34;SourceArtifact\u0026#34;] name = \u0026#34;Deploy\u0026#34; namespace = \u0026#34;DeployVariables\u0026#34; output_artifacts = [] owner = \u0026#34;AWS\u0026#34; provider = \u0026#34;CodeDeploy\u0026#34; region = var.region run_order = 1 version = \u0026#34;1\u0026#34; } } } EventBridgeでソースとなるブランチの変更検知の設定をしている状態で、PollForSourceChanges = \u0026quot;true\u0026quot; だとどうなるか。二重にパイプラインが起動され、2回デプロイが走る。完全に無駄である。CloudWatchLogsでも、所定のブランチが存在しないとポーリング時にエラーとなり、延々とログに出力される。完全に無駄である\u0026hellip;。(なんか変だなと思いつつ放置してた)\n（追記） もうひとつ注意点あり。PollForSourceChanges = \u0026quot;false\u0026quot; にしてTerraformでパイプラインを作成した。これで二重実行はなくなるはずだ！と思いきや、そうではなかった。まだデプロイが重複している。パイプラインの履歴画面を見ると、同一のコミットに対してEventBridgeが二つ存在する。パラメータを変更したことにより、AWS側が勝手に判断してイベントルールを自動生成したのである。親切でやってるんだろうけどね\u0026hellip;、このマネージドルールを削除後にデプロイしたところ、やっと期待値になった。（デプロイは一回のみ）\n今書いてて思い出したけど、このマネージドルールに紐づくIAMロールも自動生成されるはず。そっちも削除する必要があるな。あぁ、面倒くさい。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-codepipeline-memo/","summary":"\u003cp\u003eTerraformでCodePipeline作成する時のオプション\u0026quot;PollForSourceChanges\u0026quot;の注意点。\u003c/p\u003e","title":"TerraformでCodePipeline - PollForSourceChangesの注意"},{"content":"ネタ以下のネタだけど、RDP（リモートデスクトップ）のショートカット。\nWindowsキー + R で、mstsc 入力\n","permalink":"https://ecnedaced-seirots.github.io/post/b/rdp-connect/","summary":"\u003cp\u003eネタ以下のネタだけど、RDP（リモートデスクトップ）のショートカット。\u003c/p\u003e","title":"リモートデスクトップのショートカット"},{"content":"Firefoxでソースを表示するには。\nツール -＞　ブラウザツール -＞ ページのソース\nまたは\n⌘ + U\nこれだけなんだけど、しばらく使わないと忘れてイラッとくるから。\nそれにしても、ここ数日救急サイレンの音多すぎるな\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/b/firefox-show-source/","summary":"\u003cp\u003eFirefoxでソースを表示するには。\u003c/p\u003e","title":"Firefoxでソースを表示"},{"content":"サクラエディタで、一時的にコメント入れるとか先頭列だけ置換したいとき。\n1. ファイル全体行をコメントアウトする Ctrl + Rで置換ボックスを開き、入力欄に以下を入力する。\n置換前：^ 置換後: # （変換したい文字何でも） 下のチェックボックスで「正規表現」にチェックを入れ、「すべて置換」押下。\nこれでファイル全体の行頭に#が入る。\n戻す時\n置換前：^# 置換後: （何も入力しない） 同様に「すべて置換」で元に戻る。\n2. ファイルの一部数行だけをコメントアウトする Altを押しながら、変更したい行の先頭1列分だけ選択する。\nその状態でshift + 「#」押下　-＞ 選択部分のみ#が投入される。\n戻す時 Altを押しながら戻したい行の先頭1列分だけ選択する。その状態で「Backspace押下」で元に戻る\nあまり使わないと思うが、行末で同じことやりたかったら「$」。\n参考\n【サクラエディタ】正規表現を使った置換で行頭、行末に文字列を追加する方法\n","permalink":"https://ecnedaced-seirots.github.io/post/b/sakura-replace/","summary":"\u003cp\u003eサクラエディタで、一時的にコメント入れるとか先頭列だけ置換したいとき。\u003c/p\u003e","title":"サクラエディタで先頭列を置換する"},{"content":"村上龍初期エッセイ「アメリカン★ドリーム」より。\n進化の原動力となるのは、常に異端者、はじきとばされたもの達なんだ。要するに、環境に適応できないものが未来を背負うことになる。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-11/","summary":"\u003cp\u003e村上龍初期エッセイ「アメリカン★ドリーム」より。\u003c/p\u003e","title":"「アメリカン★ドリーム」より (1)"},{"content":"ここしばらくワクネタやらその周辺やら追ってばかりいて、憂鬱になってしまう。ちょっと離れないとな。\nhugoブログ書きたかったけど何やかんやで書けなかった。「普通の感覚」を思い出す必要がある。\nずっと昔に旅行した尾道の展望台から。銀塩だからモヤっとしてるけど。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/travel-0001/","summary":"\u003cp\u003eここしばらくワクネタやらその周辺やら追ってばかりいて、憂鬱になってしまう。ちょっと離れないとな。\u003c/p\u003e","title":"小休止"},{"content":"技術記事書きたいけどいろいろありすぎて書けない。ここしばらく憂鬱なネタばかり触れてるから、少しでも上向きなことを。\n何か誘われたり招待されたときの返答として、こんなの。\nI\u0026rsquo;d be glad to.（喜んで）\nいいね、こういう、人の笑顔が目に浮かぶような言葉。\n何が何でも戦い続けなければいけない、けれどそのためには、平常心、平穏な気持ちを保つことが何よりも重要なのだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/english-glad-to/","summary":"\u003cp\u003e技術記事書きたいけどいろいろありすぎて書けない。ここしばらく憂鬱なネタばかり触れてるから、少しでも上向きなことを。\u003c/p\u003e","title":"英語メモ - I'd be glad to."},{"content":"Pythonで、区切り文字の最後の要素を取得する。「要素」と言ってるのは、一旦リストにする必要があるため。\n例えば、'/path/to/document' から、\u0026ldquo;document\u0026quot;だけ抽出したい場合。\n#文字列を一旦リストにする str = \u0026#39;/path/to/document\u0026#39; doc_list = str.split(\u0026#39;/\u0026#39;) print(doc_list) [\u0026#39;\u0026#39;, \u0026#39;path\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;document\u0026#39;] #[-1]により、リストから最後の値を取得 doc_name = doc_list[-1] print(doc_name) document 参考\nPythonのsplit関数で文字列分割して最後の要素を取得する方法を現役エンジニアが解説\n","permalink":"https://ecnedaced-seirots.github.io/post/b/python-get-last-string/","summary":"\u003cp\u003ePythonで、区切り文字の最後の要素を取得する。「要素」と言ってるのは、一旦リストにする必要があるため。\u003c/p\u003e","title":"Pythonで区切り文字の最後の要素を取得"},{"content":"Amazon CloudWatch AgentはLinuxとWindowsでかなり仕組みが異なるところがあるので注意がいる。\nディスク監視閾値の違い 例えば、ディスク使用率監視の閾値はLinux/Windowsで異なる。Linuxの場合、例えばディスク使用率70%超過でアラームになるとしたら初期値は0。（これが普通）。Winは逆で、初期値が100なのだ！まったく使用されていない時が100で、使い切ったら0になる。ゆえに、ディスク使用率が実際は30%の場合は70になる。（70に「下降」する）ややこしい\u0026hellip;\nディスク使用率70%を超えたらアラームとする例\nLinuxの閾値：70より上 Windowsの閾値：30より下 設定ファイル読み込み時の違い Linuxの場合、以下コマンドでJSON設定ファイルを読み込む必要がある。Windowsはいらない。\n$ sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -s -c file:/opt/aws/amazon-cloudwatch-agent/bin/cw-agent.json また、LinuxではJSON設定ファイルを複数対象にすることが可能だがWindowsはそれができない。\nLinuxの場合、設定変更を行なった都度上記コマンドを実行するが、複数の設定ファイルが存在する場合は-aオプションの値が異なってくる。初回は-a fetch-configとし、それ以降は-a append-configとする。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/cloudwatch-agent-tips/","summary":"\u003cp\u003eAmazon CloudWatch AgentはLinuxとWindowsでかなり仕組みが異なるところがあるので注意がいる。\u003c/p\u003e","title":"CloudWatch Agent: LinuxとWindowsの違い"},{"content":"\u0026ldquo;Freedom Convoy\u0026quot;はひと言で言うと、カナダのトラック運転手のワクチン強制接種反対の運動。\n2月12日の投稿\nこのトラック運転手の反乱がどのように終わるのか、わかった気がする。@ezralevant\n（上記元ネタのツイ）\n2月6日の投稿\nフリーダムコンボイ　国民へのメッセージ – 2022年2月6日「緊急事態アップデート」｜IrnieracingNews\nそして、トラック運転手たちがプラットフォームを作ってくれたおかげで、科学の真実を語っている医師たちやブリーフ、ドクターたちが活動できるようになりました。\nすっげぇ\u0026hellip;！\n運動は海外に飛び火している。現状ほぼフランスのニュースだけしか入ってこないが、他でもやっているんだろうか。頑張れ\u0026hellip;.！！\nなかなか興味深いサイトだが、日本語は機械翻訳。もともとアルツハイマー関連の情報発信してた？ https://alzhacker.com/\nTwitterアカウント\nAlzhacker\n","permalink":"https://ecnedaced-seirots.github.io/post/b/freedom-convoy/","summary":"\u003cp\u003e\u0026ldquo;Freedom Convoy\u0026quot;はひと言で言うと、カナダのトラック運転手のワクチン強制接種反対の運動。\u003c/p\u003e","title":"カナダ及び各国のFreedom Convoyに注目"},{"content":"2022年2月イタリアの現実を、現地在住日本人が伝えている。\n最近国内では欧州各国で規制が緩和されつつあるような報道があったが、現地の実情はまったく違うとのこと。SNSなんかチラ見してると「海外では規制撤廃の動きがあるのに、日本は決断できない！だからダメなんだ！」といった論調が多い。君たちはまだ読みが浅い。\n以下動画の発言より一部要旨抜粋。\n規制緩和といってもスーパーグリーンパス保持者が、ほんの少し行動が緩和されるだけ。\n未接種者が立ち入り許可されるのはスーパーと薬局だけ、他の商店は利用できない、バールやレストラン、郵便局もダメ（抜け道はあるらしい）、2月15日から50才以上摂取義務化。未接種者は仕事できない、年金ももらえないと。マスクはFFP2タイプでないとダメ（こいつが相当ヤバそう）。\nイタリア全土で三分の一のホテルが閉館している。かろうじて営業しているホテルも宿泊客がほとんどいなくて閑古鳥状態、いつまで持つかわからない。レストランも全然お客がこない。\n未接種者は行動を制限されているが、お店やレストラン側もスーパーグリーンパスのチェックによってトラブルが起きたり売り上げが減るのはデメリットなので、その辺は適当に対応するケースもある。政府の命令にひたすら従順に従う層と、反発して独自の方針で営業する層で二分化している。\n\u0026hellip;とまぁ、赤裸々な事実を伝えてくれている。最近のイタリアの実情については研究者 荒川宏氏のnote(*1)にも詳しく書かれていたが、動画で語っているのを聞くとさらにリアリティが迫ってくる。\nカナダのトラック運転手の運動についてここでも話題になっている。欧州でも同類の動きはあるが、具体的な話題が聞こえてこない、ただヒントみたいなのはあったとか。14日のブリュッセルに注目。国内メディアはどうせまともに伝えないだろうけど。\nそれと、動画の最初の方では先日死去したリュック・モンタニエ博士（Luc Montagnier）について語っている。エイズウイルスを発見したノーベル賞学者である。当初ワクチン推進派だったが去年5月頃反対派に転向したらしい。そういえば最近の動きとしてHIVワクチンの開発のニュースがあったな。「そういうこと」なんだろうか？\n動画は以下より。\n“狂気のイタリア続報と悲しい知らせ【モンタニエ博士訃報】” イタリアの食卓　Miho’s kitchen 関連記事\nモンタニエの心変わりが示すこと\n【追悼】モンタニエ博士が急逝　ワクに警笛を鳴らし続けた\n(*1) 荒川氏のブログより。\nまた、グリーンパスのためのワクチン接種後の有効期限の間隔は9ヶ月から6ヶ月に短縮されました。それでも疑問視せず、抵抗しない人が多いです。2022年1月17日現在、イタリアのワクチン接種者は81.9%。イタリア人の国民性は意外にもかなり従順です。\nコロナ禍により世界中で経済も人々の暮らしも疲弊しています。「人は病だけでなく、経済でも命を落とす」という言葉がありますが、まさにその通りだと思います。実際に現在進行形で人々の生活の破壊が進んでいるわけです。コロナ騒動を自分の利益の為に企図した少数の人間がいるとしても、結局のところ実際に人々の生活を破壊しているのは無意識的に騒動に自分から加担している人々ではないでしょうか。疑問を持たず、盲目的に従う行為こそが自分達の暮らしを破壊しているのではないでしょうか。\nディストピアを作り上げるのは、疑う事を知らず、命令、要請、多数派に従う一人一人の人間です。世界中で多くの人が自主的に放棄しているのは、自由であり、健康であり、命です。\nコロナワクチンをめぐるイタリアの状況について\n「疑う事を知らず、命令、要請、多数派に従う一人一人の人間」。こういうところは、イタリアも日本も大して変わらんな。イタリアでは大規模デモも起きてるから、違うところもあるけど。\nこの地獄絵図がいつ終わるのか、終わりが来ないのか、わからない。しかし終わったとしても、世界は決して2020年以前のようには戻らない、ということだけはわかる。動画を見て、もうEUに足を踏み入れることは生涯ないかもしれないな、と本気で思った。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/italy-now-and-luc-montagnier/","summary":"\u003cp\u003e2022年2月イタリアの現実を、現地在住日本人が伝えている。\u003c/p\u003e","title":"イタリアの現状と、リュック・モンタニエ博士の急逝"},{"content":"数年前からずっと飲んできた、ソラレー社(Solaray)のマグネシウム・グリシネートが生産停止になってしまった。最後に購入したのは去年の11月だ。\nでもってiHerbで他メーカーを検索したら、ほぼ在庫切れ！！ちなみにグリシネート（グリシン酸）じゃないやつは普通に在庫あり。ということは\u0026hellip;..、グリシン酸マグネシウムがワク解毒に効くということだな。(*1)\n吸収がいいから？グルタチオンの原料グリシンが入っているから？ここにきて生産停止って裏で何かあるんか？俺はずっとSolarayのMagnesium Glycinate一本だった。あぁ、それなのに\u0026hellip;。\nマグネシウムには複数の種類がある。グリシン酸マグネシウムは現状ほぼ全メーカーで入手不可になっているが、まだ生産中止したわけじゃない。しかしいつ全面的に生産中止に追い込まれるかわからないから、他の種類について備忘録をしたためておく。\n4種類のマグネシウムから自分の目標に合ったものを選ぶ方法\n上記の記事によると、以下の順でお勧めらしい。やっぱりグリシン酸マグネシウムが一番いいんだね。酸化マグネシウムは勧めていない。\nグリシン酸マグネシウム クエン酸マグネシウム 炭酸マグネシウム 酸化マグネシウム 酸化マグネシウムはバイオアベイラビリティ（吸収率）が低いため、他のマグネシウムよりも有効量を増やす必要があると思われます。つまり、摂取量をかなり増やさないと効果が得られないため、消化器系の副作用が出る可能性が高くなるということです。\n酸化マグネシウムは安価だが、有効量を吸収するためには多めに摂取する必要があり、かつ消化器系に負担がかかる。安価でも高コストになってしまう。グリシン酸マグネシウムは若干高価だが吸収率がよく、機能が優れている。どちらがコストパフォーマンスが高いかといえば、後者になるね、サプリメントに限らずいろんなことに言えるけど。\nポストする前に未練がましく海外情報漁って見たら、パッケージとか容量は異なるがまだSolarayでMagnesium Glycinateを生産販売しているのを発見！（ここ）\n\u0026hellip;だけどiHerbでは売ってないみたいだ。（未練）\n代わりにこんなん見つけた。グリシン酸じゃないけどこれも良さげ。カリウムとブロメラインがスタックされている、今度試してみよう。今月すでにiHerb破産しそうな勢いだから、来月にでも。\nSolaray, マグネシウムカリウムアスポロレート、植物性カプセル120粒 (*1) グリシン酸マグネシウム品薄の理由、後日たまたま以下の記事読んで判明した。グリシン酸マグネシウムは、「グルタチオン合成を促進する補助因子」となる栄養素だった！\nグルタチオンを増やす8つの戦略\n","permalink":"https://ecnedaced-seirots.github.io/post/b/magnesium-suppliment/","summary":"\u003cp\u003e数年前からずっと飲んできた、ソラレー社(Solaray)のマグネシウム・グリシネートが生産停止になってしまった。最後に購入したのは去年の11月だ。\u003c/p\u003e","title":"グリシン酸マグネシウムが入手困難！"},{"content":"Pythonの辞書・文字列変換と、JSON処理。必須項目でしょっちゅう使うくせに覚えられない\u0026hellip;\n辞書 ＜\u0026ndash;＞　文字列変換基本 辞書から文字列に変換（dict -＞ string）： json.dumps()\n文字列から辞書に変換（string -＞ dict）： json.loads()\njson.loads() とjson.load()は似ているが違うもの。json.load()はJSON形式のファイルを読み込むために使う。\nJSON読み込み例 以下、CloudWatchアラームの閾値超え発生時イベントの中身をファイルに保存したのを呼び出している。json.load()で呼び出した時点で、このオブジェクトは辞書型であり、それをjson.dumps()で文字列に変換している。\n\u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; path = \u0026#34;event_sample.json\u0026#34; \u0026gt;\u0026gt;\u0026gt; with open(path, encoding=\u0026#34;utf-8\u0026#34;, mode=\u0026#34;r\u0026#34;) as f: ... event = json.load(f) ... msg = json.dumps(event, indent=3) ... print(msg) ... { \u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;86fa8a3f-7470-8c16-ef56-aaba9821771e\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;CloudWatch Alarm State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.cloudwatch\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;012345678910\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-02-03T10:17:51Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [ \u0026#34;arn:aws:cloudwatch:ap-northeast-1:012345678910:alarm:CPU_Utilization_Test\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;alarmName\u0026#34;: \u0026#34;CPU_Utilization_Test\u0026#34;, \u0026#34;state\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;ALARM\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Threshold Crossed: 1 out of the last 1 datapoints [100.0 (03/02/22 10:11:00)] was greater than the threshold (10.0) (minimum 1 datapoint for OK -\u0026gt; ALARM transition).\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2022-02-03T10:17:51.018+0000\\\u0026#34;,\\\u0026#34;startDate\\\u0026#34;:\\\u0026#34;2022-02-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[100.0],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2022-02-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;sampleCount\\\u0026#34;:5.0,\\\u0026#34;value\\\u0026#34;:100.0}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-02-03T10:17:51.020+0000\u0026#34; }, \u0026#34;previousState\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;INSUFFICIENT_DATA\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Insufficient Data: 1 datapoint was unknown.\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2022-02-03T10:13:51.019+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2022-02-03T10:13:00.000+0000\\\u0026#34;}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-02-03T10:13:51.023+0000\u0026#34; }, \u0026#34;configuration\u0026#34;: { \u0026#34;metrics\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;4cbe7286-d70f-fcb9-4a0a-758612d568db\u0026#34;, \u0026#34;metricStat\u0026#34;: { \u0026#34;metric\u0026#34;: { \u0026#34;namespace\u0026#34;: \u0026#34;AWS/EC2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: { \u0026#34;InstanceId\u0026#34;: \u0026#34;i-01234567891012345\u0026#34; } }, \u0026#34;period\u0026#34;: 60, \u0026#34;stat\u0026#34;: \u0026#34;Maximum\u0026#34; }, \u0026#34;returnData\u0026#34;: true } ] } } } イベントの中身を抽出するためにやってるんだけど、JSONの保存形式に不正があるとエラーになったりして面倒くさい。Lambdaにイベント渡している場合、LambdaのロググループをLogs Insightsでクエリかけると項目毎に見やすく整型されて画面表示してくれる。だからそっちで確認してもいいのだが\u0026hellip;、やはりJSONデータとして見たい時もあるんだよな。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/python-json-dumps-load/","summary":"\u003cp\u003ePythonの辞書・文字列変換と、JSON処理。必須項目でしょっちゅう使うくせに覚えられない\u0026hellip;\u003c/p\u003e","title":"Pythonの辞書・文字列変換とJSON処理"},{"content":"村上龍著「愛と幻想のファシズム」より\nシステムに包囲されていることに変わりはないのだ。火星に移住しても同じだ。きっとウイッツもそのことを知っているはずだ。幻のエルクと同化するしかない。増殖するシステムの中心にいること、つまり支配するシステムを常に増殖させることだ。\n1983年に書かれたこの小説の中で、村上龍は2022年を予言した。ここで言う「システム」が何を表しているか、今ほどリアルに、骨身に沁みてわかる時はなかっただろう。「システム」が、ここまで具体的に正体を表したこともなかった。奴らは、本気なのだ。\n2022年の今、人類は「愛と幻想のファシズム」と「コインロッカーベイビーズ」と「フィジーの小人」と「だいじょうぶマイ・フレンド」と「５分後の世界」と「ヒュウガ・ウイルス」が、混沌と混ざり合いながら具現化した世界に生きている。（これに、少し昔に公開された和製SFエログロホラー映画「アナザヘヴン」を加えてもいいな、「時計じかけのオレンジ」もね）\nこの異常な世界。だけど俺は、鈴原冬二とキクとミズノ少尉を心に秘めて生き抜いてやる。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-10/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e","title":"「愛と幻想のファシズム」より(7)"},{"content":"Go言語のSwitch文による条件分岐例など。\n基本構文。まぁ説明するまでもない。\nswitch 条件 { case A: 処理コードA case B: 処理コードB case C: 処理コードC default: デフォルト処理 } サンプル。引数を与えて、その値によって処理を分岐させる。\nswitch1.go\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { flag.Parse() //条件の値となる引数を定義。 city := flag.Arg(0) //引数の値に応じて処理 switch city { case \u0026#34;Tokyo\u0026#34;: fmt.Println(\u0026#34;住んでいます。\u0026#34;) case \u0026#34;Bangkok\u0026#34;: fmt.Println(\u0026#34;一度行ったことがあります。\u0026#34;) case \u0026#34;NY\u0026#34;: fmt.Println(\u0026#34;行ったことないです。\u0026#34;) default: fmt.Println(\u0026#34;いつか行きたいです。\u0026#34;) } } 結果。\n$ go run switch1.go Tokyo 住んでいます。 $ go run switch1.go NY 行ったことないです。 $ go run switch1.go Bangkok 一度行ったことがあります。 $ go run switch1.go Havana いつか行きたいです。 参考\n【Go入門】switchによる分岐 ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-switch/","summary":"\u003cp\u003eGo言語のSwitch文による条件分岐例など。\u003c/p\u003e","title":"Go入門(13) - Switch文による条件分岐"},{"content":"OpenCV(Python)で、グレースケールの出力と画像ファイルの保存をしてみる。\n1. グレースケールの出力 import cv2 #ファイル読み込み img = cv2.imread(\u0026#39;img_01.png\u0026#39;) #グレースケールの定義 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # 画像を出力 cv2.imshow(\u0026#39;Yellow\u0026#39;, img) #オリジナル cv2.imshow(\u0026#34;gray\u0026#34;, gray)　#グレースケール while True: # Escキー入力で終了 if cv2.waitKey(1) == 27: break cv2.destroyAllWindows() こんな感じになる。escキー入力で閉じる。\n2. 画像を保存する import cv2 #ファイル読み込み img = cv2.imread(\u0026#39;img_01.png\u0026#39;) #グレースケールの定義 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #別名のファイルとして保存 outfile = cv2.imwrite(\u0026#39;img_gray.png\u0026#39;, gray) if outfile: print(\u0026#39;Image is successfully saved.\u0026#39;) 結果、Image is successfully saved.が出力され、同じディレクトリにグレースケールに変換された img_gray.pngが保存された。こういうのやってると、ImageMagickをいじっていた頃を思い出すな\u0026hellip;（遠い昔）\n参考\nPythonによる画像処理に利用するライブラリを現役エンジニアが解説【初心者向け】\nPython OpenCV cv2.imwrite() – Save Image\n","permalink":"https://ecnedaced-seirots.github.io/post/b/python-opencv-2/","summary":"\u003cp\u003eOpenCV(Python)で、グレースケールの出力と画像ファイルの保存をしてみる。\u003c/p\u003e","title":"OpenCVで画像ファイルを保存する"},{"content":"Goで文字列を連結したい場合、複数のやり方があるがパフォーマンスの良し悪しが関連してくる。\nどの言語でも使われる + で連結するのはコスト効率が悪いので大量に処理する時には向かないようだ。以下のコードでは(4)〜(6)の方式が性能的に効率がいいらしい。ま、ちょろっとした処理なら(1)や(2)でいいっしょ、て思うけど。(7)はオマケ的なやつ。\nappend_str.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;bytes\u0026#34; ) func main() { //(1) +で連結する name1 := \u0026#34;Quentin\u0026#34; + \u0026#34; \u0026#34; + \u0026#34;Tarantino\u0026#34; fmt.Println(name1) //(2) fmtパッケージのprint関数では引数の複数文字列を自動的に連結する。 fmt.Println(\u0026#34;Pulp\u0026#34;, \u0026#34;Fiction\u0026#34;) //(3) stringsパッケージのjoin()関数を使う sampleSlice := []string{\u0026#34;Directed\u0026#34;, \u0026#34;by\u0026#34;, \u0026#34;Quentin\u0026#34;, \u0026#34;Tarantino\u0026#34;} result := strings.Join(sampleSlice, \u0026#34; \u0026#34;) fmt.Println(result) //(4) バイトバッファによる文字列連結 var sample bytes.Buffer sample.WriteString(\u0026#34;Martin \u0026#34;) sample.WriteString(\u0026#34;Scorsese\u0026#34;) fmt.Println(sample.String()) //(5) strings Builderメソッドによる文字列連結 var sb strings.Builder sb.WriteString(\u0026#34;Taxi \u0026#34;) sb.WriteString(\u0026#34;Driver\u0026#34;) fmt.Println(sb.String()) //(6) []byte型の値に文字列を足していって連結 b := make([]byte, 0, 10) //サイズ0、内部バッファの長さ10byteの割り当て b = append(b, \u0026#34;Directed \u0026#34;...) b = append(b, \u0026#34;by \u0026#34;...) b = append(b, \u0026#34;Martin \u0026#34;...) b = append(b, \u0026#34;Scorsese\u0026#34;...) fmt.Println(string(b)) fmt.Println(\u0026#34;...\u0026#34;) //(7) 文字列繰り返し fmt.Println(strings.Repeat(\u0026#34;Blah \u0026#34;, 3)) } 結果\nQuentin Tarantino Pulp Fiction Directed by Quentin Tarantino Martin Scorsese Taxi Driver Directed by Martin Scorsese ... Blah Blah Blah 参考\nGolangで文字列を連結する7つの方法 （いろいろ紹介してくれてるけど動作しないコードがあった\u0026hellip;）\nGoでは文字列連結はコストの高い操作 （[]byte例）\nGo言語で効率良く文字列を連結する話 #golang （bytes.Buffer例）\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-append-string/","summary":"\u003cp\u003eGoで文字列を連結したい場合、複数のやり方があるがパフォーマンスの良し悪しが関連してくる。\u003c/p\u003e","title":"Go入門 (12) - Goで文字列を連結するいくつかの方法"},{"content":"迷惑サジェスト その１ Outlookで「登録名の先頭の数文字の入力で候補を表示する」を無効にしたい。\nなんのことかと言うと、Outlookのメールで「自分の苗字を入れると勝手に名前が補完される」やつ。登録名だから企業内ルールで表示される書式が変わってくると思うけど、とにかくうざい、いらんのだ。\n「ファイルタブ」 -＞　「オプション」 「メール」-＞　「スペルチェックとオートコレクト」-＞ 「詳細設定」 一覧から「登録名の先頭の数文字の入力で候補を表示する」のチェックを外す 迷惑サジェスト その2 その1より極悪な、Excelのオートコンプリート。シート内で同じ文字から始まる文章を勝手に自動入力するやつ。それを消すのに余計に手間がかかる。嫌がらせレベルである。\n「ファイル」タブ -\u0026gt; 左下の「その他」-＞「オプション」 左側「詳細設定」-\u0026gt; 「オートコンプリートを使用する」のチェックを外す 参考\nOutlookメール書くときに鬱陶しいサジェストをオフにする\n【Excel】おせっかい機能を無効化したい！邪魔な入力候補や勝手にデータを変える機能をオフにするテク\n（追記）\nこれだけでは足りなかった。英文字の先頭を勝手に大文字にしたり2文字目以降を勝手に小文字にしたり、余計なことばかりしやがって。単語全部小文字にしたり、2文字目も大文字にしたい時だってあるんだよ！！（相当控えめに言ってるが内心怒り心頭）\nこの嫌がらせをやめさせるには、先述の手順2.で「文章校正」を選択。表示された「オートコレクトのオプション」画面で、不要な操作のチェックを外す。「2文字目を小文字にする」を真っ先に外したが、よく見たら他の項目も全部いらんかったから全部さっぱりと外しましたぜ！！\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ms-outlook-excel-disable-suggest/","summary":"\u003ch3 id=\"迷惑サジェスト-その１\"\u003e迷惑サジェスト その１\u003c/h3\u003e\n\u003cp\u003eOutlookで「登録名の先頭の数文字の入力で候補を表示する」を無効にしたい。\u003c/p\u003e","title":"MS Officeの邪魔なサジェストを無効にする"},{"content":"AWS CodeDeployでVPCエンドポイントを使用する場合は一手間必要なのでその辺のネタを。\n今時だと大抵のEC2インスタンスはプライベートサブネットに配置されているので、VPC外に通信する場合はNATゲートウェイ・プロキシ・VPCエンドポイントいずれかを通って出ていくことになる。最初の2つは気にしなくていいのだが、VPCエンドポイントの場合は別途追加対応が必要なのである。\n事象 codedeploy-agentが再起動を繰り返していて、こんなエラーを吐いていた。\nErrorno:: ENETUNREACH - Failed to open TCP connection to 169.254.169.254:80 (Network is unreachble \u0026hellip;\nERROR [codedeploy-agent(2100)]: booting child: error during start or run: SystemExit - exit - \u0026hellip;\nさらに、cloudwatch-agentのログにもこんなエラーが大量の吐き出されていた。codedeployのログよりこっちの方がすごかった。\nERROR [codedeploy-agent(4492)]:Error validating the SSL configuration: Invalid server certificate (snip)\nERROR [codedeploy-agent(2100)]: booting child: error during start or run: SystemExit - Stopping CodeDeploy agent due to SSL validation error. (snip)\nメッセージから見ると通信に失敗しているのは明らかなのだが、別環境の検証時は問題なく動いていた。しかしその時はNATゲートウェイを使用していた。VPCエンドポイントに切り替えた環境で、上記エラーが発生したのだ。\nやったこと 調べた結果、追加で以下の設定が必要と判明。\ncodedeployagent.yml\n:enable_auto_policy:true #デフォルトはfalse ファイルパス\nLinux: /etc/codedeploy-agent/conf/codedeployagent.yml\nWindows: C:¥ProgramData¥Amazon¥CodeDeploy¥conf.yml\nこれで起動状態は正常になってエラーも解消した。しかし、追加のIAMポリシーがないとデプロイ時に権限が足りないと怒られて失敗する。エージェントが動作するEC2にアタッチしているIAMロールに、以下の権限が必要なのである。\n{ \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy-commands-secure:GetDeploymentSpecification\u0026#34;, \u0026#34;codedeploy-commands-secure:PollHostCommand\u0026#34;, \u0026#34;codedeploy-commands-secure:PutHostCommandAcknowledgement\u0026#34;, \u0026#34;codedeploy-commands-secure:PutHostCommandComplete\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 対象IAMロールに上記ポリシー追加後、デプロイが成功した。ネットワーク環境の違いって何かと影響でかいんだよな\u0026hellip;、まぁそんなに疲れるネタじゃなかったからいいけど。\nオマケ：CodeDeployのエンドポイントと疎通確認するには以下コマンドで。\n$ curl -v https://codedeploy-commands.ap-northeast-1.amazon.com 参考\nCodeDeployエージェント構成リファレンス\nAmazon Virtual Private Cloud で CodeDeploy を使用\n【AWSの呼吸 弐ノ型】CodeDeployでVPCエンドポイントを設定する\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-codedeploy-vpc-endpoint/","summary":"\u003cp\u003eAWS CodeDeployでVPCエンドポイントを使用する場合は一手間必要なのでその辺のネタを。\u003c/p\u003e","title":"AWS CodeDeployでVPCエンドポイント使用時の注意"},{"content":"CloudWatch Logs Insightsで、秒毎のログイベント数をカウントしたい時。すっげぇ簡単なんだけどすぐ忘れるから。\nログストリームと時間範囲指定後、以下クエリを実行する。sをm,hにして分毎、時間毎のカウントとしてもよい。\nfileds @timestamp, @message | sort @timestamp desc | stats count(*) by bin(1s) あとおまけで、「フィルタキーワードのor条件 + 大文字小文字区別しない」パターン。\nfileds @timestamp, @message | filter @message like /(?i)(error|fail|exception)/ | sort @timestamp desc 以下にすると、該当ログイベントを含むログストリーム数をカウントする。\nfileds @timestamp, @message | filter @message like /(?i)(error|fail|exception)/ | sort @timestamp desc | stats count(*) by @logStream こないだちょっと思ったのが、キーワード\u0026quot;hoge\u0026quot;を含むログのみ絞り込んで、その中でかつerrorが出力されているものを抽出したい時はどうればいいんだろう、と。こう言う時にparseが使えるんだろうか？いいかげんparse覚えたい。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/cloudwatch-logs-insights-bin/","summary":"\u003cp\u003eCloudWatch Logs Insightsで、秒毎のログイベント数をカウントしたい時。すっげぇ簡単なんだけどすぐ忘れるから。\u003c/p\u003e","title":"Logs Insightsで秒毎のログイベント数をカウントするクエリ"},{"content":"文字列から数値 or 数値から文字列。Goでこのように型を変更するには、strconvを使う。\nchangetype.go\npackage main import ( \u0026#34;strconv\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { //文字列から数値に変換(string -\u0026gt; int) var i int var str string=\u0026#34;100100\u0026#34; i, _ = strconv.Atoi(str) //変換後の値を出力 fmt.Println(i) //変換後の型を出力 fmt.Printf(\u0026#34;%T \\n\u0026#34;, i) fmt.Println(\u0026#34;---------------\u0026#34;) //数値から文字列に変換(int -\u0026gt; string) var i2 int=200200 var str2 string str2 = strconv.Itoa(i2) //変換後の値を出力 fmt.Println(str2) //変換後の型を出力 fmt.Printf(\u0026#34;%T \\n\u0026#34;, str) } 結果\n100100 int --------------- 200200 string ちなみに変数の定義方法は以下でもいいのだが（ただし関数内に限る）、どっちにしても3行必要なんだな。\ni := 100100 var str string str = strconv.Itoa(i) 参考\ngolang　文字列→数値、数値→文字列変換\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-changetype/","summary":"\u003cp\u003e文字列から数値 or 数値から文字列。Goでこのように型を変更するには、\u003ccode\u003estrconv\u003c/code\u003eを使う。\u003c/p\u003e","title":"Go入門(11) - 型変換(str-int, int-str)"},{"content":"村上龍 対談集「最前線」〜「サッカーを通して見える日本と世界」より。\n村上 - 金子さんはスペインにいてサッカーの取材をしてきたわけですが、バルセロナと日本のズレというのはとんでもないものがあるでしょう。\n金子 - 向こうに住んで一番よかったのは、難しい言い方をすると、30歳すぎてこてんぱんにやられたってことですね。外国に住んだことのある人はみなさんお感じになると思いますけど、オピニオンのないやつは人間扱いされない。敵のない人間は味方もいない、みたいな。\n（村上龍 x 金子達二）\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-9/","summary":"\u003cp\u003e村上龍 対談集「最前線」〜「サッカーを通して見える日本と世界」より。\u003c/p\u003e","title":"村上龍 対談集「最前線」より"},{"content":"コマンドライン引数を受け取って処理。どの言語でもやるけどGoはどうするんだろう、と思って軽く調べてみた。\nざっくり言うと引数を扱うにはosパッケージとflagパッケージの2種類があり、どちらかを使う。flagは色々と細かい制御ができて便利、らしい。しかし説明やコードを読んで理解するのが面倒なんである。今は簡単なことができればいいのである。というわけで、今回面倒なことは書かない。いつも書かないけど。\nargs1.go\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { flag.Parse() //引数の値を出力 fmt.Println(flag.Args()) //特定の要素を取り出して出力 arg1 := flag.Arg(0) arg2 := flag.Arg(1) fmt.Println(arg1) fmt.Println(arg2) //要素の型と値を出力 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, arg1, arg1) fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, arg2, arg2) //変数argに引数を代入 args := flag.Args() //引数の値を出力 //fmt.Println(args) //引数の型を出力 fmt.Printf(\u0026#34;%T\\n\u0026#34;, args) //引数の型と値を出力 fmt.Printf(\u0026#34;%T, %v\\n\u0026#34;, args, args) } 結果\n$ go run args1.go blue green red [blue green red] blue green string, blue string, green []string []string, [blue green red] 一番知りたかったのは「引数の特定の要素を取り出す」という、非常に単純しかし絶対よく使う方法なんだが、検索の仕方が悪いのか知らんが見つけるのに妙に手間取った。\nちなみに引数に数値を指定しても型はstringである。通常は受け取ってからintに変換とかやるけど、flagの機能を使えば渡す時点でうまいことやってくれるのかな。\n次、os.Args()の例。os.Argsはstring型のスライス。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { //引数の要素数を出力 fmt.Printf(\u0026#34;args count: %d\\n\u0026#34;, len(os.Args)) //コマンド名と要素の値全てを出力 fmt.Printf(\u0026#34;args : %#v\\n\u0026#34;, os.Args) //要素の個別の値を出力 //arg[0]は実行内容であり、実際の引数はarg[1]以降になる。 for i, v := range os.Args { fmt.Printf(\u0026#34;args[%d] -\u0026gt; %s\\n\u0026#34;, i, v) } } 実行結果。実行環境がMacだとこんなパスが表示されるが、これがコマンドの実体ということになる。（xxxxxxはランダム文字列/数値）\n$ go run args2.go blue green red args count: 4 args : []string{\u0026#34;/var/folders/14/xxxxxxx/T/go-buildxxxxxxx/b001/exe/args2\u0026#34;, \u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;red\u0026#34;} args[0] -\u0026gt; /var/folders/14/xxxxxxx/T/go-buildxxxxxxx/b001/exe/args2 args[1] -\u0026gt; blue args[2] -\u0026gt; green args[3] -\u0026gt; red 参考\ngolang でコマンドライン引数を使う\nGo言語 - os.Argsでコマンドラインパラメータを受け取る\nGoでflagを使ってコマンドライン引数を扱う\n【Go入門】型（type）を調べる – %T と Printf() ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-command-args/","summary":"\u003cp\u003eコマンドライン引数を受け取って処理。どの言語でもやるけどGoはどうするんだろう、と思って軽く調べてみた。\u003c/p\u003e","title":"Go入門(10) - コマンドライン引数の処理"},{"content":"今時あまり流行らないが、「AMIを作り込んでEC2を起動」というサイクルを繰り返す運用があるとする。それをTerraformに組み込む場合の、AMIの参照方法。\nAMIを以下のようにデータソースとして定義する。実際のAMIの名前は更新する度にdev-example-20220130, dev-example-20220215\u0026hellip;と日付が付与されるとする。\n##################################################### # aws ami ##################################################### data \u0026#34;aws_ami\u0026#34; \u0026#34;ami_example\u0026#34; { most_recent = true owners = [\u0026#34;self\u0026#34;] fileter { name = \u0026#34;name\u0026#34; values =[\u0026#34;dev-example-*\u0026#34;] } } 先のAMIを参照してインスタンスを起動する例。以下のami行の記述により、AMI更新後も名前が「dev-example-*」のAMIを元にインスタンスを作成する。\n##################################################### # EC2 instance ##################################################### resource \u0026#34;aws_instance\u0026#34; \u0026#34;instance_example_001\u0026#34; { ami = ${data.aws.ami.ami_example.id}\u0026#34; availability_zone = \u0026#34;ap-northeast-1c\u0026#34; instance_type = \u0026#34;m5.large\u0026#34; vpc_security_group_ids = [var.example-sg] subnet_id = var.example-subnet-id iam_instance_profile = var.example-instance-prolie key_name = var.exapmple-key tags = { Name = \u0026#34;example-instance\u0026#34; } } ところでvpc_security_group_idsは以下のようにリストにしないとエラーになる。（[ ]で囲む）いつもそれを忘れてつまづいてしまう。idsと言うくらいだから複数アイテムを前提としているせいか？\n追記 この方式はapply時に更新したAMIでインスタンスを再作成する場合はいいのだが、そうしたくない場合もある。（更新前のAMIから起動したいとか）現在のインスタンスの中身を変えずに起動したい場合は、ami = ${data.aws.ami.ami_example.id}\u0026quot; としているのを、所定のAMI IDの定数に置き換える。\n参考\nResource: aws_instance\n","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-ec2-ami/","summary":"\u003cp\u003e今時あまり流行らないが、「AMIを作り込んでEC2を起動」というサイクルを繰り返す運用があるとする。それをTerraformに組み込む場合の、AMIの参照方法。\u003c/p\u003e","title":"Terraform - EC2インスタンス作成時のAMI参照"},{"content":"Go言語におけるif-else文の覚書。\n基本構文\nif 条件式 { 処理A } else { 処理B } 以下サンプル。\nif_else1.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { num := 15 var str string str = strconv.Itoa(num) //if-elseによる条件分岐 if num \u0026gt;= 10 { fmt.Println(str, \u0026#34;:\u0026#34;, \u0026#34;変数numは10以上です。\u0026#34;) //15 : 変数numは10以上です。 } else { fmt.Println(str, \u0026#34;:\u0026#34;, \u0026#34;変数numは10未満です。\u0026#34;) } } if文の条件の分岐を複数実行するには、else ifブロックを作って投入する。以下の条件に沿って処理が実行される。\n条件式Aが成立する場合は処理A 条件式Bが成立する場合は処理B これらの条件が成立しなかった場合は処理C ただし条件が成立した時点で処理が終了するため、記述方法には注意する。\nif 条件式A { 処理A } else if 条件式B { 処理B } else { 処理C } if_else2.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { num := 6 var str string str = strconv.Itoa(num) //if-else文で複数条件分岐するには、\u0026#34;else if\u0026#34;を挟む。 if num \u0026gt;= 10 { fmt.Println(str, \u0026#34;:\u0026#34;, \u0026#34;変数num は10以上です。\u0026#34;) } else if num \u0026gt;= 5 { fmt.Println(str, \u0026#34;:\u0026#34;, \u0026#34;変数num は5以上10未満です。\u0026#34;) //6 : 変数num は5以上10未満です } else { fmt.Println(str, \u0026#34;:\u0026#34;, \u0026#34;変数num は5未満です。\u0026#34;) } } Python置き換えパターン。\ndef main(): num = 4 s = str(num) # Pythonの複数条件分岐ブロックは \u0026#34;else if\u0026#34;ではなく\u0026#34;elif\u0026#34;とする。 if num \u0026gt;= 10: print(s, \u0026#34;:\u0026#34;, \u0026#34;変数numは10以上です。\u0026#34;) elif num \u0026gt;= 5: print(s, \u0026#34;:\u0026#34;, \u0026#34;変数numは5以上10未満です。\u0026#34;) else: print(s, \u0026#34;:\u0026#34;, \u0026#34;変数numは5未満です。\u0026#34;) # 4 : 変数numは5未満です。 if __name__ == \u0026#34;__main__\u0026#34;: main() 追記。引数を与えてそれに応じて処理するパターンやってみた。\nif_args.go\npackage main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) func main() { flag.Parse() //引数をintに変換する arg := flag.Arg(0) var i int var str string=arg i, _ = strconv.Atoi(str) //引数の値に応じて出力を分岐 if i \u0026gt;= 100 { fmt.Println(\u0026#34;変数iは100以上です。\u0026#34;) } else { fmt.Println(\u0026#34;変数iは100未満です。\u0026#34;) } } 結果\n$ go run if_args.go 100 変数iは100以上です。 $ go run if_args.go 101 変数iは100以上です。 $ go run if_args.go 99 変数iは100未満です。 参考\n【Go入門】ifによる条件分岐とelse if, elseブロック\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-if-2/","summary":"\u003cp\u003eGo言語におけるif-else文の覚書。\u003c/p\u003e","title":"Go入門(9) - if else文"},{"content":"CloudWatch Logs Insightsでログメッセージを抽出する時に一番よく使うのはキーワードでフィルタをかけるパターンだと思うが、ロギングタイプを指定することも可能と最近知った。\nクエリ内容は以下の通り。\nfields @message | parse @message \u0026#34;[*] *\u0026#34; as loggingType, loggingMessage | filter loggingType = \u0026#34;ERROR\u0026#34; | display loggingMessage これにより、ロギングタイプがERRORのメッセージのみ抽出される。\n以下はキーワード抽出の例。filedsに@logStreamを指定すると対象のログストリームのリンク列が表示されてちょっと便利。先のパターンでは指定できない。目的に応じて使い分けるか。\nfileds @timestamp, @message, @logStream | filter @message like /ERROR/ | sort @timestamp desc 参考\nCloudWatch Logs Insights の勉強メモ\n","permalink":"https://ecnedaced-seirots.github.io/post/b/cloudwatch-logs-insights-tips/","summary":"\u003cp\u003eCloudWatch Logs Insightsでログメッセージを抽出する時に一番よく使うのはキーワードでフィルタをかけるパターンだと思うが、ロギングタイプを指定することも可能と最近知った。\u003c/p\u003e","title":"Logs Insightsでロギングタイプを指定するクエリ"},{"content":"簡単そうとなめてかかると罠にはまりがちなAWS CodeDeployについて、いくつか覚書。\n単純化しているが以下のサンプルを元にする。\nappspec.yml\nversion: 0.0 os: linux files: - source: /opt/script #ディレクトリ自体を配布 destination: /opt/script - source: /opt/conf/server.conf #特定のファイルを配布 destination: /opt/conf file_exists_behavior: OVERWRITE #既存ファイルの上書き指定 permissions: - object: /opt/script #/opt/script配下のディレクトリすべて指定したパーミッションになる pattern: \u0026#34;**\u0026#34; owner: root group: root mode: 755 type: - directory - object: /opt/script pattern: \u0026#34;*.sh\u0026#34; owner: root group: root mode: 755 type: - file - object: /opt/conf #/opt/script配下のshファイルはすべて指定したパーミッションになる pattern: \u0026#34;**\u0026#34; owner: root group: root mode: 755 type: - directory - object: /opt/conf #/opt/conf内のserver.confに対するパーミッションを指定 pattern: \u0026#34;server.conf\u0026#34; owner: root group: root mode: 644 type: - file hooks: AfterInstall: - location: ./deploy_task #hookスクリプトファイルを相対パスで指定 timeout: 300 1.filesセクションの記述 appspec.ymlのfilesセクションがわかっているようでわかっていなかった。ひとつのappspec.ymlに複数のパターンがあると気をつけていても間違える。\nfiles\nsource: ディレクトリ配布の場合はディレクトリ名を、個別ファイルの場合はファイル名を指定。\ndestination: ディレクトリ名を指定。\ndestinationではファイル名は指定しない。（これ重要）\n2. CodeDeployの上書きオプション OSに最初から入っている既存のファイルやリビジョンに加える前から存在しているファイルを配布したい場合、デフォルトだと以下のエラーにより失敗する。\nThe deployment failed because a specified file already exists at this location\nCodeDeployエージェント 1.3.2以降のバージョンであれば、appspec.ymlのfilesセクションにfile_exists_behaviorオプションを指定すれば期待値になる。\nfiles: - source: /opt/script destination: /opt/script - source: /opt/conf/server.conf destination: /opt/conf file_exists_behavior: OVERWRITE #既存リソースに対する動作を上書きとして指定 file_exists_behaviorに指定可能な値は DISALLOW|OVERWRITE|RETAIN のどれか。詳細は以下参考。\n参考\nAppSpecの「files」セクション\n3. デプロイ後のファイルタイムスタンプ問題 現状の仕様により、CodePipelineでソースアクションとしてCodeCommitをソースにした場合、ファイルのタイムスタンプを取得できないという問題がある。何もしないとデプロイ後のタイムスタンプが1979年12月29日になってしまう。これを是正するため、以下のhookスクリプトによりデプロイ時点の時刻をタイムスタンプとしてセットする。\nミドルウェアの設定ファイルを配布する場合は、この後プロセス再起動の処理を書くこともできる。\ndeploy_task\n#!/bin/bash touch /opt/script/* touch /opt/conf/* 4. AMIから復旧させたインスタンスのリビジョン 過去のインスタンスで実行した既存のデプロイは、teriminate後にAMIから復旧させたインスタンスでもリビジョン対象として認識される。このためfile_exists_behaviorがなくてもデプロイは可能である。（しかしその後の変更時にエラーを回避したければ、つけておく方が安心）\n5. リビジョン対象資材削除時の対応 検索したが意外に情報がない。ほぼ皆無だ。以下、仕方ないので自分で検証して判明した結果より。\n(1) ディレクトリ内の資材一部の削除 リポジトリ内の対象資材をGit上から削除する。コミット/pushするとデプロイ時にその資材は削除された状態になる。サンプルymlの例で言うと、/opt/script内に複数のスクリプトがあるとして、その中の一つを削除したければGit上でdeleteし、appspec.ymlは変更なしでよい。\n(2) filesセクションで特定のファイルを削除する appspec.ymlのfilesセクションから対象のsource/destination行を削除する。permissionセクションからも削除。サンプルymlからserver.confを削除する場合、以下2行を削除する。\n- source: /opt/conf/server.conf destination: /opt/conf さらに以下も削除。\n- object: /opt/conf pattern: \u0026#34;server.conf\u0026#34; owner: root group: root mode: 644 type: - file ただし、これを実行すると「対象のファイルだけリビジョン対象外としてディレクトリは残す」ことができない。（ディレクトリの階層の状況にもよる）デプロイで期待値にならない部分は手動で対応するしかなさそうである。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-codedeploy-tips/","summary":"\u003cp\u003e簡単そうとなめてかかると罠にはまりがちなAWS CodeDeployについて、いくつか覚書。\u003c/p\u003e","title":"AWS CodeDeploy備忘録"},{"content":"村上龍著「愛と幻想のファシズム」より。\nこいつらは簡単にだまされる。飢えているからだ。疲れて、参っている奴らは、たとえ嘘だとわかっていても暖かい光景に飢えているのだ。飢餓や混乱の経験がなく、いつも見慣れている風景が一瞬にして殺戮の廃墟と化すことがあると知らない奴らは、弱い。気付かない。暖かい心や言葉や光景は永遠のものだと信じていて、人間も風景もあっという間に変わってしまうのだと気付かない。\n俺がヒューマニズムとセンチメンタリズムを敵視する理由はこの引用にも表現されている。\n反吐が出そうな偽善民主主義ファシズムに覆われた、糞みたいな世界。こんな世界で奴隷ではない生き方で生きようとしたら、それこそ鈴原冬二のごとく、快楽とともに極限まで獲物を狙い、敵を見据えて戦う意志がなけりゃいけない。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-8/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より。\u003c/p\u003e","title":"「愛と幻想のファシズム」より(6)"},{"content":"Go言語におけるif文の基本覚書。\n今回も細かい話は抜きにして、サンプル構文。\nif_1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := 1 if num \u0026gt; 0 { fmt.Println(\u0026#34;正の数です。\u0026#34;) } //変数定義と条件式を1行で記述してもよい if num := 1; num \u0026gt; 0 { fmt.Println(\u0026#34;これも正の数です。\u0026#34;) } } 結果\n正の数です。 これも正の数です。 if_2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { if 1 == 1 { fmt.Println(\u0026#34;番号は1です。\u0026#34;) } if true { fmt.Println(\u0026#34;trueです。\u0026#34;) } if false { fmt.Println(\u0026#34;falseです。\u0026#34;) } if !true { fmt.Println(\u0026#34;trueじゃないです。\u0026#34;) } if !false { fmt.Println(\u0026#34;falseじゃないです。ということはtrueです。\u0026#34;) } } 結果。trueの場合のみ出力が発生している。\n番号は1です。 trueです。 falseじゃないです。ということはtrueです。 Pythonに置き換えると。\nif.py\ndef main(): num = 1 if num \u0026gt; 0: print(\u0026#34;正の数です。\u0026#34;) if 1 == 1: print(\u0026#34;番号は1です。\u0026#34;) if True: print(\u0026#34;Trueです。\u0026#34;) if False: print(\u0026#34;Falseです。\u0026#34;) if not True: print(\u0026#34;Trueじゃないです。\u0026#34;) if not False: print(\u0026#34;Falseじゃないです。ということはTrueです。\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: main() 結果\n正の数です。 番号は1です。 Trueです。 Falseじゃないです。ということはTrueです。 参考\n【Go入門】if文による条件分岐とtrue, false\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-if/","summary":"\u003cp\u003eGo言語におけるif文の基本覚書。\u003c/p\u003e","title":"Go入門(8) - if文の基本"},{"content":"画像処理ライブラリのOpenCVをいじってみようと思った。OpenCVがやりたいというより、Python + 画像処理なら両方好きだからモチベーションを維持できそうと思ったのだ。\nMacにインストールする。インストール方法が複数あり、その時点でどれを選んでいいか分からずつまづく派が多いらしい。とりあえずpipがおすすめらしいのでそれでいく。\n$ pip3 install opencv-python : : $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 numpy==1.21.4 #numpyも一緒に入る opencv-python==4.5.5.62 pandas==1.3.4 python-dateutil==2.8.2 (snip) 適当なディレクトリに画像ファイルと以下コードを格納する。\ninit.py\nimport cv2 img = cv2.imread(\u0026#39;img_01.png\u0026#39;) #イメージファイルを指定 cv2.imshow(\u0026#39;Yellow\u0026#39;, img) #ウィンドウ名とイメージファイルを指定 cv2.waitKey(0) #これを記述することで、ファイルオープンの状態が継続する cv2.destroyAllWindows() #キーボード入力があった時点で終了 上記はカレントディレクトリにファイルが存在する前提。それ以外の場合は絶対パスか相対パスで指定する。実行すると以下のように画像が開く。何かキーボート入力すると閉じる。\n何もしてないに等しいが、今日はここまで。\n参考\n【初心者向け】PythonとOpenCVで画像処理を体験してみよう\n","permalink":"https://ecnedaced-seirots.github.io/post/b/python-opencv-1/","summary":"\u003cp\u003e画像処理ライブラリのOpenCVをいじってみようと思った。OpenCVがやりたいというより、Python + 画像処理なら両方好きだからモチベーションを維持できそうと思ったのだ。\u003c/p\u003e","title":"PythonでOpenCV始めてみる"},{"content":"Goのmap操作続き。range, 追加やdeleteなど。\n要素の追加。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, } fmt.Println(city) fmt.Println(city[\u0026#34;London\u0026#34;]) //key \u0026#34;London\u0026#34;の値出力 fmt.Println(city[\u0026#34;Bangkok\u0026#34;]) //要素がないkeyの値は0 v, ok := city[\u0026#34;Bangkok\u0026#34;] //\u0026#34;Bangkok\u0026#34;の値と真偽を確認 fmt.Println(v) fmt.Println(ok) city[\u0026#34;Bangkok\u0026#34;] = 400 //要素\u0026#34;Bangkok\u0026#34;を追加 //要素と値の真偽を取得し、trueの場合に処理を実行 if v, ok := city[\u0026#34;Bangkok\u0026#34;]; ok { fmt.Println(v) } } 結果\nmap[London:200 NY:100 Tokyo:300] 200 0 0 false 400 rangeを使ってloop処理。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, } //keyにBangkokを追加 city[\u0026#34;Bangkok\u0026#34;] = 400 //rangeでループ処理してkey:valueを出力 for k, v := range city { fmt.Println(k, v) } } 結果\nBangkok 400 NY 100 London 200 Tokyo 300 要素の削除。\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{ \u0026#34;NY\u0026#34;: 100, \u0026#34;Tokyo\u0026#34;: 300, } fmt.Println(city) //\u0026#34;NY\u0026#34;を削除 delete(city, \u0026#34;NY\u0026#34;) fmt.Println(city) //要素と値の真偽を取得し、trueの場合に削除処理を実行 if v, ok := city[\u0026#34;Tokyo\u0026#34;]; ok { fmt.Println(\u0026#34;num:\u0026#34;, v) delete(city, \u0026#34;Tokyo\u0026#34;) } fmt.Println(city) //空のmapが出力される } 結果\nmap[NY:100 Tokyo:300] map[Tokyo:300] num: 300 map[] Pythonに置き換えると。\ndict2.py\ndef main(): city = {\u0026#34;NY\u0026#34;: 100, \u0026#34;Tokyo\u0026#34;: 300} print(city) # 辞書に要素を追加 city[\u0026#34;Bangkok\u0026#34;] = 400 print(city) # popで要素を削除 print(city.pop(\u0026#34;NY\u0026#34;)) print(city) # clearで辞書データを削除 city.clear() print(city) if __name__ == \u0026#34;__main__\u0026#34;: main() 結果\n{\u0026#39;NY\u0026#39;: 100, \u0026#39;Tokyo\u0026#39;: 300} {\u0026#39;NY\u0026#39;: 100, \u0026#39;Tokyo\u0026#39;: 300, \u0026#39;Bangkok\u0026#39;: 400} 100 {\u0026#39;Tokyo\u0026#39;: 300, \u0026#39;Bangkok\u0026#39;: 400} {} 参考\n【Go入門】mapの操作 – 要素の追加, range, delete\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-map-2/","summary":"\u003cp\u003eGoのmap操作続き。range, 追加やdeleteなど。\u003c/p\u003e","title":"Go入門(7) - mapのrange,deleteなど"},{"content":"「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より、クライマックスに近づくあたりのシーン。\nキクとアネモネが小笠原の孤島からやってきた真夏のTokyoで、中古で購入したバイクに乗って高速道路を走るところ。すごくかっこよくて、かつ非常に重要なシーンなのだが、なんと英語版は以下赤字snipとしている箇所が抜けている！\nNothing ever changes, he thought. Everbodys\u0026rsquo; still trying to break out of themselves, hoping for that new wind to blow through and shake their hearts awake. (snip) But for us, for all the babies who slept their first sleep in those muggy boxes, who head that sound, the only sound there was until the air first touched our skin \u0026ndash; the sound of our mothers\u0026rsquo; hearts\u0026ndash;nothing ever changes. How could it? How could any of us forget \u0026ndash; a sign that came to us in the dark, endlessly, ceaselessly, wiht just one message, over and over and over again? \u0026hellip;\n何一つ変わっていない、誰もが胸を切り開き新しい風を受けて自分の心臓の音を響かせたいと願っている、渋滞する高速道路をフルスロットルですり抜け疾走するバイクライダーのように生きたいのだ、俺は跳び続ける、ハシは歌い続けるだろう、夏の柔らかな箱で眠る赤ん坊、俺達はすべてあの音を聞いた、空気に触れるまで聴き続けたのは母親の心臓の鼓動だ。一瞬も休みなく送られてきたその信号を忘れてはならない。信号の意味はただ一つだ。\n(snip)部分に相当するのは下原文の赤字箇所である。その後に続くセンテンスも、意味としては原文とほぼ同等だが若干表現が異なる。それは翻訳のスタイルだからいいとして、ここは削除しないで欲しかったなぁ、キクが「ハシは歌い続けるだろう」とつぶやくこの部分を知っているか知らないかで、この後に続くクライマックスの受け止め方が相当ブレる。（俺は、つまりキクはハシがTokyoで歌い続けることを確信した上で破壊物質のダチュラをばら撒いたという関係性を、原文を読んでやっと呑み込めた）\nそして、端折られているのはここだけじゃない。英語版を読み終わってから原文のラスト十数ページだけ読んだところ、数ページ分まるごと抜けていた！ハシが病院のNevaを訪ねて、そこで拉致られるあたりの数ページが。どうりで、話の展開についていけなかったわけだよ。（小説後半はハシの妄想シーンが多く占めていたから、展開がわけがわからないのはそういうもんだと軽く流してた。）うーん、数ページ削除ってさすがに乱暴すぎないか。\n全体通すと他にもカットシーンがあるんだろうな、映画をTVで放映する際にいくつかカットされたりする、あれと同じだ。いや、翻訳版はそういうのがあるってのは知っていたけど、冒頭の箇所はすごく重要なセンテンスだから端折らないで欲しかったな（2度目）、翻訳者の意向か編集側の意向か知らないけど。\n\u0026hellip;て、まぁこれについては若干モヤモヤ感があるものの、英語版の「コインロッカーベイビーズ」を読んですげぇよかったと思う、日本語の原文より刺さったからね、強烈に痺れる文章が何箇所かあった、英語で読むと日本語より集中するし、言葉が頭に入ってくる回路が違うから、日本語で読むのとは別の快楽・喜びがあるんだな。こんな時、長文読解鍛えておいてよかったとつくづく思う。\nしかし実は出だしは鈍くてなかなか進まなくて、完読に3ヶ月くらいかかるんじゃないかと思ってた。去年12月中旬に読み始めて先週半ばに読了したけど、当初はまさか1ヶ月ちょいで読み終わるとは思っていなかった。最後の方はめっちゃスパートかけた、やればできるじゃん、俺。\n野暮なことは語りたくないからゴチャゴチャ言わないけど、英語読解の復習も兼ねて今後もちょっとずつ引用していこうと思う。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-7/","summary":"\u003cp\u003e「コインロッカーベイビーズ」(村上龍）の英語翻訳版 “Coin Locker Babies\u0026quot;より、クライマックスに近づくあたりのシーン。\u003c/p\u003e","title":"Coin Locker Babies-2, Ryu Murakami"},{"content":"AWS Lambdaは関数が呼び出されると自動でCloudWatch Logsにログを吐く。このログの監視についてベストプラクティスを考えてみた。\nこれまでやってきた検証では、Lambdaとは無関係のロググループにエラー出力させて、そのログのサブスクリプションフィルタのターゲットにログ監視用Lambda関数を指定している。一方、Lambda自体のログを監視するには若干捻りが必要そうである。\n以下記事のように、適当なLambda関数のログにサブスクリプションフィルタを設定してエラー検知 ＆ SNS連携でメッセージ通知させること自体は問題ない。\nCloudWatch Logsの特定文字を検知してログ内容を通知するLambda Function\n一応、実際に試してみた。\nLambda① 適当な処理を実行 Lambda② ログ監視用関数。SNSと連携してメール送信 Lambda①のログにサブスクを設定。ターゲットはLambda②とする。これだけなら動作は想定内で、Lambda①でエラーログを1回発生させたら、Lambda②により通知メールが1回送信された。\nしかしLambda①も監視用の関数の場合は注意が必要である。例えばその関数がアラーム監視に紐付いている場合の挙動を想定すると：\n-＞Lambda①にエラー要因がなければ、アラームトリガー発生時は設定したSNSに連携され、ログにはエラーが出ない。（ログ監視通知は飛ばない）\nここまではいいとして、気をつけたいのはLambda①にエラー要因がある状態でトリガー発生した場合:\n-＞ Lambdaログにエラーが吐き出され、サブスクが検知 -＞ ログ監視通知のLambdaが起動し、通知を送信する。\nアラーム監視自体で大量にトリガーが発生した場合、Lambdaのログエラーもそれに準じて高騰することになり、2倍に大量通知が飛ぶことになる。やってはいけないレベルではないかもしれないが、ソリューションは検討しておく必要がある。\nそして、Lambda①がログ監視用関数の場合はそれ自体にLambdaをターゲットとするサブスクを設定してはいけない。\n無限の呼び出しループが作成されるため、ログ配布関数のロググループにサブスクライブすることは避けてください。\nAWS Lambdaでのロギングのベストプラクティス\nつまり、Lambda②のログはLambdaと連携させての監視はできない。他のターゲットなら可能かは不明。どちらにしろ、logsのサブスクは直接SNSに連携できないし、これだけのためにKinesis他のソリューションを採用するのも大袈裟だ。いや、どうしてもっていうなら他の仕組みを実装するしかないけど、自動通知が必須でなければ運用回避でもいいわけで。そんな中以下の記事を目にして、一瞬ハッとした。\nエラー出力をする前に、なんのために必要なのか考えないといけない\nよく自分も陥りがちなのは、「色々な例外がありそうだからとりあえずERROR出力をする」といったパターンです。とりあえず設定したログレベルは、一度リリースされると改修による不具合発生のリスクや、リソースの都合でななかな変更できない事が多いと思います。\n本当に検知や対処が必要なものであればERROR出力は必要です。しかし、ERROR通知を受けた後何もしないのであれば、通知する必要はないのかもしれません。実装の時点で、検知したエラーを元に何をしたいのかを考慮した上で適切なログレベルをつける事が大切です。\nServerless時代のシステム監視、ノイズ通知だらけな日々を経験しての反省点\n発想の転換。自分も「とにかくエラーは通知しなければいけない」と思い込んでいたふしがある。ちょっとクールダウンして再検討しよう。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-lambda-log-monitoring/","summary":"\u003cp\u003eAWS Lambdaは関数が呼び出されると自動でCloudWatch Logsにログを吐く。このログの監視についてベストプラクティスを考えてみた。\u003c/p\u003e","title":"AWS Lambdaのログ監視方法を考えてみる"},{"content":"TerraformでNAT Gatewayを作る。EKS Fargateの検証する時に、EKSリソースと一緒に自動生成したいからだ。\nちなみに手動作成の手順は以下。\nAWS NATゲートウェイの作成と設定\nNATゲートウェイを作るだけなら、以下コードだけでよい。\nnat.tf\n########################################### # EIP ########################################### resource \u0026#34;aws_eip\u0026#34; \u0026#34;poc_eip\u0026#34; { vpc = true } ########################################### # NAT Gateway ########################################### resource \u0026#34;aws_nat_gateway\u0026#34; \u0026#34;nat_gw\u0026#34; { allocation_id = aws_eip.poc_eip.id subnet_id = var.public-a tags = { Name = \u0026#34;NAT-for-PoC\u0026#34; } # To ensure proper ordering, it is recommended to add an explicit dependency # on the Internet Gateway for the VPC. # depends_on = [aws_internet_gateway.example] } 先にEIPを作ってNATゲートウェイに割り当てている。このEIPはリソースに関連付けている限りは課金対象外だが、関連付けリソースから外れると課金対象になる。このためNATゲートウェイ削除時にはEIPもリリースしないといけないが、忘れがちなので要注意である。Terraformで作成するならTerraform destroy時に一緒にリリースされるはずだから安心だ。（しかし未検証）\nで、上記をapplyするとEIPとNATゲートウェイが作成される。しかし実際に使用できるようにするにはルートテーブルの設定が必要なのである。これが、よくわからなくてハマった。当初はaws_route_table_associationで設定可能か？と思って試してみた。しかしドキュメントを見ると設定可能なのはインターネットゲートウェイかサブネットIDのみで、NATゲートウェイは含まれていない。それでも無理矢理コードを書いてapplyしてみたら、無効なパラメータなんだよボケ！と怒られた。\nError: error creating Route Table (rtb-1234567890123445) Association: InvalidParameterValue: invalid value for parameter gateway-id: nat-02d182b4d52eb6aa7 status code: 400, request id: ae4cb491-23d6-41e8-b7ef-e01983cabef8 (snip) しばし思いを馳せて、NATゲートウェイの関連付けはaws_route_table_associationではなくroute_tableでやればいいらしいのはなんとなく分かった。しかしドキュメントを読んでも設定項目がわからん\u0026hellip;\nTerraform - route_table\nそこで、ルートテーブルの設定をマネコンから手動で実施して、その状態をimportして探ってみた。importするため以下のような最低限のtfコードを用意してimportコマンドを実行する。\nrt-prv.tf\nresource \u0026#34;aws_route_table\u0026#34; \u0026#34;rt_prv\u0026#34; { } $ terraform import aws_route_table.rt_prv rtb-1234567890123445 実行後のtfstateを確認する。以下は対象ルートテーブルの辺りだけ抜粋。\n{ \u0026#34;mode\u0026#34;: \u0026#34;managed\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;aws_route_table\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;rt_prv\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;provider[\\\u0026#34;registry.terraform.io/hashicorp/aws\\\u0026#34;]\u0026#34;, \u0026#34;instances\u0026#34;: [ { \u0026#34;schema_version\u0026#34;: 0, \u0026#34;attributes\u0026#34;: { \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:ec2:ap-northeast-1:0123456789010:route-table/rtb-1234567890123445\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;rtb-1234567890123445\u0026#34;, \u0026#34;owner_id\u0026#34;: \u0026#34;0123456789010\u0026#34;, \u0026#34;propagating_vgws\u0026#34;: [], \u0026#34;route\u0026#34;: [ { \u0026#34;carrier_gateway_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cidr_block\u0026#34;: \u0026#34;0.0.0.0/0\u0026#34;, \u0026#34;destination_prefix_list_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;egress_only_gateway_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;gateway_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;instance_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ipv6_cidr_block\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;local_gateway_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;nat_gateway_id\u0026#34;: \u0026#34;nat-02d182b4d52eb6aa7\u0026#34;, \u0026#34;network_interface_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;transit_gateway_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;vpc_endpoint_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;vpc_peering_connection_id\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;tags\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;dev-private-rt\u0026#34; }, \u0026#34;tags_all\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;dev-private-rt\u0026#34; }, \u0026#34;timeouts\u0026#34;: { \u0026#34;create\u0026#34;: null, \u0026#34;delete\u0026#34;: null, \u0026#34;update\u0026#34;: null }, \u0026#34;vpc_id\u0026#34;: \u0026#34;vpc-1234567890123445\u0026#34; }, \u0026#34;sensitive_attributes\u0026#34;: [], \u0026#34;private\u0026#34;: (snip) 上記の値を参考にroute_tableでNATゲートウェイの関連付けができそうではある。しかしここで、今更ではあるがふと気がついた。\nもともと今回使っているサブネットやルートテーブルはTerraform外で作成したものである。既存の管理外ルートテーブルを下手にTerraformで操作して干渉させるのはNGじゃないかと。そして、importを実行した時点でTerraform管理下になってしまっているが、確認したかっただけなので管理下に置くつもりはないのである。(なので、今後のTerraform作業はこのtfstateから干渉されないパスで実行する）\nネットワーク周りもすべてTerraformで作成したものであれば使い終わったらすべてdestroyで問題ないが、そうでないとなかなか厄介だ。かといってそのために今からコード追加したり書き換えるのも面倒だ。\nで、考えた挙句、ルートテーブル関連付けだけは手動でやることにした。本来は全自動でやりたいが、現状はNATゲートウェイ作成とEKSクラスタ作成を2段階で分割する必要がある。なかなか、思い通りにはいかない。まぁこういうジレンマは、TerraformだろうがCFnだろうがついて回る。試行錯誤でやっていくしかない。\nところで自分はこれまでTerraformインポートは構成の確認のために使っていたが、こういう目的で使うこともあるのか。備忘録。\nTerraform import機能を使って既存のVPCとサブネットをTerraformで管理できるようにする\n追記\nTerraform import後の結果を見やすく出力するコマンドがあったのを思い出した。\n$ terraform state show [AWSリソース名].[Terraformリソース名] $ terraform state show aws_route_table.rt_prv # aws_route_table.rt_prv: resource \u0026#34;aws_route_table\u0026#34; \u0026#34;rt_prv\u0026#34; { arn = \u0026#34;arn:aws:ec2:ap-northeast-1:0123456789010:route-table/rtb-01234567890123456\u0026#34; id = \u0026#34;rtb-01234567890123456\u0026#34; owner_id = \u0026#34;0123456789010\u0026#34; propagating_vgws = [] route = [ { carrier_gateway_id = \u0026#34;\u0026#34; cidr_block = \u0026#34;0.0.0.0/0\u0026#34; destination_prefix_list_id = \u0026#34;\u0026#34; egress_only_gateway_id = \u0026#34;\u0026#34; gateway_id = \u0026#34;\u0026#34; instance_id = \u0026#34;\u0026#34; ipv6_cidr_block = \u0026#34;\u0026#34; local_gateway_id = \u0026#34;\u0026#34; nat_gateway_id = \u0026#34;nat-02d182b4d52eb6aa7\u0026#34; network_interface_id = \u0026#34;\u0026#34; transit_gateway_id = \u0026#34;\u0026#34; vpc_endpoint_id = \u0026#34;\u0026#34; vpc_peering_connection_id = \u0026#34;\u0026#34; }, ] tags = { \u0026#34;Name\u0026#34; = \u0026#34;dev-private-rt\u0026#34; } tags_all = { \u0026#34;Name\u0026#34; = \u0026#34;dev-private-rt\u0026#34; } vpc_id = \u0026#34;vpc-01234567890123456\u0026#34; timeouts {} } ","permalink":"https://ecnedaced-seirots.github.io/post/b/terraform-nat-gateway/","summary":"\u003cp\u003eTerraformでNAT Gatewayを作る。EKS Fargateの検証する時に、EKSリソースと一緒に自動生成したいからだ。\u003c/p\u003e","title":"TerraformでNATゲートウェイを作成する"},{"content":"Goのmapはkey:valueの配列で構成されており、Pythonの辞書に似ている。ほぼ辞書と同等の使い方ができるようだが、若干挙動が異なる。\nmap定義の構文は以下の通り。\nmap[keyの型名]値の型名{key: value, key: value, ..., key: value} map1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //mapの基本 city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) } 結果\n出力の順番は保証されない（記述した順番通りに出力されない）。\nmap[Bangkok:400 London:200 NY:100 Tokyo:300] 次にkeyの値を出力、valueの変更、key:valueの追加など。\nmap2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) //map[Bangkok:400 London:200 NY:100 Tokyo:300] //指定したkeyの値を出力 fmt.Println(city[\u0026#34;Tokyo\u0026#34;]) //300 //指定したkeyの値を変更 city[\u0026#34;Tokyo\u0026#34;] = 500 fmt.Println(city[\u0026#34;Tokyo\u0026#34;]) //500 //key:valueを新たに追加 city[\u0026#34;Buenos Aires\u0026#34;] = 600 fmt.Println(city) //map[Bangkok:400 Buenos Aires:600 London:200 NY:100 Tokyo:500] } 空のmapを作成してkey:valueを追加。配列を初期化して値を追加していくとかありがちだからいつか使う、かも。\nmap3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //makeで空のmap作成後、key:valueを追加 city2 := make(map[string]int) city2[\u0026#34;Paris\u0026#34;] = 700 fmt.Println(city2) //map[Paris:700] } 次に、存在しないkey指定時の動作など。\nmap4.go\npackage main import \u0026#34;fmt\u0026#34; func main() { city := map[string]int{\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} fmt.Println(city) //valueがないkeyを指定すると: fmt.Println(city[\u0026#34;L.A\u0026#34;]) //指定したkeyのvalueと、存在有無を出力。値が存在する場合: v, isOk := city[\u0026#34;London\u0026#34;] fmt.Println(v, isOk) //値が存在しない場合: v2, isOk2 := city[\u0026#34;L.A\u0026#34;] fmt.Println(v2, isOk2) } 結果\nmap[Bangkok:400 London:200 NY:100 Tokyo:300] 0 200 true 0 false 最後に、Python置き換えの例。\ndict.py\ndef main(): # 辞書定義 city = {\u0026#34;NY\u0026#34;: 100, \u0026#34;London\u0026#34;: 200, \u0026#34;Tokyo\u0026#34;: 300, \u0026#34;Bangkok\u0026#34;: 400} print(city) #{\u0026#39;NY\u0026#39;: 100, \u0026#39;London\u0026#39;: 200, \u0026#39;Tokyo\u0026#39;: 300, \u0026#39;Bangkok\u0026#39;: 400} # 指定したkeyの値を出力 print(city[ \u0026#34;London\u0026#34;]) #200 # 指定したkeyの値を変更 city[ \u0026#34;Tokyo\u0026#34;] = 500 print(city[ \u0026#34;Tokyo\u0026#34;]) #500 # key:valueを新たに追加 city[\u0026#34;Buenos Aires\u0026#34;] = 600 print(city) #{\u0026#39;NY\u0026#39;: 100, \u0026#39;London\u0026#39;: 200, \u0026#39;Tokyo\u0026#39;: 500, \u0026#39;Bangkok\u0026#39;: 400, \u0026#39;Buenos Aires\u0026#39;: 600} # 存在しないkeyを指定 print(city[ \u0026#34;L.A\u0026#34;]) #KeyError: \u0026#39;L.A\u0026#39; if __name__ == \u0026#34;__main__\u0026#34;: main() 参考\n【Go入門】mapの基本\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-map/","summary":"\u003cp\u003eGoのmapはkey:valueの配列で構成されており、Pythonの辞書に似ている。ほぼ辞書と同等の使い方ができるようだが、若干挙動が異なる。\u003c/p\u003e","title":"Go入門(6) - mapの基本"},{"content":"Macで、特定の拡張子がつくファイルを開く時のデフォルトアプリケーションを設定したい時。例えばスクリプト系は一律mi.appとしたいが、最近始めたGoはまだ設定されていない。\n未設定のファイルを１つ選択し、「情報を見る」(⌘ + I)を開いて以下のように設定する。\n2番目の画像で、「続ける」を押下。設定後は「このアプリケーションで開く」が「mi.app（デフォルト）」となり、次回からxxx.goはすべてmiで開くことができる。\nどうということもないネタなんだが、すぐ忘れるんだなこれが。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/mac-files-setting/","summary":"\u003cp\u003eMacで、特定の拡張子がつくファイルを開く時のデフォルトアプリケーションを設定したい時。例えばスクリプト系は一律mi.appとしたいが、最近始めたGoはまだ設定されていない。\u003c/p\u003e","title":"Macでファイルをデフォルトで開くアプリを設定"},{"content":"「コインロッカーベイビーズ」(村上龍）の英語翻訳版 \u0026ldquo;Coin Locker Babies\u0026quot;より。\nhe had leaned the things: one was that all the pain stopped when you stopped fighting death; and the other was that as long as you could still hear your heart beating, you had to keep fighting back.\n\u0026ldquo;Coin Locker Babies\u0026rdquo; by Ryu Murakmi(page 474)\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-6/","summary":"\u003cp\u003e「コインロッカーベイビーズ」(村上龍）の英語翻訳版 \u0026ldquo;Coin Locker Babies\u0026quot;より。\u003c/p\u003e","title":"Coin Locker Babies-1, Ryu Murakami"},{"content":"Go言語におけるfor文の基本覚書。\n細かい話は抜きにして、サンプル構文。\nfor.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //初期値をインクリメント for i := 0; i \u0026lt;= 10; i++ { fmt.Println(i) } fmt.Println(\u0026#34;----------\u0026#34;) //配列の値をループ city := []string{\u0026#34;NY\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Bangkok\u0026#34;, \u0026#34;Tokyo\u0026#34;} for i := 0; i \u0026lt; len(city); i++ { fmt.Println(city[i]) } } 結果\n$ go run for.go 0 1 2 3 4 5 6 7 8 9 10 ---------- NY London Bangkok Tokyo Pythonの場合 Pythonではインクリメント/デクリメント演算子が使用できないため、代替となるコードで記述する。while文なら累算代入で似たような処理ができるが、for文でやるとすればrangeを使うことになる。一方、Goにはwhile文がない。\ndef main(): for i in range(11): print(i) print(\u0026#39;-----------\u0026#39;) city = [\u0026#39;NY\u0026#39;, \u0026#39;London\u0026#39;, \u0026#39;Bangkok\u0026#39;, \u0026#39;Tokyo\u0026#39;] for i in city: print(i) if __name__ == \u0026#34;__main__\u0026#34;: main() 実行結果はGoのコードと同じ。\n参考\n【Go入門】loop処理 – for文の基本 Go言語 for文のサンプル(break/continue)\n【Python入門】インクリメント演算子は使えない!?対処法まとめ\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-for/","summary":"\u003cp\u003eGo言語におけるfor文の基本覚書。\u003c/p\u003e","title":"Go入門(5) - for文の基本"},{"content":"Goの時刻扱いについて。しかし日付時刻の扱いを網羅すると果てしない旅路になるので、今回は触りだけ、現在時刻を出力。\nGoにおいて時刻はロケーション情報を持つtime構造体に格納される。timeで定義済みロケーションはtime.UTCと、time.Localの２つ。それ以外のロケーションを呼び出すには一手間必要で、例えば正式にJSTの時刻を定義するならこうするとかあるけれども、日付時刻の扱いを網羅すると(ry \u0026hellip;なので今回はスキップ。\ntime1.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { //現在時刻をUTCで出力 fmt.Println(\u0026#34;UTCの現在時刻：\u0026#34;, time.Now().UTC()) //ローカルの現在時刻を出力 fmt.Println(\u0026#34;JSTの現在時刻：\u0026#34;, time.Now().Local()) } 出力結果\n$ go run time1.go UTCの現在時刻： 2022-01-16 07:49:06.70495 +0000 UTC JSTの現在時刻： 2022-01-16 16:49:06.705033 +0900 JST 次に、UNIXタイムスタンプの値を出力してみる。さらにデータ型を出力させる。\ntime2.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { //時刻定義を変数に格納 t1 := time.Now().UTC() t2 := time.Now().Local() t3 := time.Now().Unix() //通常の時刻で値と型を出力 fmt.Println(\u0026#34;UTCの現在時刻:\u0026#34;,t1) fmt.Printf(\u0026#34;%T\\n\u0026#34;, t1) fmt.Println(\u0026#34;JSTの現在時刻:\u0026#34;,t2) fmt.Printf(\u0026#34;%T\\n\u0026#34;, t2) //UNIXタイムスタンプの値と型を出力 fmt.Println(\u0026#34;UNIXタイムスタンプ:\u0026#34;,t3) fmt.Printf(\u0026#34;%T\\n\u0026#34;, t3) } 出力結果。UNIXタイムスタンプはint64で、他はtime.Timeであると分かる。\n$ go run time2.go UTCの現在時刻: 2022-01-16 07:55:54.772297 +0000 UTC time.Time JSTの現在時刻: 2022-01-16 16:55:54.772298 +0900 JST time.Time UNIXタイムスタンプ: 1642319754 int64 最後にUNIXタイムスタンプをTime型に変換してみる。\ntime3.go\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { //UNIXタイムスタンプをTime型に変換し、値と型を出力。 t := time.Unix(1642319638, 0) fmt.Println(t.Format(\u0026#34;2006-01-02 15:04:05\u0026#34;)) //2022-01-16 16:53:58 fmt.Printf(\u0026#34;%T\\n\u0026#34;, t) //time.Time } 時刻出力/変換、タイムゾーンの問題はどの言語でも避けて通れない手強い敵なのだが、こればっかりやってもいられないので、まぁボチボチやっていこう。\n参考\nGo言語の時刻演算パッケージ「time」の使い方メモ\n[Go] Unix タイムスタンプを Time 型のデータに変換する\n【Go入門】型（type）を調べる – %T と Printf() ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-time/","summary":"\u003cp\u003eGoの時刻扱いについて。しかし日付時刻の扱いを網羅すると果てしない旅路になるので、今回は触りだけ、現在時刻を出力。\u003c/p\u003e","title":"Go入門(4) - 現在時刻の出力"},{"content":"Goには配列と似た「スライス(Slice)」というデータ構造の概念がある。要素数の指定が不要で、配列より柔軟にデータを扱うことができる。\nスライスの宣言 var 配列名 []型名 var 配列名 []型名 = []型名{要素a, 要素b,...} スライスの使用例 slice1.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //短縮系でスライスnumを定義 num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //[1 2 3 4 5 6 7 8 9] fmt.Println(num) } 特定の要素を取得するにはスライス名[インデックス値]となり、他の言語と変わりない。\nslice2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //すべての要素を出力 fmt.Println(num) //[1 2 3 4 5 6 7 8 9] //インデックスを指定して特定の要素を取得して出力 fmt.Println(num[2]) //3 //要素の値を変更 num[6] = 7000 fmt.Println(num) //[1 2 3 4 5 6 7000 8 9] } 以下は要素の範囲を指定したり、値を追加する例。\nslice3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { num := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} //すべての要素を出力 fmt.Println(num) //[1 2 3 4 5 6 7 8 9] //インデックス範囲の開始・終了地点を指定 fmt.Println(num[3:6]) //[4 5 6] //インデックスの終了地点のみ指定 fmt.Println(num[:6]) //[1 2 3 4 5 6] //インデックスの開始地点のみ指定 fmt.Println(num[6:]) //[7 8 9] //要素に値を追加 num = append(num, 10, 11, 12, 100) fmt.Println(num) //[1 2 3 4 5 6 7 8 9 10 11 12 100] //セミコロンで全要素を対象とする fmt.Println(num[:]) //[1 2 3 4 5 6 7 8 9 10 11 12 100] } Pythonの場合 若干順番はずれているが、以下Pythonの例。Pythonにはsliceの概念がないのでlist。かつ、要素の型宣言が省略されている。\nlist.py\ndef main(): num = [1, 2, 3, 4, 5, 6, 7, 8, 9] print(num) # 要素の範囲指定 print(num[2:6]) print(num[:6]) print(num[6:]) # 要素に値を追加 num.append(10) num.append(11) num.append(12) num.append(100) print(num) # 要素の値を変更 num[6] = 7000 print(num[:]) if __name__ == \u0026#34;__main__\u0026#34;: main() 出力結果\n$ python3 list.py [1, 2, 3, 4, 5, 6, 7, 8, 9] [3, 4, 5, 6] [1, 2, 3, 4, 5, 6] [7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 100] [1, 2, 3, 4, 5, 6, 7000, 8, 9, 10, 11, 12, 100] ちなみにPythonではnum.append(10,11,12,100)のような記述は以下のエラーになり、NGである。このため上記のように逐一個別に指定する必要がある。これについてはGoの方がちょっと便利。\nTypeError: list.append() takes exactly one argument (4 given) 参考\n【Go入門】スライス（Slice）の基本 ","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-slice/","summary":"\u003cp\u003eGoには配列と似た「スライス(Slice)」というデータ構造の概念がある。要素数の指定が不要で、配列より柔軟にデータを扱うことができる。\u003c/p\u003e","title":"Go入門(3) - スライス(Slice)の扱い"},{"content":"Goの配列は要素数を宣言する。宣言した数を超える要素は格納できない。少ない分には可能。Goは配列よりスライスの方がよく使われるらしい。\n配列の基本 配列の宣言はvar 配列名[要素数]型名 の形で行う。値の格納と同時に宣言する場合は、波括弧に要素を格納する。\narray.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //配列の変数宣言 + 角括弧[]の中に格納するデータ数 + データの型名を記述 var num [5]int num[0] = 1000 num[1] = 2000 num[2] = 3000 num[3] = 4000 num[4] = 5000 fmt.Println(num) //要素の値を代入して宣言する。 //配列の変数宣言 + イコール + 要素数と型名 + 波括弧{}内に要素の値を格納。 var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} fmt.Println(city) } 結果\n$ go run array.go [1000 2000 3000 4000 5000] [NY Paris London Sydney Tokyo] 要素数の増減 先述の通り、宣言した数を超える要素は格納できないが、少ない分には可能。要素の数が足りていなくても宣言した要素数は保持される。\narray2.go\npackage main import \u0026#34;fmt\u0026#34; func main() { //宣言した要素数より多い要素の格納は不可。 //宣言した要素数より少ない要素数の格納は可能。 var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} fmt.Println(city) //配列の要素数を出力 //この場合実際に格納した数ではなく宣言した数を出力する fmt.Println(len(city)) } 結果\n$ go run array2.go [NY London Sydney Tokyo ] 5 配列の要素へのアクセス 以下のように記述して配列の要素を取得できる。\n変数名 := 配列名[インデックス値] 例\nc0 := city[0] array3.go\npackage main import \u0026#34;fmt\u0026#34; func main() { var city [5]string = [5]string{\u0026#34;NY\u0026#34;, \u0026#34;Paris\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;Sydney\u0026#34;, \u0026#34;Tokyo\u0026#34;} //配列の要素すべて出力 fmt.Println(city) //配列の要素を取得して変数に格納 c0 := city[0] c1 := city[1] c2 := city[2] c3 := city[3] c4 := city[4] //個別の要素を出力 fmt.Println(c0) fmt.Println(c1) fmt.Println(c2) fmt.Println(c3) fmt.Println(c4) } 結果\n$ go run array3.go [NY Paris London Sydney Tokyo] NY Paris London Sydney Tokyo 参考\n【Go入門】配列（Array）の宣言と要素へのアクセス\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-array/","summary":"\u003cp\u003eGoの配列は要素数を宣言する。宣言した数を超える要素は格納できない。少ない分には可能。Goは配列よりスライスの方がよく使われるらしい。\u003c/p\u003e","title":"Go入門(2) - 配列の扱い"},{"content":"Go言語の学習を始めることにした。シンプルで学びやすい。セミコロンは使わない。try-catchがサポートされていない。:=をよく使う。とのことだ。\nGoインストール まずはbrewでMacにインストール。\n$ brew install go $ go version go version go1.17.5 darwin/amd64 最初のコード 何はなくともHello World、ということで以下のファイルを作成。\ninitial.go\npackage main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;Hello World\u0026#34;) } それぞれのコンポーネントの役割は以下の通り。importするパッケージ名は他の言語と異なりダブルクォーテーションで囲む。\npackage 所属パッケージ名 import \u0026#34;利用パッケージ名\u0026#34; func 関数名() { 処理コード } プログラムを実行するには、go run /path/to/[ファイル名].go とする。\n$ go run initial.go Hello World 変数の宣言 (1) 変数の型を宣言後、関数内で変数の値を定義。\nvar msg string msg = \u0026#34;Hello World\u0026#34; #関数内に記述 (2) 変数の型宣言と変数の値定義（初期化）を同時に行う\nvar msg string = \u0026#34;Hello World\u0026#34; (3) 変数の短縮宣言\nこれは関数の内部でのみ使用可能。グローバル変数は(1)(2)の記述で対応する。\nmsg := \u0026#34;Hello World\u0026#34; #関数内に記述 initial1.go\npackage main import \u0026#34;fmt\u0026#34; //(1)の記述 var msg string func main(){ msg = \u0026#34;Hello World\u0026#34; fmt.Println(msg) } initial2.go\npackage main import \u0026#34;fmt\u0026#34; //(2)の記述 var msg string = \u0026#34;Hello World\u0026#34; func main(){ fmt.Println(msg) } initial3.go\npackage main import \u0026#34;fmt\u0026#34; //(3)の短縮型で記述 func main(){ msg := \u0026#34;Hello World\u0026#34; fmt.Println(msg) } 実行結果はすべて最初のinitial.goと同様となる。\n参考\nGolang 入門 #1 【Go入門】Go言語でHello World! – パッケージとインポート\n","permalink":"https://ecnedaced-seirots.github.io/post/b/golang-init-install/","summary":"\u003cp\u003eGo言語の学習を始めることにした。シンプルで学びやすい。セミコロンは使わない。try-catchがサポートされていない。\u003ccode\u003e:=\u003c/code\u003eをよく使う。とのことだ。\u003c/p\u003e","title":"Go入門(1) - 変数の定義"},{"content":" But Anemone had finally seen through all this talk; all Sachiko\u0026rsquo;s trips and lovers and \u0026ldquo;experiences\u0026rdquo; amounted to the same thing: boredom.\n\u0026ldquo;Coin Locker Babies\u0026rdquo; by Ryu Murakami\nboredom: 退屈、倦怠\n","permalink":"https://ecnedaced-seirots.github.io/post/b/english-boredom/","summary":"\u003cblockquote\u003e\n\u003cp\u003eBut Anemone had finally seen through all this talk; all Sachiko\u0026rsquo;s trips and lovers and \u0026ldquo;experiences\u0026rdquo; amounted to the same thing: boredom.\u003c/p\u003e\n\u003c/blockquote\u003e","title":"英語メモ - boredom"},{"content":"村上龍著「愛と幻想のファシズム」より\n「ただ、彼らの、彼らというのは西欧民主主義国家を言ってるのですが、彼らの、恐ろしさというのは、とてもわかりにくいのです、というのは、彼らは、ヒューマニズムを実践しているからです、恐怖を全面に押し出して来ないからですよ」\n「アメリカが見えませんか？」\n「ボンヤリしています」\n「たぶんね、アメリカ人自身にもアメリカは見えないかも知れませんよ」\n小説「愛と幻想のファシズム」は1983年〜84年にかけて書かれた。龍氏は同じ頃、「アメリカン★ドリーム」というエッセイを連載していて、一冊の本になっている。これは龍氏のアメリカに対する鋭く深く、ポップな洞察がびっしり詰まった、最高に濃くてエキサイティングな書物。この2つの本を合わせ技で読むと、アメリカ、世界統一的政治システム、その中の日本\u0026hellip;といった関係性が浮かび上がってくる。小説の中の物語としての筋書きとは、別の何かが。\n今は遠い過去の歴史となった東西冷戦真っ只中の時代に書かれた小説だが、今でも通用する世界観が散りばめられているし、今この時代だからこそ鮮烈に迫ってくる表現が多々ある。2019年以前に読んでいたらなかったかもしれないけど。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/ryu-quotes-5/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e","title":"「愛と幻想のファシズム」より(5) "},{"content":"過去記事でEKS FargateのPodを起動するところまでやってみた。今回はFargate PodからFluent Bit経由でCloudWatch Logsにログを送信してみる。\nEKS Fargateの関連記事\nEKS FargateクラスタをTerraformで作成する(1) EKS FargateクラスタをTerraformで作成する(2) Fargate + Fluent Bitの参考記事\nFluent Bit for Amazon EKS on AWS Fargate をリリース\nAmazon EKS on Fargate上のPodログをCloudWatchLogsに送信する\nEKSクラスタは過去記事同様にTerraformから自動作成とする。で、FluentBit対応に入るが、準備してからクラスタ作成したかったのでドキュメントとは若干順番が異なる。まず過去記事でFargate Pod用のIAMロールを作成したが、CWログ送信にあたって追加で権限が必要なため別途ポリシーを作成して対象ロールにアタッチする。\n# ポリシーファイルをDL。 $ curl -OL https://raw.githubusercontent.com/aws-samples/amazon-eks-fluent-logging-examples/mainline/examples/fargate/cloudwatchlogs/permissions.json # ポリシー作成 $ aws iam create-policy \\ --policy-name eks-fargate-fluent-bit-cloudwatch \\ --policy-document file://permissions.json # 既存のFargate Pod用ロールにポリシーをアタッチする。 $ aws iam attach-role-policy \\ --policy-arn arn:aws:iam::012345678910:policy/eks-fargate-fluent-bit-cloudwatch \\ --role-name AmazonEKSFargatePodExecutionRole この後terraform applyでEKSクラスタを作成。この間に必要なマニフェストを用意。試行錯誤したが最終的にPoCに使ったマニフェストは以下2種。ファイル名や各種値は任意だが一部変更不可の値があるため注意。\nfargate-logging.yaml（ロギング専用Namespace及びConfigMapの定義） httpd-pod.yaml （Fargate用Namespace及びログ送信用Deploymentの定義） fargate-logging.yaml\nkind: Namespace apiVersion: v1 metadata: name: aws-observability #変更不可 labels: aws-observability: enabled --- kind: ConfigMap apiVersion: v1 metadata: name: aws-logging namespace: aws-observability #変更不可 data: output.conf: | #変更不可（他に設定可能な値もある） [OUTPUT] Name cloudwatch Match * region ap-northeast-1 log_group_name /aws/eks/fargate-fluent-bit log_stream_prefix fargate-pod-log- auto_create_group true httpd-pod.yaml\nkind: Namespace apiVersion: v1 metadata: name: fargate-test #Fargateプロファイルで設定している値 --- apiVersion: apps/v1 kind: Deployment metadata: name: httpd-pod #任意名称 namespace: fargate-test #Fargateプロファイルで設定している値 spec: selector: matchLabels: app: nginx replicas: 1 template: metadata: labels: app: nginx spec: containers: - name: main image: nginx ports: - containerPort: 80 クラスタ作成完了後、aws eks update-kubeconfig --name [your cluster name]を実行し、以下コマンドを実行する。\n#ログ送信定義をapply $ kubectl apply -f fargate-logging.yaml namespace/aws-observability created configmap/aws-logging created #Fargate Podを起動 $ kubectl apply -f httpd-pod.yaml namespace/fargate-test created deployment.apps/httpd-pod created #ConfigMapの確認 $ kubectl -n aws-observability get cm NAME DATA AGE aws-logging 1 32s kube-root-ca.crt 1 32s ここからログ送信のためhttpリクエストを生成していく。ターミナルを3個開いて作業する。\n###ターミナル1 #deploymentをexposeする。 $ kubectl -n fargate-test expose deploy httpd-pod #コネクション生成 kubectl -n fargate-test port-forward svc/httpd-pod 8080:80 Forwarding from 127.0.0.1:8080 -\u0026gt; 80 Forwarding from [::1]:8080 -\u0026gt; 80 ###ターミナル2 #リクエスト送信。以下コマンドを何度か繰り返す。 $ curl localhost:8080 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; (snip) \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ###ターミナル3 #ローカルでログ確認 $ kubectl -n fargate-test logs deploy/httpd-pod -f (snip) 127.0.0.1 - - [10/Jan/2022:09:17:15 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 615 \u0026#34;-\u0026#34; \u0026#34;curl/7.64.1\u0026#34; \u0026#34;-\u0026#34; 127.0.0.1 - - [10/Jan/2022:09:17:47 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 615 \u0026#34;-\u0026#34; \u0026#34;curl/7.64.1\u0026#34; \u0026#34;-\u0026#34; 127.0.0.1 - - [10/Jan/2022:09:19:01 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 615 \u0026#34;-\u0026#34; \u0026#34;curl/7.64.1\u0026#34; \u0026#34;-\u0026#34; マネコンを覗いてみると、CloudWatch Logsにログが送信されていることを確認できた。\nしかし実際にはこのようにあっさり成功したのではなく、それなりに試行錯誤があった、変更不可の値を任意の名称に変えたりしてたから。以下はfargate-logging.yamlを2回目にapplyした時のエラー。初回はエラー出なかったんだよ。最初から言ってくれよ\u0026hellip;\nError from server: error when creating \u0026ldquo;fargate-logging.yaml\u0026rdquo;: admission webhook \u0026ldquo;0500-amazon-eks-fargate-configmaps-admission.amazonaws.com\u0026rdquo; denied the request: fargate.conf is not valid. Please only provide output.conf, filters.conf, parsers.conf or flb_log_cw in the logging configmap\n素直に公式ドキュメントの通りにしていればつまづくことはなかっただろう。まぁわかったからいいけどね。\nそれと設定が読み込まれていないと思われるケースではPod再起動してみたり。（しかし今回の場合は原因はこれじゃなかった）\n$ kubectl -n fargate-test rollout restart deploy httpd-pod 課題 今回はログストリームのプレフィックスを決め打ちにしているが、本来であれば通常のEKSのように、Kubernetes filterでPod名から拾うとかさせたいのである。FargateでのKubernetes filterは初期の頃はサポートされていなかったが、現在は使用できるようになった。今度やってみよう。\nAmazon EKS on AWS Fargate が Fluent Bit Kubernetes Filter のサポートを開始\nちなみに通常のEKSのログ送信については以下参照\nEKS Container InsightsのFluent Bit設定\n","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-fluent-bit/","summary":"\u003cp\u003e過去記事でEKS FargateのPodを起動するところまでやってみた。今回はFargate PodからFluent Bit経由でCloudWatch Logsにログを送信してみる。\u003c/p\u003e","title":"EKS FargateからFluent BitでCloudWatchにログ送信する"},{"content":"小ネタ。AWSのNATゲートウェイは業務では利用することが多いし自分で作ったりもしていた。個人アカでは利用したことがなかったが、先日必要に迫られて作ってみた。\nというのは、Fargate-EKSクラスタを作成する際、FargateのPodが起動するノードはプライベートサブネットに配置する必要があるからだ。外に出る口がないとコントロールプレーンと通信できなくて起動しないんじゃないか？と予想したらやはりその通りだったので、起動途中で詰まっている間にチャチャッとNATゲートウェイを作ったら、サクッとPodが起動した。\nで、NATゲートウェイの作成自体は特に難しいことはなく、業務でやっていた記憶を辿ってなんとなくやったらできた。しかし後で参照できるように記録を残す。\nパブリックサブネットとプライベートサブネットは作成済みとして、大まかには以下の対応となる。\nNATゲートウェイを作成。パブリックサブネットに所属させる。 プライベートサブネットのルートテーブルに1.のNATゲートウェイを関連付ける。 プライベートサブネットのルートテーブルを編集する。\nこれで、プライベートサブネット上のPod/インスタンスが外に出ていけるようになる。\nNATゲートウェイは課金対象なので、Fargateの検証が済んだらすかさず削除する。EKSクラスタはTerraformで作ったので、削除時もterraform destroyであっさり削除。楽ちんだな〜！\nではNATゲートウェイの作成も自動化すればいいじゃないかというと、マネコン操作でも1分でできてしまうので、このままでもいいやと思ってしまうんだな。でもせっかくだから次回はNATゲートウェイも一緒にTerraformで作ってしまおうかな？\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-create-nat-gateway/","summary":"\u003cp\u003e小ネタ。AWSのNATゲートウェイは業務では利用することが多いし自分で作ったりもしていた。個人アカでは利用したことがなかったが、先日必要に迫られて作ってみた。\u003c/p\u003e","title":"AWS NATゲートウェイの作成と設定"},{"content":"Terraformで、「AWS SNSトピックのサブスク + エンドポイントがメール」のパターンで、複数のメールアドレスを指定したかった。しかし、通常の記述方法だとエラーになってしまうのである。\nそれで調べてみたんだが、ほぼ情報が見当たらない。結論から言うと、以下記事参考にしたらできた。この例ではcountで繰り返し処理をしている。\nHow to add email subscribers to an AWS SNS topic with Terraform\n参考記事によると、TerraformでSNSサブスクリプションのエンドポイントとしてメールがサポートされたのが、2021年初頭らしい。そのため、それまではこれまたトリッキーな記述をする必要があった模様。ちなみにアドレスが単体であればcoount処理をせずに通常の記述方法で作成可能である。\n以下、ほぼパクリだがコード例。delivery_policyはデフォルトでよければ設定必要なしと想定する。\n################################################## # E-mail address definition ################################################## locals { emails = [\u0026#34;foo@example.com\u0026#34;,\u0026#34;bar@example.com\u0026#34;] } ################################################## # SNS topic ################################################## resource \u0026#34;aws_sns_topic\u0026#34; \u0026#34;sns_topic\u0026#34; { name = \u0026#34;sns-test-topic\u0026#34; display_name = \u0026#34;Notification Mail\u0026#34; # メールの差出人として表示される delivery_policy = jsonencode({ \u0026#34;http\u0026#34; : { \u0026#34;defaultHealthyRetryPolicy\u0026#34; : { \u0026#34;minDelayTarget\u0026#34; : 20, \u0026#34;maxDelayTarget\u0026#34; : 20, \u0026#34;numRetries\u0026#34; : 3, \u0026#34;numMaxDelayRetries\u0026#34; : 0, \u0026#34;numNoDelayRetries\u0026#34; : 0, \u0026#34;numMinDelayRetries\u0026#34; : 0, \u0026#34;backoffFunction\u0026#34; : \u0026#34;linear\u0026#34; }, \u0026#34;disableSubscriptionOverrides\u0026#34; : false, \u0026#34;defaultThrottlePolicy\u0026#34; : { \u0026#34;maxReceivesPerSecond\u0026#34; : 1 } } }) } ################################################## # SNS topic subscription(for multi e-mail address) ################################################## resource \u0026#34;aws_sns_topic_subscription\u0026#34; \u0026#34;sns_topic_subs\u0026#34; { count = length(local.emails) topic_arn = aws_sns_topic.sns_topic.arn protocol = \u0026#34;email\u0026#34; endpoint = local.emails[count.index] #ここでlocal変数のメールアドレスを参照 } 上記、endpoint = [\u0026quot;foo@example.com\u0026quot;,\u0026quot;bar@example.com\u0026quot;] でいいじゃないかと思ってそう書くと失敗する。「何でこれでダメなんだ！」となるが仕方ない。簡単そうに見える場所にも何かと罠が潜んでいるTerraformである。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/aws-sns-topic-multi-endpoint/","summary":"\u003cp\u003eTerraformで、「AWS SNSトピックのサブスク + エンドポイントがメール」のパターンで、複数のメールアドレスを指定したかった。しかし、通常の記述方法だとエラーになってしまうのである。\u003c/p\u003e","title":"TerraformのSNSサブスクリプションで複数メールアドレス指定"},{"content":"前回投稿の続き。Terraformから構築したEKSクラスタで、Fargate Podを起動してみる。\nEKS FargateクラスタをTerraformで作成する(1)\nこの時点ではノードグループ、Fargateプロファイルを含めてEKSクラスタが構築完了した状態である。まずはupdate-kubeconfig実行して状態を確認。（kubectlのセットアップは割愛。前からあったv1.19で今回のクラスタのバージョンv1.21に対応していないが、一応動作した）\n$ aws eks update-kubeconfig --name eks-test-cluster $ kubectl get no NAME STATUS ROLES AGE VERSION ip-10-0-2-99.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 19m v1.21.5-eks-bc4871b ip-10-0-3-18.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 19m v1.21.5-eks-bc4871b $ kubectl get po -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-6fp74 1/1 Running 0 19m kube-system aws-node-ncjhh 1/1 Running 0 19m kube-system coredns-76f4967988-7pr2d 1/1 Running 0 48m kube-system coredns-76f4967988-t4lmc 1/1 Running 0 48m kube-system kube-proxy-58kvx 1/1 Running 0 19m kube-system kube-proxy-pfw7j 1/1 Running 0 19m ここまではいつもと同じ。最小限のノードに、システム系のPodが起動している。ではFargate Podを起動！\u0026hellip;の前に、前回の構築時にSelectorとしてNamespace[fargate-test]を指定しているため、fargate-testネームスペースが必要である。この時点では対象ネームスペースが存在しないため新規作成する。\n# 作業前のネームスペース確認 $ kubectl get namespace NAME STATUS AGE default Active 54m kube-node-lease Active 54m kube-public Active 54m kube-system Active 54m # ネームスペース fargate-testを作成 $ kubectl create namespace fargate-test namespace/fargate-test created # 確認 $ kubectl get namespace | grep fargate fargate-test Active 53s ネームスペースが作成されたので、これを指定してFargate Podを起動する。マニフェストは何も用意していないからこんなんで。\n$ kubectl create deployment test-app --namespace fargate-test --image=nginx deployment.apps/test-app created やっとRunningになった。\n$ kubectl get po -n fargate-test NAME READY STATUS RESTARTS AGE test-app-f8c9656cd-ph7vg 1/1 Running 0 96s get noしてみると、Fargage専用ノードが起動しているのが確認できた。\n$ kubectl get no NAME STATUS ROLES AGE VERSION fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 103s v1.21.2-eks-06eac09 ip-10-0-2-99.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 31m v1.21.5-eks-bc4871b ip-10-0-3-18.ap-northeast-1.compute.internal Ready \u0026lt;none\u0026gt; 31m v1.21.5-eks-bc4871b そういえば、get pods に-o wideつければ一回で確認可能だった。\n$ kubectl get po -n fargate-test -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES test-app-f8c9656cd-ph7vg 1/1 Running 0 5m7s 10.0.2.10 fargate-ip-10-0-2-10.ap-northeast-1.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 最後にPodのdescribe結果を載せておく。リソース割り当てらしき箇所、[CapacityProvisioned: 0.25vCPU 0.5GB]となっている。これがデフォルト値なんだろう。当然実運用に向けては適宜サイジングすることになる。\n$ kubectl describe po -n fargate-test test-app-f8c9656cd-ph7vg Name: test-app-f8c9656cd-ph7vg Namespace: fargate-test Priority: 2000001000 Priority Class Name: system-node-critical Node: fargate-ip-10-0-2-10.ap-northeast-1.compute.internal/10.0.2.10 Start Time: Mon, 03 Jan 2022 12:31:21 +0900 Labels: app=test-app eks.amazonaws.com/fargate-profile=test-profile pod-template-hash=f8c9656cd Annotations: CapacityProvisioned: 0.25vCPU 0.5GB Logging: LoggingDisabled: LOGGING_CONFIGMAP_NOT_FOUND kubernetes.io/psp: eks.privileged Status: Running IP: 10.0.2.10 IPs: IP: 10.0.2.10 Controlled By: ReplicaSet/test-app-f8c9656cd Containers: nginx: Container ID: containerd://30f18fbf447144fec406634651e8e7ba0651a285a814419b77bf8c4d1d317f44 Image: nginx Image ID: docker.io/library/nginx@sha256:0d17b565c37bcbd895e9d92315a05c1c3c9a29f762b011a10c54a66cd53c9b31 Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; State: Running Started: Mon, 03 Jan 2022 12:31:30 +0900 Ready: True Restart Count: 0 Environment: \u0026lt;none\u0026gt; Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-9c7kb (ro) Conditions: Type Status Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-9c7kb: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: \u0026lt;nil\u0026gt; DownwardAPI: true QoS Class: BestEffort Node-Selectors: \u0026lt;none\u0026gt; Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning LoggingDisabled 14m fargate-scheduler Disabled logging because aws-logging configmap was not found. configmap \u0026#34;aws-logging\u0026#34; not found Normal Scheduled 13m fargate-scheduler Successfully assigned fargate-test/test-app-f8c9656cd-ph7vg to fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Normal Pulling 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Pulling image \u0026#34;nginx\u0026#34; Normal Pulled 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Successfully pulled image \u0026#34;nginx\u0026#34; in 7.409339398s Normal Created 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Created container nginx Normal Started 13m kubelet, fargate-ip-10-0-2-10.ap-northeast-1.compute.internal Started container nginx ここまで確認できたのでPodを削除\n$ kubectl delete deployment test-app --namespace fargate-test eksクラスタはterraform destroyで一気に削除した。\n$ time terraform destroy : : aws_eks_fargate_profile.fargate-test: Destroying... [id=eks-test-cluster:test-profile] aws_eks_node_group.eks-node: Destroying... [id=eks-test-cluster:eks-test-node] 6m6.166s 次回からは再びterraform applyでお気軽に検証できるもんな！\u0026hellip;と言いつつ、正直Fargateの有り難みってよくわからんな。\u0026hellip;ということがわかった検証であった。Podとノードは1:1と決まっていて処理が終わったらノードも消滅するとなれば、バッチ処理に向いていることくらいは想像がつくが。\n通常のEKSとFargateは共存可能なため、アプリの処理の特性によってそれぞれどちらを選択するのか、または1クラスタにおいて片方のみで運用するのか、その検討のために頭を使うことになる。やはり夢は見ちゃいけないのである。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-by-terraform-2/","summary":"\u003cp\u003e前回投稿の続き。Terraformから構築したEKSクラスタで、Fargate Podを起動してみる。\u003c/p\u003e","title":"EKS FargateクラスタをTerraformで作成する(2)"},{"content":"一回EKSのFargateを試してみようと思っていたので、新年早々やってみた。せっかくなのでEKS+FargateプロファイルをTerraformから作成する。他の事例だとeksctlから構築するパターンが多いようだが、最近Terraformいじってるし、eksctl嫌いなもんで。（削除時にハマったこともあり）\nその前に Fargateのことをよく分かっていなかったので基本項目をあげておく。以下は2022年1月現在の仕様・制約事項。\n「面倒なEC2の管理が不要！」と大っぴらに言われているが、Fargateでも最低限のノードグループは必要。 Fargate Pod用のノードが起動するサブネットはプライベートサブネットであること。 2.のPodがコントロールプレーンと通信するためVPC外へ出る必要がある。NATゲートウェイ/プロキシ/VPCエンドポイントいずれかの方式で外部への通信経路を確保する。 Fargateプロファイルを設定する。（大雑把に言うとここでFargateが動作する環境を定義する） FargateにおけるPodとノードの関係は常に1:1となる。（1ノードに複数のPodは起動できない） Fargate Pod専用のIAMロールが必要。（4.で指定） Fargateと通常のEKSワーカーノードの共存が可能。 実は 1.については知らなかったので、EKSクラスタ起動してFargateプロファイル設定すればPodが起動できるもんだと思っていた。EC2がいらないってウソやんけ\u0026hellip;。当初その辺りで躓いたのだが、余計な失敗ネタは置いといて成功パターンを書いておく。\nで、Terraformのコード載せる前に基本前提について。上記の制約があることから、最小限以下の構成を用意しておく。それらもTerraformで作るのであればそれでもいいが、自分はさすがに面倒見切れないので既存のアイテムを流用した。VPCはすでにある想定で：\nAZにまたがったパブリックサブネット AZにまたがったプライベートサブネット NATゲートウェイ（2.のサブネットが外部と通信するため） ①EKSクラスタ ②ノードグループ ③Fargate Pod用の各IAMロール ノードグループリモートアクセス用のセキュリティグループ EKSクラスタ用のセキュリティグループ ノードグループ用のssh key Fargateだろうが何だろうが、これらの前提アイテムは別途構築しなければならないのである。「eksctlならよしなに作ってくれるから楽！」とか言ってても、PoCならともかく実運用時にeksctlでお任せ構築なんてあり得ないのである。夢は見させてくれないのである。\nIAMロールについて ①クラスタ②ノード用ロールは既存のを使用した。ちなみにそれぞれ必要なポリシーは、①はAmazonEKSClusterPolicy、②はAmazonEKSWorkerNodePolicy、AmazonEC2ContainerRegistryReadOnlyとなる。②については、PoC時は最小限の権限でよいが本来Podが必要とするサービスの権限をすべてポリシーに追加する。\n参考\nAmazon EKS クラスター の IAM ロール\nAmazon EKS ノード の IAM ロール\nFargate Pod用ロールはCLIから新規作成した。信頼ポリシー用JSONを用意してコマンド実行。\neks-fargate-pods-policy.json（信頼ポリシー用JSON）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;eks-fargate-pods.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } } # ロール作成 $ aws iam create-role \\ --role-name AmazonEKSFargatePodExecutionRole \\ --assume-role-policy-document file://eks-fargate-pods-policy.json # ロールにポリシーをアタッチ aws iam attach-role-policy \\ --role-name AmazonEKSFargatePodExecutionRole\\ --policy-arn \u0026#34;arn:aws:iam::aws:policy/AmazonEKSFargatePodExecutionRolePolicy\u0026#34; Teraraformコード 以降、Terraformコード。今回、前提条件となるネットワーク環境、IAMロール等はTerraform外で作成済みのアイテムを指定している。\neks.tf\n############################################# # EKS Cluster ############################################# resource \u0026#34;aws_eks_cluster\u0026#34; \u0026#34;eks-cluster\u0026#34; { name = \u0026#34;eks-test-cluster\u0026#34; role_arn = var.cluster-role vpc_config { subnet_ids = [var.public-a, var.public-c] security_group_ids = [var.cluster-sg] } } output \u0026#34;endpoint\u0026#34; { value = aws_eks_cluster.eks-cluster.endpoint } output \u0026#34;kubeconfig-certificate-authority-data\u0026#34; { value = aws_eks_cluster.eks-cluster.certificate_authority[0].data } ############################################# # EKS Node Group ############################################# resource \u0026#34;aws_eks_node_group\u0026#34; \u0026#34;eks-node\u0026#34; { cluster_name = aws_eks_cluster.eks-cluster.name node_group_name = \u0026#34;eks-test-node\u0026#34; node_role_arn = var.node-role subnet_ids = [var.private-a, var.private-c] ami_type = \u0026#34;AL2_x86_64\u0026#34; instance_types = [\u0026#34;t3.small\u0026#34;] labels = { type = \u0026#34;fargate-test\u0026#34; } remote_access { ec2_ssh_key = var.keyname source_security_group_ids = [var.remote-sg] } scaling_config { desired_size = 2 max_size = 2 min_size = 2 } } ############################################# # EKS Fargate Profile ############################################# resource \u0026#34;aws_eks_fargate_profile\u0026#34; \u0026#34;fargate-test\u0026#34; { cluster_name = aws_eks_cluster.eks-cluster.name fargate_profile_name = \u0026#34;test-profile\u0026#34; pod_execution_role_arn = var.pod-role subnet_ids = [var.private-a, var.private-c] selector { namespace = \u0026#34;fargate-test\u0026#34; } } 以下、変数参照先のvariables.tf。最近のTerraform PoCではtfvarsを使っていたが、今回は単純なケースなのでこれ一本で行く。\nvariables.tf\n############################# # public subnet-a ############################# variable \u0026#34;public-a\u0026#34; { default = \u0026#34;subnet-xxxxxxxxxxxxxxxxx\u0026#34; } ############################# # public subnet-c ############################# variable \u0026#34;public-c\u0026#34; { default = \u0026#34;subnet-yyyyyyyyyyyyyyyyy\u0026#34; } ############################# # private subnet-a ############################# variable \u0026#34;private-a\u0026#34; { default = \u0026#34;subnet-wwwwwwwwwwwwwwwww\u0026#34; } ############################# # private subnet-c ############################# variable \u0026#34;private-c\u0026#34; { default = \u0026#34;subnet-zzzzzzzzzzzzzzzzz\u0026#34; } ############################# # cluster security group ############################# variable \u0026#34;cluster-sg\u0026#34; { default = \u0026#34;sg-xxxxxxxxxxxxxxxxx\u0026#34; } ############################# # eks node security group ############################# variable \u0026#34;remote-sg\u0026#34; { default = \u0026#34;sg-xxxxxxxxxxxxxxxxx\u0026#34; } ############################# # cluster IAM role ############################# variable \u0026#34;cluster-role\u0026#34; { default = \u0026#34;arn:aws:iam::012345678910:role/eks-cluster-role\u0026#34; } ############################# # node IAM role ############################# variable \u0026#34;node-role\u0026#34; { default = \u0026#34;arn:aws:iam::012345678910:role/eks-node-group-role\u0026#34; } ############################# # pod IAM role ############################# variable \u0026#34;pod-role\u0026#34; { default = \u0026#34;arn:aws:iam::012345678910:role/AmazonEKSFargatePodExecutionRole\u0026#34; } ############################# # eks node key ############################# variable \u0026#34;keyname\u0026#34; { default = \u0026#34;eks-workeernode-key\u0026#34; } この状態で terraform apply したところ、十数分後にEKSクラスタ/ノードグループ/Fargateプロファイルの作成が完了した。\n最後のFargate Profile -＞ [Pod selectors]は、Fargate上で実行させたいPodの条件が設定されている。上記の場合Namespaceに[fargate-test]を指定しているため、Kubernetes上のfargate-testネームスペースにおいてFarget Podが実行されるようになる。\nではようやく、Fargate Podを起動してみる。\u0026hellip;といきたいが、長くなるので次回に持ち越し。\n参考\nGetting started with AWS Fargate using Amazon EKS\n【AWS】 EKS on Fargate のクラスタを構築してみる\nEKS on Fargateの特徴、通常のEKSとの違いは何か？（第1回）\nAmazon Fargate for Amazon EKSを試してみた #reinvent\nなんとなく「Fargate for EKS」が分かった気になる？ ～ いろいろなギモンを調べてみた ～ #reinvent\n続きは以下。\nEKS FargateクラスタをTerraformで作成する(2)\n","permalink":"https://ecnedaced-seirots.github.io/post/b/eks-fargate-by-terraform/","summary":"\u003cp\u003e一回EKSのFargateを試してみようと思っていたので、新年早々やってみた。せっかくなのでEKS+FargateプロファイルをTerraformから作成する。他の事例だとeksctlから構築するパターンが多いようだが、最近Terraformいじってるし、eksctl嫌いなもんで。（削除時にハマったこともあり）\u003c/p\u003e","title":"EKS FargateクラスタをTerraformで作成する(1)"},{"content":"今朝目覚めの前に、REST APIのリクエストURL記述について、これなら上手くいくとかいかないとか議論しているような夢を見た。\n31日の目覚め前にもTerraformコードが夢に登場した。（確かに気になっていた部分だったので31日はそのままPoCして記事に書いた）\n夢に仕事関係のネタが登場することはたまにある、過去にもその時気になっているコードなどがフラッシュバック状態で登場することはあった。昔は「うわ、夢の中でまで\u0026hellip;やめてくれ！」と嫌な気分になったものだが、いつからか「脳が気になっている情報を整理しているんだろうな」と淡々と受け流すようになった。\nしかし今現在仕事でREST APIに関わる対応はしていないのに何故これが夢に現れたんだろう、と不思議に思った。それに関連して過去の同僚のことが思い浮かんだりしたので、本来の目的はその同僚を思い出すことだったのかもしれない。それでも意味不明だが、まぁいいや。\n通常、朝方の目覚めの前は数十分程度のレム睡眠状態にあり、この時間帯に夢を見ているらしい。この時は「手続き記憶」の定着を行なっていると聞いた。手続き記憶とは、楽器の演奏やスポーツなどの身体的な動作の記憶を示す、と。ではプログラムのコードや仕事関連の事柄が朝方の夢に現れるのは、それも手続き記憶の種類に入るのだろうか、と思って軽く調べたところ、別の意味も判明した。\nレム睡眠時に見る夢は、前日（直近）に経験した出来事と過去の出来事の関連性を整理したり、記憶の定着や索引付けを行なっているらしい。それを知って納得した。\nまた，記憶と睡眠の関係において，ノンレム睡眠－レム睡眠は異なる働きをもっています。ノンレム睡眠は，深いノンレム睡眠（一晩の睡眠の前半に多い）では，「いやな記憶」を消去する働きがあります。一方，浅いノンレム睡眠（一晩の睡眠の後半：朝方に多い）は，手続き記憶を固定する働きがあります。手続き記憶とは，自転車の乗り方や，習字，スポーツの技術などを身につけることと理解してください。また，浅いノンレム睡眠には，昼間記憶したことと過去の記憶を結合する働きもあります。これは色々な記憶を相互に関連づけることです。\nさらに。以下重要。\n基本的な睡眠として，７時間半寝るとすると，前半では深いノンレム睡眠が出現し，後半で浅いノンレム睡眠が出現することを思い出してください。就床後，間も無い時にしっかり寝ないと，昼間に経験した恐怖などの「嫌な記憶（嫌な感覚）」が消えず，心が癒されません。また，３時間や４時間の短時間睡眠では，浅いノンレム睡眠が無くなり，昼間一生懸命練習したことが身につかず，また，色々な出来事の関連情報が記憶されません。更に，短時間睡眠では，朝方の長いレム睡眠がないので，記憶の定着や記憶の索引付けが出来なくなります。\n第１回 「睡眠と記憶について／基本的な睡眠とは」\n不快な記憶を忘却させ、生きていくために必要な情報は整理して記憶の定着に導く。睡眠のメカニズム、人間の脳の働き\u0026hellip;すげぇ！！\nところで夢に過去（または現在）の同僚が登場するのは、その時どんな気分だったかにより意味合いが変わってくるそうだが、個人的には、爽快というわけでもないが不快な気分ではなく、どちらかと言えばプラス方向の気分であることが多い。その場合、自分の理想像として登場している意味があるとかないとか。\nま、今朝思い出した元同僚は確かにできる奴だった。しばらく前にも別の、過去に一緒に仕事をした相当キレる人物が夢に登場したことがあった。これは何を象徴しているのか\u0026hellip;。それにしても、一緒に仕事をした時期は数ヶ月程度で、しかも数えてみると約8年くらい昔なのだ。\nこういう事柄が夢に現れるということは、やはり自分にとって記憶に残しておくべき意味があると解釈すべき、なんだろうか。\n","permalink":"https://ecnedaced-seirots.github.io/post/b/mind-hacks-rem-sleep/","summary":"\u003cp\u003e今朝目覚めの前に、REST APIのリクエストURL記述について、これなら上手くいくとかいかないとか議論しているような夢を見た。\u003c/p\u003e","title":"レム睡眠と夢と記憶"},{"content":"イベント監視通知のためにAWS Configを設定して検証したが、個人PoCであり普段は必要ないため削除しようと思った。微々たる金額だが課金対象だし。\nしかしマネコンから削除しようとしたところ、該当する操作内容が見当たらない。AWS Configはマネコンからは削除できない仕様らしい。\nCLIからであれば可能ということで、CLIからaws configを削除する。\n削除前の確認 $ aws configservice describe-delivery-channels { \u0026#34;DeliveryChannels\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;s3BucketName\u0026#34;: \u0026#34;config-bucket-xxxxxxxxxxxxx\u0026#34; } ] } $ aws configservice describe-configuration-recorders { \u0026#34;ConfigurationRecorders\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;roleARN\u0026#34;: \u0026#34;arn:aws:iam::012345678910:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\u0026#34;, \u0026#34;recordingGroup\u0026#34;: { \u0026#34;allSupported\u0026#34;: false, \u0026#34;includeGlobalResourceTypes\u0026#34;: false, \u0026#34;resourceTypes\u0026#34;: [ \u0026#34;AWS::EC2::Instance\u0026#34; ] } } ] } 削除実行 以下の順番で。先にconfiguration recorderを削除しないとエラーになる。\n$ aws configservice delete-configuration-recorder --configuration-recorder-name default $ aws configservice delete-delivery-channel --delivery-channel-name default 削除後の確認 $ aws configservice describe-delivery-channels { \u0026#34;DeliveryChannels\u0026#34;: [] } $ aws configservice describe-configuration-recorders { \u0026#34;ConfigurationRecorders\u0026#34;: [] } 参考\nAWSマネジメントコンソールから消せないAWS Configの設定をAWSCLIで綺麗にする方法\n","permalink":"https://ecnedaced-seirots.github.io/post/b/delete-aws-config/","summary":"\u003cp\u003eイベント監視通知のためにAWS Configを設定して検証したが、個人PoCであり普段は必要ないため削除しようと思った。微々たる金額だが課金対象だし。\u003c/p\u003e","title":"AWS ConfigをCLIから削除する"},{"content":"大晦日も淡々と自宅PoCをし、淡々と記事を書く。Terraform loop処理シリーズ、今回はEC2インスタンスに対するCloudWatch Alarmの作成をやってみる。\n最初は定数バージョンのサンプルから。EventBridgeでアラームを検知する想定のためalarm_actionsは設定しない。\n（補足）SNSと直接連携する場合は以下のように記述する。\nalarm_actions = [aws_sns_topic.sns.arn] ################################################ # CloudWatch metric alarm # 定数版 ################################################ resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;alarm_001\u0026#34; { alarm_name = \u0026#34;ec2-alarm-cpu-001\u0026#34; comparison_operator = \u0026#34;GreaterThanThreshold\u0026#34; evaluation_periods = \u0026#34;1\u0026#34; metric_name = \u0026#34;CPUUtilization\u0026#34; namespace = \u0026#34;AWS/EC2\u0026#34; period = \u0026#34;60\u0026#34; statistic = \u0026#34;Average\u0026#34; threshold = \u0026#34;80\u0026#34; alarm_description = \u0026#34;CPU Usage Check Alarm\u0026#34; datapoints_to_alarm = \u0026#34;1\u0026#34; treat_missing_data = \u0026#34;missing\u0026#34; dimensions = { InstanceId = \u0026#34;i-xxxxxxxxxxxxxxxxx\u0026#34; } } 上記はインスタンスi-xxxxxxxxxxxxxxxxxに対するCPU使用率監視のアラームを作成する。しかし実際にはひとつのインスタンスに対してメモリ、ディスク、複数のプロセス監視等を行うだろう。（あーEC2面倒くせぇ\u0026hellip;）それらを繰り返し記述するのはありえないのでloopにする。\nちなみにここではTerraformで作成していないインスタンスを指定したのでインスタンスIDを直接指定しているが、インスタンスもTerraformで作成する場合は以下のように記述する。\ndimensions = { InstanceId = aws_instance.instance_001.id } 以下がloopバージョン。インスタンスが複数ある場合、loopの固まりをその分追加で作成し、aws_instance.instance_002.id, aws_instance.instance_003.id \u0026hellip;など指定すればよいかと。EC2インスタンス側もloopで作成する場合はまた参照方法が異なってくるが、EC2はlookupで参照するのは不可能と思われる。他のアラーム用パラメータとEC2のloopの順番は一致しないはずだから。（上手く言い表せない）\nmetric_alarm.tf\n################################################ # CloudWatch metric alarm # loop版 ################################################ resource \u0026#34;aws_cloudwatch_metric_alarm\u0026#34; \u0026#34;alarm_001\u0026#34; { for_each = var.ec2_alarm001_param_list alarm_name = lookup(each.value, \u0026#34;alarm_name\u0026#34;) comparison_operator = lookup(each.value, \u0026#34;comparison_operator\u0026#34;) evaluation_periods = \u0026#34;1\u0026#34; metric_name = lookup(each.value, \u0026#34;metric_name\u0026#34;) namespace = lookup(each.value, \u0026#34;namespace\u0026#34;) period = lookup(each.value, \u0026#34;period\u0026#34;) statistic = lookup(each.value, \u0026#34;statistic\u0026#34;) threshold = lookup(each.value, \u0026#34;threshold\u0026#34;) alarm_description = lookup(each.value, \u0026#34;alarm_description\u0026#34;) datapoints_to_alarm = \u0026#34;1\u0026#34; treat_missing_data = lookup(each.value, \u0026#34;treat_missing_data\u0026#34;) dimensions = { InstanceId = \u0026#34;i-xxxxxxxxxxxxxxxxx\u0026#34; } } 以下は参照する変数リストとなる。\nmetric_alarm.auto.tfvars\n########################################### # CloudWatch alarm vars ########################################### ec2_alarm001_param_list = { param1 = { alarm_name = \u0026#34;ec2-alarm-system-001\u0026#34; comparison_operator = \u0026#34;GreaterThanOrEqualToThreshold\u0026#34; metric_name = \u0026#34;StatusCheckFailed_System\u0026#34; namespace = \u0026#34;AWS/EC2\u0026#34; period = \u0026#34;300\u0026#34; statistic = \u0026#34;Maximum\u0026#34; threshold = \u0026#34;1\u0026#34; alarm_description = \u0026#34;Node Status Monitoring\u0026#34; treat_missing_data = \u0026#34;missing\u0026#34; } param2 = { alarm_name = \u0026#34;ec2-alarm-status-001\u0026#34; comparison_operator = \u0026#34;GreaterThanOrEqualToThreshold\u0026#34; metric_name = \u0026#34;StatusCheckFailed_Instance\u0026#34; namespace = \u0026#34;AWS/EC2\u0026#34; period = \u0026#34;300\u0026#34; statistic = \u0026#34;Maximum\u0026#34; threshold = \u0026#34;1\u0026#34; alarm_description = \u0026#34;Node Status Monitoring\u0026#34; treat_missing_data = \u0026#34;missing\u0026#34; } param3 = { alarm_name = \u0026#34;ec2-alarm-cpu-001\u0026#34; comparison_operator = \u0026#34;GreaterThanThreshold\u0026#34; metric_name = \u0026#34;CPUUtilization\u0026#34; namespace = \u0026#34;AWS/EC2\u0026#34; period = \u0026#34;60\u0026#34; statistic = \u0026#34;Average\u0026#34; threshold = \u0026#34;80\u0026#34; alarm_description = \u0026#34;CPU Usage Monitoring\u0026#34; treat_missing_data = \u0026#34;missing\u0026#34; } param4 = { alarm_name = \u0026#34;ec2-alarm-process-001\u0026#34; comparison_operator = \u0026#34;LessThanThreshold\u0026#34; metric_name = \u0026#34;procstat_lookup_pid_count\u0026#34; namespace = \u0026#34;Prosess\u0026#34; period = \u0026#34;60\u0026#34; statistic = \u0026#34;Average\u0026#34; threshold = \u0026#34;1\u0026#34; alarm_description = \u0026#34;Process Monitoring\u0026#34; treat_missing_data = \u0026#34;missing\u0026#34; } } こんなやっつけコードだがあっさり期待値になった。\nちなみにこれはloop回数が4つ分だけだから手動で書いたが、実際にはもっと多くの監視項目が並ぶ。過去記事に書いたように変数リストを自動生成する仕組みを作った方がよい。\nTerraformのtfvarsファイルを自動生成する\nということでこれまでTerraformのloop処理方式をいくつか探ってきたが、どのような構成にすべきかはそれなりに頭を捻る必要がある。構成というのは、全体的な範囲と、リソース毎の構成。tfコード本体と変数リストの組み合わせとか。loop処理にすべきかどうかはリソースの数にもよる。また、loopか否かによって参照するリソース側の記述も変わってくる。回答はひとつではないのである。\nまぁ頭を捻る場面があるからこそ、面白いとも言えるけど。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-6/","summary":"\u003cp\u003e大晦日も淡々と自宅PoCをし、淡々と記事を書く。Terraform loop処理シリーズ、今回はEC2インスタンスに対するCloudWatch Alarmの作成をやってみる。\u003c/p\u003e","title":"Terraform loop処理の応用編(5) - Metric Alarm"},{"content":"過去LGS（リーキーガット症候群:Leaky gut syndrome) に罹ったことがあるから、腸内の日和見菌が凶暴化するとどれほど身体と脳が破壊されるか身に染みてわかる。\nあの地獄を抜け出すのに、2年以上はかかった。しかし油断すればまた日和見菌が暴徒化する。\n日和見菌は憎らしくて厄介だが、人体は日和見菌なくして生存できないのも事実だ。だから目標は日和見菌の撲滅ではない。無害な菌に戻して共存するしかない。\n世の中の仕組みと全く同じ。この世はごく一部の悪玉菌、善玉菌と、大多数の日和見菌で成り立っている。今の世界も極限までに日和見菌が凶暴化した状況に見える。しかし日和見菌は撲滅対象ではない。\n上記は約一年前、2020年11月19日に書いたメモ書き。たまたま発見した。ここで言っている「日和見菌」とは、99.99%の日本人のことである。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/lgs/","summary":"\u003cp\u003e過去LGS（リーキーガット症候群:Leaky gut syndrome) に罹ったことがあるから、腸内の日和見菌が凶暴化するとどれほど身体と脳が破壊されるか身に染みてわかる。\u003c/p\u003e","title":"Non Title"},{"content":"Pythonライブラリをローカルインストールする必要に迫られて対応した記録。実行した環境はWindowsだが、Linuxでも同様らしい。\npypi.orgにアクセスし、ライブラリ名で検索。対象のwhlファイルをダウンロードし、実行環境に配置する。tar.gz形式の場合もあるが、それもWindowsにインストール可能。\npypi.org\n複数の参考記事によれば以下のようなコマンドが紹介されている。（pipのパスが通っていない場合はpy -m pip ...とする）\n\u0026gt; pip install [Pythonパッケージのパス] しかしそのまま実行すると、pip freeze実行時の出力がおかしい。\n\u0026gt; pip install ./six-1.16.0-py2.py3-none-any.whl \u0026gt; pip freeze six @ file:///C:/Users/xxxxx/six-1.16.0-py2.py3-none-any.whl 一旦アンインストールして、--find-linksオプションを指定して再度インストール。\n\u0026gt; pip install --no-index --find-links=./six-1.16.0-py2.py3-none-any.whl six 上記コマンドにした場合、期待値になる。\n\u0026gt; pip freeze six==1.16.0 ","permalink":"https://ecnedaced-seirots.github.io/post/a/python-package-localinstall/","summary":"\u003cp\u003ePythonライブラリをローカルインストールする必要に迫られて対応した記録。実行した環境はWindowsだが、Linuxでも同様らしい。\u003c/p\u003e","title":"Pythonライブラリのローカルインストール方法"},{"content":"村上龍著「愛と幻想のファシズム」より\n「危機が生じると、弱者がくっきりと浮かび上がるもんだ」\n本当は人間には何の欲望もない。対象があるために欲望が発生するだけだ。もし、欲望の充足、つまり自らの欲望の消去、または消去の過程を、快楽と呼ぶのならば、グリズリーは、永遠の快楽と共に在るということになる。\n俺は結局撃たなかった。そのグリズリーを中心とした完璧な世界の中で、自分のことを余計なものだと感じた。そんなことは初めてだった。ライフルを下げている自分をみじめだと思った。ライフルがなぜ必要かがわかった。人間はあまりにも不完全で、快楽の森林からはっきりと拒絶されているために、ライフルが必要なのだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-4/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e「危機が生じると、弱者がくっきりと浮かび上がるもんだ」\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(4)"},{"content":"AWS Lambdaでサイズがでかいリソースをアップロードすると、こんなメッセージが表示されてコードが見れないことがある。\n日本語\nLambda 関数「xxxxxx-function」のデプロイパッケージが大きすぎて、インラインコード編集を有効にできません。ただし、関数を呼び出すことはできます。\n英語\nThe deployment package of your Lambda function \u0026ldquo;xxxxxx-function\u0026rdquo; is too large to enable inline code editing. However, you can still invoke your function.\nこの時アップロードしたのは、関数自体は空ファイルなのだが（アップロードしてからインラインで記述するつもりだった）モジュールが相当重かったようだ。こういうのは、Lambdaで処理すべきじゃないんだな。EC2上じゃなくてLambdaでサクッと実行できればいいな〜て処理があったのだが、頓挫\u0026hellip;\nそれはしょうがないとして、大分過去に検証した関数をまた見たくなって覗いたら上記のメッセージが出てコードが見れないという事例があったからメモ。って、以下記事にある通りマネコン画面から簡単にエクスポートできるんだけど。\nコンソールで確認できないLambda関数のコードを確認する\n画面右上のActionプルダウンから、\u0026ldquo;Export function\u0026quot;選択。（日本語「関数のエクスポート」）\nCLIだったらaws lambda get-functionでエクスポート可能。でもマネコンからの方が簡単だな。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/lambda-function-export/","summary":"\u003cp\u003eAWS Lambdaでサイズがでかいリソースをアップロードすると、こんなメッセージが表示されてコードが見れないことがある。\u003c/p\u003e","title":"AWS Lambda関数をダウンロードする"},{"content":"過去に類似のテーマで、CloudTrailによるイベント監視 + 通知メールカスタマイズをしてみた。今回はイベントソースをAWS Configにしてみる。\n（10月頃から金太郎飴のように類似の検証を重ね重ねやっていて脳内パズル状態甚だしいが、やらないことには整理ができない\u0026hellip;）\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)\nEventBridgeのルールで変更を検知したいが、ConfigとEventBridgeのルールはそれぞれ独立している様子で、仕組みが今いち不明。基本的にConfigで設定するルールはコンプライアンスに沿っているかどうかをチェックするためのものであり、変更を検知する目的とは意味合いが違うみたいだ。これまでその辺もよくわかっていなかった。実を言うと今もよくわかってはいないが、何はともあれConfigを用意して試す。Configのルールはマネージドのルールから「ec2-instance-profile-attached」をつけておいた。S3バケット、IAMロールは自動で生成させた。\n今回作成したリソース名称。\nアイテム 名称 SNSトピック custom-event-notification Lambda用IAMロール custom-event-mail-role Lambda関数 config-event-function eventルール config-change-notify-rule eventルール(EventBridge)は、当初イベント内容を絞って試したが検知されなかったのでとりあえずAnyにした。\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.config\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;Config Configuration Item Change\u0026#34;] } イベント内容を確認するため、最初は以下のLambdaコードでメールを飛ばしてみる。SNSトピックは環境変数で指定。\nimport json import boto3 import os print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): type = event[\u0026#39;detail-type\u0026#39;] Msg = json.dumps(event) sub = \u0026#39;[AWS Config]\u0026#39; + str(type) client = boto3.client(\u0026#39;sns\u0026#39;) response = client.publish( TopicArn = sns_arn, Message = Msg, MessageStructure = \u0026#39;context\u0026#39;, Subject = sub ) return EC2インスタンスにつけたIAMロールをデタッチしてイベントルールが検知すると、JSONデータが丸ごと送信された。これをJSONファイルとして保存し、解析する。\n\u0026gt;\u0026gt;\u0026gt; event_file = open(\u0026#39;config_sample.json\u0026#39;,\u0026#39;r\u0026#39;) \u0026gt;\u0026gt;\u0026gt; type(event_file) \u0026lt;class \u0026#39;_io.TextIOWrapper\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; event = json.load(event_file) \u0026gt;\u0026gt;\u0026gt; msg = json.dumps(event, indent=3) #JSONを見やすく整形する \u0026gt;\u0026gt;\u0026gt; print(msg) { \u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;07cedb49-ed89-6b1f-3ef7-b02fch9ae318\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Config Configuration Item Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.config\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;012345678910\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-12-26T04:36:35Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [ \u0026#34;arn:aws:ec2:ap-northeast-1:012345678910:instance/i-xxxxxxxxxxxxxxxxx\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;recordVersion\u0026#34;: \u0026#34;1.3\u0026#34;, \u0026#34;messageType\u0026#34;: \u0026#34;ConfigurationItemChangeNotification\u0026#34;, \u0026#34;configurationItemDiff\u0026#34;: { \u0026#34;changedProperties\u0026#34;: { \u0026#34;Configuration.IamInstanceProfile\u0026#34;: { \u0026#34;updatedValue\u0026#34;: { \u0026#34;arn\u0026#34;: \u0026#34;arn:aws:iam::012345678910:instance-profile/test-instance-role\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;AIPBIC67ZVZTAHPSHTWDM\u0026#34; }, \u0026#34;changeType\u0026#34;: \u0026#34;CREATE\u0026#34; } }, \u0026#34;changeType\u0026#34;: \u0026#34;UPDATE\u0026#34; }, (snip) ちなみに実際に取得したevent生データは以下。（一部マスク実施）\n{\u0026#39;version\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;id\u0026#39;: \u0026#39;03696e62-00e3-a8c1-3d1d-854a5153b93e\u0026#39;, \u0026#39;detail-type\u0026#39;: \u0026#39;Config Configuration Item Change\u0026#39;, \u0026#39;source\u0026#39;: \u0026#39;aws.config\u0026#39;, \u0026#39;account\u0026#39;: \u0026#39;012345678901\u0026#39;, \u0026#39;time\u0026#39;: \u0026#39;2021-12-26T04:12:26Z\u0026#39;, \u0026#39;region\u0026#39;: \u0026#39;ap-northeast-1\u0026#39;, \u0026#39;resources\u0026#39;: [\u0026#39;arn:aws:ec2:ap-northeast-1:012345678901:instance/i-xxxxxxxxxxxxxxxxx\u0026#39;], \u0026#39;detail\u0026#39;: {\u0026#39;recordVersion\u0026#39;: \u0026#39;1.3\u0026#39;, \u0026#39;messageType\u0026#39;: \u0026#39;ConfigurationItemChangeNotification\u0026#39;, \u0026#39;configurationItemDiff\u0026#39;: {\u0026#39;changedProperties\u0026#39;: {\u0026#39;Configuration.IamInstanceProfile\u0026#39;: {\u0026#39;previousValue\u0026#39;: {\u0026#39;arn\u0026#39;: \u0026#39;arn:aws:iam::012345678901:instance-profile/system-role\u0026#39;, \u0026#39;id\u0026#39;: \u0026#39;AIPAQNBL2HJCF36XERVQR\u0026#39;}, \u0026#39;changeType\u0026#39;: \u0026#39;DELETE\u0026#39;}}, \u0026#39;changeType\u0026#39;: \u0026#39;UPDATE\u0026#39;}, \u0026#39;notificationCreationTime\u0026#39;: \u0026#39;2021-12-26T04:12:26.909Z\u0026#39;, \u0026#39;configurationItem\u0026#39;: {\u0026#39;relatedEvents\u0026#39;: [], \u0026#39;relationships\u0026#39;: [{\u0026#39;resourceId\u0026#39;: \u0026#39;eni-6v292a2739eb1c95h\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::NetworkInterface\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Contains NetworkInterface\u0026#39;}, {\u0026#39;resourceId\u0026#39;: \u0026#39;sg-02a83b08a8bw1379f\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::SecurityGroup\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Is associated with SecurityGroup\u0026#39;}, {\u0026#39;resourceId\u0026#39;: \u0026#39;subnet-0bw1xc364270607cb\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::Subnet\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Is contained in Subnet\u0026#39;}, {\u0026#39;resourceId\u0026#39;: \u0026#39;vol-027326eaebf1903f2\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::Volume\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Is attached to Volume\u0026#39;}, {\u0026#39;resourceId\u0026#39;: \u0026#39;vpc-1247b576cb69f93d3\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::VPC\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Is contained in Vpc\u0026#39;}], \u0026#39;configuration\u0026#39;: {\u0026#39;amiLaunchIndex\u0026#39;: 0.0, \u0026#39;imageId\u0026#39;: \u0026#39;ami-032s715c7f0f18cue\u0026#39;, \u0026#39;instanceId\u0026#39;: \u0026#39;i-xxxxxxxxxxxxxxxxx\u0026#39;, \u0026#39;instanceType\u0026#39;: \u0026#39;t2.micro\u0026#39;, \u0026#39;keyName\u0026#39;: \u0026#39;My.pem\u0026#39;, \u0026#39;launchTime\u0026#39;: \u0026#39;2021-12-19T02:43:42.000Z\u0026#39;, \u0026#39;monitoring\u0026#39;: {\u0026#39;state\u0026#39;: \u0026#39;disabled\u0026#39;}, \u0026#39;placement\u0026#39;: {\u0026#39;availabilityZone\u0026#39;: \u0026#39;ap-northeast-1a\u0026#39;, \u0026#39;groupName\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;tenancy\u0026#39;: \u0026#39;default\u0026#39;}, \u0026#39;privateDnsName\u0026#39;: \u0026#39;ip-10-0-0-80.ap-northeast-1.compute.internal\u0026#39;, \u0026#39;privateIpAddress\u0026#39;: \u0026#39;10.0.0.80\u0026#39;, \u0026#39;productCodes\u0026#39;: [], \u0026#39;publicDnsName\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;state\u0026#39;: {\u0026#39;code\u0026#39;: 80.0, \u0026#39;name\u0026#39;: \u0026#39;stopped\u0026#39;}, \u0026#39;stateTransitionReason\u0026#39;: \u0026#39;User initiated (2021-12-19 14:36:10 GMT)\u0026#39;, \u0026#39;subnetId\u0026#39;: \u0026#39;subnet-0bw1xc364270607cb\u0026#39;, \u0026#39;vpcId\u0026#39;: \u0026#39;vpc-1247b576cb69f93d3\u0026#39;, \u0026#39;architecture\u0026#39;: \u0026#39;x86_64\u0026#39;, \u0026#39;blockDeviceMappings\u0026#39;: [{\u0026#39;deviceName\u0026#39;: \u0026#39;/dev/xvda\u0026#39;, \u0026#39;ebs\u0026#39;: {\u0026#39;attachTime\u0026#39;: \u0026#39;2020-08-22T09:55:48.000Z\u0026#39;, \u0026#39;deleteOnTermination\u0026#39;: True, \u0026#39;status\u0026#39;: \u0026#39;attached\u0026#39;, \u0026#39;volumeId\u0026#39;: \u0026#39;vol-027326eaebf1903f2\u0026#39;}}], \u0026#39;clientToken\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;ebsOptimized\u0026#39;: False, \u0026#39;enaSupport\u0026#39;: True, \u0026#39;hypervisor\u0026#39;: \u0026#39;xen\u0026#39;, \u0026#39;elasticGpuAssociations\u0026#39;: [], \u0026#39;elasticInferenceAcceleratorAssociations\u0026#39;: [], \u0026#39;networkInterfaces\u0026#39;: [{\u0026#39;attachment\u0026#39;: {\u0026#39;attachTime\u0026#39;: \u0026#39;2020-08-22T09:55:47.000Z\u0026#39;, \u0026#39;attachmentId\u0026#39;: \u0026#39;eni-attach-0d0b8282ec9760266\u0026#39;, \u0026#39;deleteOnTermination\u0026#39;: True, \u0026#39;deviceIndex\u0026#39;: 0.0, \u0026#39;status\u0026#39;: \u0026#39;attached\u0026#39;, \u0026#39;networkCardIndex\u0026#39;: 0.0}, \u0026#39;description\u0026#39;: \u0026#39;Primary network interface\u0026#39;, \u0026#39;groups\u0026#39;: [{\u0026#39;groupName\u0026#39;: \u0026#39;dev-sg-mainte\u0026#39;, \u0026#39;groupId\u0026#39;: \u0026#39;sg-02a83b08a8bw1379f\u0026#39;}], \u0026#39;ipv6Addresses\u0026#39;: [], \u0026#39;macAddress\u0026#39;: \u0026#39;03:02:a0:fc:31:48\u0026#39;, \u0026#39;networkInterfaceId\u0026#39;: \u0026#39;eni-6v292a2739eb1c95h\u0026#39;, \u0026#39;ownerId\u0026#39;: \u0026#39;012345678901\u0026#39;, \u0026#39;privateDnsName\u0026#39;: \u0026#39;ip-10-0-0-80.ap-northeast-1.compute.internal\u0026#39;, \u0026#39;privateIpAddress\u0026#39;: \u0026#39;10.0.0.80\u0026#39;, \u0026#39;privateIpAddresses\u0026#39;: [{\u0026#39;primary\u0026#39;: True, \u0026#39;privateDnsName\u0026#39;: \u0026#39;ip-10-0-0-80.ap-northeast-1.compute.internal\u0026#39;, \u0026#39;privateIpAddress\u0026#39;: \u0026#39;10.0.0.80\u0026#39;}], \u0026#39;sourceDestCheck\u0026#39;: True, \u0026#39;status\u0026#39;: \u0026#39;in-use\u0026#39;, \u0026#39;subnetId\u0026#39;: \u0026#39;subnet-0bw1xc364270607cb\u0026#39;, \u0026#39;vpcId\u0026#39;: \u0026#39;vpc-1247b576cb69f93d3\u0026#39;, \u0026#39;interfaceType\u0026#39;: \u0026#39;interface\u0026#39;}], \u0026#39;rootDeviceName\u0026#39;: \u0026#39;/dev/xvda\u0026#39;, \u0026#39;rootDeviceType\u0026#39;: \u0026#39;ebs\u0026#39;, \u0026#39;securityGroups\u0026#39;: [{\u0026#39;groupName\u0026#39;: \u0026#39;dev-sg-mainte\u0026#39;, \u0026#39;groupId\u0026#39;: \u0026#39;sg-02a83b08a8bw1379f\u0026#39;}], \u0026#39;sourceDestCheck\u0026#39;: True, \u0026#39;stateReason\u0026#39;: {\u0026#39;code\u0026#39;: \u0026#39;Client.UserInitiatedShutdown\u0026#39;, \u0026#39;message\u0026#39;: \u0026#39;Client.UserInitiatedShutdown: User initiated shutdown\u0026#39;}, \u0026#39;tags\u0026#39;: [{\u0026#39;key\u0026#39;: \u0026#39;Name\u0026#39;, \u0026#39;value\u0026#39;: \u0026#39;terraform-kubectl\u0026#39;}], \u0026#39;virtualizationType\u0026#39;: \u0026#39;hvm\u0026#39;, \u0026#39;cpuOptions\u0026#39;: {\u0026#39;coreCount\u0026#39;: 1.0, \u0026#39;threadsPerCore\u0026#39;: 1.0}, \u0026#39;capacityReservationSpecification\u0026#39;: {\u0026#39;capacityReservationPreference\u0026#39;: \u0026#39;open\u0026#39;}, \u0026#39;hibernationOptions\u0026#39;: {\u0026#39;configured\u0026#39;: False}, \u0026#39;licenses\u0026#39;: [], \u0026#39;metadataOptions\u0026#39;: {\u0026#39;state\u0026#39;: \u0026#39;applied\u0026#39;, \u0026#39;httpTokens\u0026#39;: \u0026#39;optional\u0026#39;, \u0026#39;httpPutResponseHopLimit\u0026#39;: 1.0, \u0026#39;httpEndpoint\u0026#39;: \u0026#39;enabled\u0026#39;}, \u0026#39;enclaveOptions\u0026#39;: {\u0026#39;enabled\u0026#39;: False}}, \u0026#39;supplementaryConfiguration\u0026#39;: {}, \u0026#39;tags\u0026#39;: {\u0026#39;Name\u0026#39;: \u0026#39;terraform-kubectl\u0026#39;}, \u0026#39;configurationItemVersion\u0026#39;: \u0026#39;1.3\u0026#39;, \u0026#39;configurationItemCaptureTime\u0026#39;: \u0026#39;2021-12-26T04:12:25.750Z\u0026#39;, \u0026#39;configurationStateId\u0026#39;: 1640491945750.0, \u0026#39;awsAccountId\u0026#39;: \u0026#39;012345678901\u0026#39;, \u0026#39;configurationItemStatus\u0026#39;: \u0026#39;OK\u0026#39;, \u0026#39;resourceType\u0026#39;: \u0026#39;AWS::EC2::Instance\u0026#39;, \u0026#39;resourceId\u0026#39;: \u0026#39;i-xxxxxxxxxxxxxxxxx\u0026#39;, \u0026#39;ARN\u0026#39;: \u0026#39;arn:aws:ec2:ap-northeast-1:012345678901:instance/i-xxxxxxxxxxxxxxxxx\u0026#39;, \u0026#39;awsRegion\u0026#39;: \u0026#39;ap-northeast-1\u0026#39;, \u0026#39;availabilityZone\u0026#39;: \u0026#39;ap-northeast-1a\u0026#39;, \u0026#39;configurationStateMd5Hash\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;resourceCreationTime\u0026#39;: \u0026#39;2021-12-19T02:43:42.000Z\u0026#39;}}} これで大分見やすくなるが、階層が深いためさらに掘りたい場合は以下のようにkey:valueを抽出する。\n\u0026gt;\u0026gt;\u0026gt; dtl = event[\u0026#39;detail\u0026#39;] \u0026gt;\u0026gt;\u0026gt; for k,v in dtl.items(): \u0026gt;\u0026gt;\u0026gt; print(k,v) その結果、以下のように項目を抽出して表示させることにした。コード内のコメント「# さらに通知内容の項目を抽出」以降のあたり。生データだと余計な情報がめっちゃあるけど、通知に必要な情報だけ送信できればいい。\nLambdaコード（カスタマイズ版）\nimport boto3 import json import os from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから詳細項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] # さらに通知内容の項目を抽出 t = e[\u0026#39;time\u0026#39;] # 発生時刻 rce_type = dtl[\u0026#39;configurationItem\u0026#39;][\u0026#39;resourceType\u0026#39;] # リソースタイプ rce_arn = str(e[\u0026#39;resources\u0026#39;]) # リソースARN diff = str(dtl[\u0026#39;configurationItemDiff\u0026#39;]) # 変更内容 # 時刻変換前処理 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) # 件名整形 subject_str = \u0026#34;検証環境 Config変更通知 - \u0026#34; + rce_type # メッセージ本文整形 fix_msg = \u0026#34;AWS Configで変更を検知しました\u0026#34; + \u0026#34;\\n\u0026#34; time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str type_msg = \u0026#34;リソースタイプ:\u0026#34; + \u0026#34;\\n\u0026#34; + rce_type arn_msg = \u0026#34;リソースARN:\u0026#34; \u0026#34;\\n\u0026#34; + rce_arn diff_msg =\u0026#34;変更内容:\u0026#34; \u0026#34;\\n\u0026#34; + diff msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + type_msg + \u0026#34;\\n\\n\u0026#34; + arn_msg + \u0026#34;\\n\\n\u0026#34; + diff_msg + \u0026#34;\\n\\n\u0026#34; try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 変更を加えても通知が来なくて「おかしいなー」と言いつつ、ゴニョゴニョやっているうちにカスタマイズ版の通知メールが届いた。EC2以外の変更でも通用するかわからんが、一応その前提で作ってはいる。ダメだったらまた考えよう。（イベント検知のためインスタンスのIAMロールの「デタッチ/アタッチ」を何度も繰り返してたら、変なエラーメッセージが出るようになった。スパム行為と見做されてしまったかもしれない）\n追記\nConfigの「変更内容」にあたるJSONは、発生したイベントによってはさらにボリュームが増して内容がわかりにくくなる。メールでより内容を把握しやすくするのであれば、このJSONもインデントして表示させるとよい。\ndiff_tmp = dtl[\u0026#39;configurationItemDiff\u0026#39;] #この時点では辞書型 diff = json.dumps(diff_tmp, indent=3) #この時点でStringになる このようにすると、上記サンプルメールの「変更内容」以下のメッセージがインデントされて見やすくなる。\n以下参考記事。Configの監視はLambdaと直接連携するケースもあり、その場合eventの中身も変わってくるようだ。当然Lambdaコードの内容も変わるので注意。以下のなかでは、最初の記事がEventBridgeと連携する例となる。\n参考\nAWS Configの通知内容をLambdaで整形\n【AWS config】設定変更時のみ独自の形式で通知を送る\nAWS Config Rules カスタムルールを作成してみよう\n追記（2024年6月）\nタイムゾーンの変換処理は、Python3.9以降はZoneinfoモジュールを利用するとよい。\nLambda(Python3.9)でzoneinfoを使ってタイムゾーン設定するとかんたん\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail-3/","summary":"\u003cp\u003e過去に類似のテーマで、CloudTrailによるイベント監視 + 通知メールカスタマイズをしてみた。今回はイベントソースをAWS Configにしてみる。\u003c/p\u003e","title":"AWSイベント監視 - Config + EventBridge + Lambdaでメールカスタマイズ"},{"content":"I miss the aiport and airplane vibes.\n\u0026hellip;ということで飛行機専門（＋乗り物系）のTumblrブログのリンク並べてみた。\n以下は2021年暮れ時点でactive。微妙なのもあるが。\ntake flight. So Nice Cars airviation Aviation Lover 以下はnon active。\nStopDreaming.StartFlying Airbus A380 L-AEROPORT Wan Arief Lmran on Tumblr Fuckyeah Airplaness Non activeであっても、ブログを消さないでくれているだけでもありがたい。世界の誰かの「めっちゃ好き！」が、誰かの活力になるんだもんな。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aviation-blog/","summary":"\u003cp\u003eI miss the aiport and airplane vibes.\u003c/p\u003e","title":"飛行機画像ブログのリンク集"},{"content":" murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/english-murmur/","summary":"murmur：ぶつぶつ言う、不満をつぶやく\n類：grumble\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）から拾ったが、他の英文小説にも割と頻繁に登場する単語。それだけ普遍的な行為ということか。","title":"英語メモ - murmur"},{"content":" 俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\n恐怖に勝てるのは興奮だけなんだよ\n厳しさを知ってる奴だけが生き残るんだ、動物だって同じだよ、人間の残飯を漁る熊や狐はすぐに撃たれる、世の中が同じようにずっと続くと思ってる奴はすぐにくたばる、\n「愛と幻想のファシズム」より\n違う本だけど、これも。\nYou\u0026rsquo;re the ones who lose. My laughter will ring in your ears for the rest of your miserable lives.\n（オレはお前らだけには負けないぞ、一生、オレの楽しい笑い声を聞かせてやる\u0026hellip;..)\n「69 sixtynine」より。\nあとこれ。主人公ワヌーバの、究極の一言。\n差別と迫害にあった者にとって頼るべきものは憎悪ではなく肉体と勇気なのである。\n「フィジーの小人」より。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-3/","summary":"\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e俺達は何も知らない。快楽もない。十万人の哀れな日本人が俺を恐れ、あがめるのは、俺が日本人の中では、生態系の情報と快楽を知っているからだ。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(3) 〜「フィジーの小人」も"},{"content":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\nちなみに過去マネコンから実行する手順書いた。\nCloudWatchLogsからS3へログをエクスポートする 今回の検証に使用したアイテム（個人メモ） アイテム 名称 Lambda用IAMロール lambda_basic_execution Lambda関数 log-export-function S3バケット log-export-xxxxxxxx Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。ちなみに対象バケットは、動作不可になるためオブジェクトロックを設定しないこと。\nS3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] } Lambdaコード(Python3.9)\nimport boto3 import collections from datetime import datetime, date, time, timedelta import os def lambda_handler(event, context): log_g = event.get(\u0026#39;loggrp\u0026#39;) key1 = event.get(\u0026#39;key_name\u0026#39;) # 日付情報取得 yesterday = datetime.combine(date.today()-timedelta(1),time()) today = datetime.combine(date.today(),time()) unix_start = datetime(1970,1,1) # 日付範囲指定。範囲は実行時点を基準としたUNIXタイムスタンプの日本時間(+9h) from_t = int((yesterday-unix_start).total_seconds() * 1000) to_t = int((today-unix_start).total_seconds() * 1000) # S3 bucket + prefix定義（bucket/key1/YYYY/mmDD） bucket = os.environ[\u0026#39;S3_BUCKET\u0026#39;] key2 = yesterday.strftime(\u0026#34;%Y\u0026#34;) key3 = yesterday.strftime(\u0026#34;%m-%d\u0026#34;) s3_key = key1 + \u0026#34;/\u0026#34; + key2 + \u0026#34;/\u0026#34; + key3 try: logs = boto3.client(\u0026#39;logs\u0026#39;) response = logs.create_export_task( logGroupName = log_g, fromTime = from_t, to = to_t, destination = bucket, destinationPrefix = s3_key ) except Exception as e: print(e) では、Lambda関数をCLIから実行してみる。ま、普通はEventBridge経由とかでやると思うけど。（でもEventBridgeって引数指定できるんかな？）\n--payloadオプションのロググループ名、S3バケットの最初の階層となるサービス種別（ここではEC2)を指定している。これはJSONなので、file://parameter.jsonなどとしてファイル指定でもよい。\n$ aws lambda invoke --function-name log-export-function \\ --payload \u0026#39;{ \u0026#34;loggrp\u0026#34; : \u0026#34;/ec2/var/log/messages\u0026#34;,\u0026#34;key_name\u0026#34; : \u0026#34;EC2\u0026#34; }\u0026#39; \\ --cli-binary-format raw-in-base64-out \\ response.json 実行すると、Prefixはできていたが中身は書き込みテスト用ファイルしかない。このコード上の仕様は、前日の00:00:00 から当日の00:00:00までをエクスポートの対象としている。指定したロググループのログは、実行した時点で定義された日付範囲に含まれていないためである。\n（つまり、12/18の日中にインスタンスを起動してログが送信されたとする。しかしエクスポート対象は前日の2021-12-17 00:00:00 〜 当日の2021-12-18 00:00:00までとなるため、この期間内にログがなければ対象は存在しないことになる）\nちなみに関数が実行されるEC2のタイムゾーンはUTC。Lamabaの環境変数でタイムゾーンをJSTにするのは非推奨らしいので、コード側で制御するのが望ましい、とのこと。タイムゾーンの問題を考え始めるといつも頭の中がジグソーパズル状態になる。\nLambda のタイムゾーンを環境変数TZで指定してはいけないっていう話\nAWS Lambda でのタイムゾーン変換\n「コード内での時間は常に UTC で扱い、表示する段階でローカル時間に変換する」を意識していればいいかなと思います。\nこれを当てはめると、「コード内の基準はUTCとし、JSTとして処理する必要になった時点でJSTに変換する」と考えればいいか。\nところでPythonでのタイムゾーン変換で検索すると大抵上記リンクと同様にpytzを使ったコードが紹介されている。pytzを使えば簡単なのだが、それができない事情があったから以下のように別の方法でやった。今回のコードではまた別の方法になっているが\u0026hellip;、どこまでも執拗に追ってくるしつこい敵なので、一度タイムゾーン処理単体で記事を書こうかと思う。\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(3) 話がそれたが、翌日再試行して、今度は無事エクスポートが実行された。今回のコード上の指定では以下スクショの階層でログがアップロードされる。（長いランダム文字列のプレフィックス配下に複数のログストリームのプレフィックス、最後に圧縮ログファイル）\nしかし、引数にLambda自体のログを指定するとエクスポートされない。なぜなんだ〜！\u0026hellip;と思ったら、数時間後にリトライしたら期待値になった。試しにひとつログをDLして中身を覗いてみる。\n$ gunzip -c 000000.gz 2021-12-18T09:30:45.236Z START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST このログは、マネコンの画面上ではJST（実際にLambdaを実行した時刻の日本時間）となっている。\n2021-12-18T18:30:45.236+09:00 #Timestamp列の値 START RequestId: 4880df55-4576-4ccd-8edc-daecb18b0686 Version: $LATEST うーん、これでいいのか？コード内でJSTに変換しているけど、逆にしなくていいのか？脳内パズル。\n\u0026hellip;だが、Lambda関数が実行されるUTCのTZから、エクスポート対象のログ範囲をUTCのTZで指定すると、実際にログが吐き出されたJSTの時刻とは異なる日付範囲になる。だから関数でJSTに変換するのは正しい、と捉えてよい気がする。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-export-lambda/","summary":"CloudWatch Logsから、LmabdaでログをS3にエクスポートする。対象のロググループとバケット内の第一階層を引数で指定するようにした。今回の事例ではエクスポートの範囲は「前日0時〜実行当日の0時」となる。\n参考\nboto3 API Reference\nLambdaよりCloudWatchログをS3に保存方法紹介\nちなみに過去マネコンから実行する手順書いた。\nCloudWatchLogsからS3へログをエクスポートする 今回の検証に使用したアイテム（個人メモ） アイテム 名称 Lambda用IAMロール lambda_basic_execution Lambda関数 log-export-function S3バケット log-export-xxxxxxxx Lambda用IAMロールの権限はlogsフルアクセスのみ。S3もいると思ってたがなくてもできた。バケットポリシー側で許可しているからか。S3バケット名は環境変数で指定した。ちなみに対象バケットは、動作不可になるためオブジェクトロックを設定しないこと。\nS3バケットポリシー（log-export-xxxxxxxx）\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::log-export-xxxxxxxx/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } } } ] } Lambdaコード(Python3.9)\nimport boto3 import collections from datetime import datetime, date, time, timedelta import os def lambda_handler(event, context): log_g = event.","title":"CloudWatch LogsからS3にエクスポート(Lambda/Python)"},{"content":"村上龍著「愛と幻想のファシズム」より\n強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\n馬の臓物も、猪の肉も、からだを腹の底から暖める。野生の肉は血管を拡げるのだ。俺達は湧き出すように汗をかく。\n「その婆さんは、よく晴れた日に、二人の孫を連れて、山菜を採りに行ったんだ、そして虎に襲われた、ばあさんは棘のついた木の枝で虎の注意をそらしながら、飛びかかって、虎の耳を食いちぎったんだそうだ、そのばあさんのコメントは中国でも有名になった、圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ、ばあさんは、そう言ったんだとさ」\n「圧倒的に強い敵にギリギリまで追いつめられた時、残された唯一の手段、それは戦うことだ」\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-2/","summary":"\u003cp\u003e村上龍著「愛と幻想のファシズム」より\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e強者は嫌われない。ゴミのような人間達は、強者と同化したがるのだ。\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(2)"},{"content":"何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\n「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\n「止めてくれ、死んじゃうよ」\n「そうだろ、とにかく人間は嫌いなことはできないようになっている、ところがだ、嫌いなことでもやる奴がいる」\n「いるな」\n「いるだろ？」\n「誰だ？」\n「好きなことが何なのか捜すのに疲れた奴、あきらめた連中だ、楽をしたいと思う奴らだよ、そいつらは、奴隷だ」\n「奴隷？」\n「俺は奴隷を信頼しない」\n「どうして？」\n「人を裏切るのは気分が悪いものだ、そうだよな、誰だって人を裏切るのは嫌いなはずだ、だから嫌いなことを普段やってないやつ、つまり奴隷じゃない奴は、とりあえず信頼できるんだ」\n「（略）\u0026hellip;俺は快楽を知っている、狩猟の快楽は他の何よりもすごい、だが俺はその快楽を必死になって手に入れたんだ、あいつらは黙っていても手に入れることができる、努力して手に入れるものに価値があるのというのは、芸術家とスポーツ選手にだけ言えることで、貧乏人には当てはまらない、嘘なんだ」\n「そうだ、俺はいやなんだ、俺は快楽主義者だからな、小さな快楽で我慢しろなんて言われて黙っているのがいやなんだ、\nすっげぇ、いやもうこれ、この年になってもわかるよ、ビンビンくるよ、あぁ、そうなんだよ、本当にそうなんだよ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/ryu-quotes-1/","summary":"\u003cp\u003e何日か前に読了した、村上龍著「愛と幻想のファシズム」より。\u003c/p\u003e\n\u003cp\u003e \u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e「それで、人間というのは、他の動物でもそうだけど、嫌いなことをやり続けると拒絶反応を起こすんだ、病気になるんだよ、トウジお前IBMのセールスマンになれるか？」\u003c/p\u003e\n\u003c/blockquote\u003e","title":"「愛と幻想のファシズム」より(1)"},{"content":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\nま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1214/","summary":"あーあ、今日も、疲れた。気がついたら20時なんだもん、ひっでぇな。\nそして本来やるべきことの、半分もできていない。雑用の波が押し寄せる。言いたいことは多々あるが、ぶちまけ大会するわけにはいかない。このモヤモヤを一体どうしたらいいのか。\nま、でも今日も上手い寿司が食えたからな。寿司だ。寿司が今のオレのプライドを支えてるんだ。","title":"Non title"},{"content":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf 最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026#34;archive_file\u0026#34; \u0026#34;data-lambda-func001\u0026#34; { type = \u0026#34;zip\u0026#34; source_dir = \u0026#34;lambda/code/func001\u0026#34; output_path = \u0026#34;lambda/upload/lambda-func001.zip\u0026#34; } ################################################# # Lambda function ################################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;lambda-func001\u0026#34; { filename = data.archive_file.data-lambda-func001.output_path function_name = \u0026#34;lambda-func001\u0026#34; role = \u0026#34;arn:aws:iam::012345678910:role/send-log-filter-role\u0026#34; handler = \u0026#34;lambda-func001.lambda_handler\u0026#34; source_code_hash = base64sha256(\u0026#34;lambda/upload/lambda-func001.zip\u0026#34;) timeout = 60 runtime = \u0026#34;python3.9\u0026#34; environment { variables = { \u0026#34;SNS_TOPIC_ARN\u0026#34; = \u0026#34;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026#34; } } } ################################################# # Lambda Permission ################################################# resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;func-perm001\u0026#34; { action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = aws_lambda_function.lambda-func001.arn principal = \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; source_arn = \u0026#34;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026#34; } ################################################# # CloudWatchLogs group ################################################# resource \u0026#34;aws_cloudwatch_log_group\u0026#34; \u0026#34;cwl-group001\u0026#34; { name = \u0026#34;log-group001\u0026#34; retention_in_days = \u0026#34;7\u0026#34; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026#34;aws_cloudwatch_log_subscription_filter\u0026#34; \u0026#34;cwl-subscription001\u0026#34; { name = \u0026#34;cwl-filter001\u0026#34; log_group_name = aws_cloudwatch_log_group.cwl-group001.name filter_pattern = \u0026#34;[( msg=\\\u0026#34;*error*\\\u0026#34; || msg=\\\u0026#34;*Error*\\\u0026#34; ) \u0026amp;\u0026amp; ( msg!=\\\u0026#34;*test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*Test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*TEST*\\\u0026#34; )]\u0026#34; destination_arn = aws_lambda_function.lambda-func001.arn } これをapplyするとそれぞれ単体でリソースが作成される。次にloop処理の例。\nlambda_logs.tf（loopバージョン）\n################################################# # Lambda archive data ################################################# data \u0026#34;archive_file\u0026#34; \u0026#34;data-lambda-func\u0026#34; { for_each = var.lambda_param_list source_dir = lookup(each.value, \u0026#34;src_dir\u0026#34;) output_path = lookup(each.value, \u0026#34;out_path\u0026#34;) type = \u0026#34;zip\u0026#34; } ################################################# # Lambda function ################################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;lambda-func\u0026#34; { for_each = var.lambda_param_list filename = lookup(each.value, \u0026#34;out_path\u0026#34;) function_name = lookup(each.value, \u0026#34;func_name\u0026#34;) role = var.lambda_role handler = \u0026#34;${lookup(each.value, \u0026#34;func_name\u0026#34;)}.lambda_handler\u0026#34; source_code_hash = base64sha256(\u0026#34;${lookup(each.value, \u0026#34;out_path\u0026#34;)}\u0026#34;) timeout = 60 runtime = \u0026#34;python3.9\u0026#34; environment { variables = { \u0026#34;SNS_TOPIC_ARN\u0026#34; = var.topic_arn } } } ################################################# # Lambda Permission ################################################# resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;my-func-perm\u0026#34; { for_each = var.lambda_param_list action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = \u0026#34;arn:aws:lambda:ap-northeast-1:012345678910:function:${lookup(each.value, \u0026#34;func_name\u0026#34;)}\u0026#34; principal = \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; source_arn = var.src_arn } ################################################# # CloudWatchLogs group ################################################# resource \u0026#34;aws_cloudwatch_log_group\u0026#34; \u0026#34;cwl-group\u0026#34; { for_each = var.logs_param_list name = lookup(each.value, \u0026#34;log_grp\u0026#34;) retention_in_days = \u0026#34;7\u0026#34; } ################################################# # CloudWatchLogs subscription filter ################################################# resource \u0026#34;aws_cloudwatch_log_subscription_filter\u0026#34; \u0026#34;cwl-subscription\u0026#34; { for_each = var.logs_param_list name = lookup(each.value, \u0026#34;filter\u0026#34;) log_group_name = lookup(each.value, \u0026#34;log_grp\u0026#34;) filter_pattern = lookup(each.value, \u0026#34;pattern\u0026#34;) destination_arn = aws_lambda_function.lambda-func[\u0026#34;param1\u0026#34;].arn } archive_fileによりTerraformがLambda用のzipファイルを生成してくれる。source_code_hashがzipのハッシュ値の差分をチェックして変更があればデプロイする。と、いうことだがこの記述だとコードを変更しなくても都度zipファイルが生成されてタイムスタンプが更新され、変更していなくても変更したと判断されてデプロイされる。デプロイされてもコードは同じだから害はないんだが、どうも納得がいかん。変更扱いにしたくなければarchive_fileのブロックを全部コメントしておくか、source_code_hashをコメントするか。どういう運用がいいんだろう？\nちなみに最初のapplyは比較対象のzipファイルがなくてエラーになるため、source_code_hashは初回のみコメントアウトしておく。\nsubscription filterで、Lambdaをloopで作ったのにここで単体で指定しているのは、こういう例もあるということで。この参照の場合は、logs_param_listにLambdaのARNの変数が存在しなくても問題ない。\nlambda.auto.tfvars（tfコードが参照する変数）\n################################################# # Lambda function loop vars ################################################# lambda_param_list = { param1 = { src_dir = \u0026#34;lambda/code/func001\u0026#34; out_path = \u0026#34;lambda/upload/lambda-func001.zip\u0026#34; func_name = \u0026#34;lambda-func001\u0026#34; } param2 = { src_dir = \u0026#34;lambda/code/func002\u0026#34; out_path = \u0026#34;lambda/upload/lambda-func002.zip\u0026#34; func_name = \u0026#34;lambda-func002\u0026#34; } param3 = { src_dir = \u0026#34;lambda/code/func003\u0026#34; out_path = \u0026#34;lambda/upload/lambda-func003.zip\u0026#34; func_name = \u0026#34;lambda-func003\u0026#34; } } ################################################# # Lambda function vars ################################################# lambda_role = \u0026#34;arn:aws:iam::012345678910:role/send-log-filter-role\u0026#34; topic_arn = \u0026#34;arn:aws:sns:ap-northeast-1:012345678910:log-monitor-topic\u0026#34; ################################################# # Lambda Permission vars ################################################# src_arn = \u0026#34;arn:aws:logs:ap-northeast-1:012345678910:log-group:*:*\u0026#34; ################################################# # CloudWatchLogs group \u0026amp; filter loop vars ################################################# logs_param_list = { param1 = { log_grp = \u0026#34;log-group001\u0026#34; filter = \u0026#34;logs-filter001\u0026#34; pattern = \u0026#34;[( msg=\\\u0026#34;*error*\\\u0026#34; || msg=\\\u0026#34;*Error*\\\u0026#34; ) \u0026amp;\u0026amp; ( msg!=\\\u0026#34;*test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*Test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*TEST*\\\u0026#34; )]\u0026#34; } param2 = { log_grp = \u0026#34;log-group002\u0026#34; filter = \u0026#34;logs-filter002\u0026#34; pattern = \u0026#34;[( msg=\\\u0026#34;*error*\\\u0026#34; || msg=\\\u0026#34;*ERROR*\\\u0026#34; ) \u0026amp;\u0026amp; ( msg!=\\\u0026#34;*test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*Test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*TEST*\\\u0026#34; )]\u0026#34; } param3 = { log_grp = \u0026#34;log-group003\u0026#34; filter = \u0026#34;logs-filter003\u0026#34; pattern = \u0026#34;[( msg=\\\u0026#34;*FAIL*\\\u0026#34; || msg=\\\u0026#34;*fail*\\\u0026#34; || msg=\\\u0026#34;*Fail*\\\u0026#34; ) \u0026amp;\u0026amp; ( msg!=\\\u0026#34;*test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*Test*\\\u0026#34; \u0026amp;\u0026amp; msg!=\\\u0026#34;*TEST*\\\u0026#34; )]\u0026#34; } } フィルタパターンが汚なくて見るに耐えないがこればかりはどうしようもない\u0026hellip;\nvariables.tf（宣言のみ）\n################################## # main ################################## variable \u0026#34;region\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################################## # lambda loop ################################## variable \u0026#34;lambda_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } ################################## # lambda role ################################## variable \u0026#34;lambda_role\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################################## # topic ################################## variable \u0026#34;topic_arn\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################################## # lambda parmission ################################## variable \u0026#34;src_arn\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################################## # logs loop ################################## variable \u0026#34;logs_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } これによりログ監視に必要なリソースが一気に作成される。最初にコード書くのは面倒だけど、やっぱり自動化の仕組み作っておくと楽だな。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-5/","summary":"今日のTerraform loopネタはLambda関数作成。ログ監視の一貫なので、CloudWatchLogsのロググループとサブスクリプションフィルタ作成も一緒にやる。\nこの例でのディレクトリ構成は以下の通り。lambda/upload配下のzipファイルはTerraformにより生成されたもので、初回は空である。\nwork_dir ├── config.tf #初期化ファイル ├── lambda │ ├── code │ │ ├── func001 │ │ │ └── lambda-func001.py │ │ ├── func002 │ │ │ └── lambda-func002.py │ │ └── func003 │ │ └── lambda-func003.py │ └── upload │ ├── lambda-func001.zip │ ├── lambda-func002.zip │ └── lambda-func003.zip ├── lambda.auto.tfvars ├── lambda_cwl.tf ├── terraform.tfvars #regionのみ定義 └── variables.tf 最初に、すべて定数で記述したパターン。\nlambda_logs.tf（定数バージョン）\n################################################# # Lambda archive data ################################################# data \u0026#34;archive_file\u0026#34; \u0026#34;data-lambda-func001\u0026#34; { type = \u0026#34;zip\u0026#34; source_dir = \u0026#34;lambda/code/func001\u0026#34; output_path = \u0026#34;lambda/upload/lambda-func001.","title":"Terraform loop処理の応用編(4) - Lambda"},{"content":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026#34;aws_cloudwatch_event_rule\u0026#34; \u0026#34;pln-rule\u0026#34; { for_each = var.events_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) description = \u0026#34;Start the pipeline when detect CodeCommit repository state change.\u0026#34; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026#34;source\u0026#34;: [\u0026#34;aws.codecommit\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;CodeCommit Repository State Change\u0026#34;], \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026#34;repo_name\u0026#34;)}\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;event\u0026#34;: [\u0026#34;referenceCreated\u0026#34;, \u0026#34;referenceUpdated\u0026#34;], \u0026#34;referenceType\u0026#34;: [\u0026#34;branch\u0026#34;], \u0026#34;referenceName\u0026#34; : [\u0026#34;master\u0026#34;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026#34;aws_cloudwatch_event_target\u0026#34; \u0026#34;pln-rule\u0026#34; { for_each = var.events_param_list rule = lookup(each.value, \u0026#34;name\u0026#34;) arn = lookup(each.value, \u0026#34;pipeline\u0026#34;) role_arn = var.events_role depends_on = [aws_cloudwatch_event_rule.pln-rule] } 当初event_patternのJSONはJSONファイルを外出しにしてファイル名指定でいくつもりだった。が、loop処理で回すのができなかった。いくつか試したのだが\u0026hellip;。パターンとしては可変になるのがCodeCommitリポジトリ名だけなので、そこをloopで回せばいけるんじゃないかと思いヒアドキュメントでやったらできた。このような場合JSONファイルをルールの数だけ用意するより、ヒアドキュメントの方が意外と楽だ。\nJSON定義の一部。以下の\u0026quot;repo_name\u0026quot;に対して、変数リストから取り出したCodeCommitリポジトリ名が格納される。\n\u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026#34;repo_name\u0026#34;)}\u0026#34;], loop処理が参照する変数リストは以下の通り。\nrule.auto.tfvars\n################### # rule vars ################### events_param_list = { param1 = { name = \u0026#34;cicd-event001\u0026#34; pipeline = \u0026#34;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline001\u0026#34; repo_name = \u0026#34;repo001\u0026#34; } param2 = { name = \u0026#34;cicd-event002\u0026#34; pipeline = \u0026#34;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline002\u0026#34; repo_name = \u0026#34;repo002\u0026#34; } param3 = { name = \u0026#34;cicd-event003\u0026#34; pipeline = \u0026#34;arn:aws:codepipeline:ap-northeast-1:012345678910:pipeline003\u0026#34; repo_name = \u0026#34;repo003\u0026#34; } } ################### # Events role ################### events_role = \u0026#34;arn:aws:iam::012345678910:role/codepipeline-exe-role\u0026#34; 上記ルールだけapplyした結果、成功。CICDリソース作成用のtfコードも含めて実行した結果も、成功。\nちなみにイベントルールを別途作成しない場合、パイプラインに紐付くルールが自動で生成される。ルールを実行するためのIAMロールも、ルールと1:1で個別に自動生成される。親切と言えば親切だが、そんなにボコボコ作られてもなー、と思った。このIAMロールはリソースとして指定したCodePipelineを実行するだけだから、リソースを* にすればひとつで事足りる。各アイテムの名称も管理下におきたい。\n\u0026hellip;ということで、ここでは自動生成ではなく別途ルールを作成したけれども、そこまでこだわらないのであれば自動生成でもいいだろう。\nおまけ\nCodePipelineより汎用的によく利用されるであろう、CloudWatch アラームの例。\nevent_pattern=\u0026lt;\u0026lt;-EOT { \u0026#34;source\u0026#34;:[\u0026#34;aws.cloudwatch\u0026#34;], \u0026#34;detail-type:[\u0026#34;CloudWatch Alarm State Change\u0026#34;], \u0026#34;resources\u0026#34;:[{ \u0026#34;prefix\u0026#34;:\u0026#34;arn:aws:cloudwatch:ap-northeast-1:${var.account.id}:alarm${lookup(each.value, \u0026#34;alarm_name\u0026#34;)}\u0026#34;}], \u0026#34;detail\u0026#34;:{ \u0026#34;state\u0026#34;:{ \u0026#34;value\u0026#34;:[\u0026#34;ALARM\u0026#34;] } } } EOT ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-4/","summary":"過去記事Terraform loop処理の応用編(2)で、AWS Code兄弟のリソースをTerraformのloop処理で作成した。それとは別に、CodePipelineのトリガーをEventBridgeルールにしたかったので追加処理を書いた。パイプラインの数だけ対応するルールを作成するため、これもloop処理で書く。Code兄弟の分も含めて全て同じtfファイルにまとめてもよいが、ここでは分割している。\n以下tfコード本体に、ルールとターゲットを作成する処理を書く。\nevent_rule.tf\n######################################## # EventBridge rule ######################################## resource \u0026#34;aws_cloudwatch_event_rule\u0026#34; \u0026#34;pln-rule\u0026#34; { for_each = var.events_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) description = \u0026#34;Start the pipeline when detect CodeCommit repository state change.\u0026#34; event_pattern = \u0026lt;\u0026lt;-EOT { \u0026#34;source\u0026#34;: [\u0026#34;aws.codecommit\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;CodeCommit Repository State Change\u0026#34;], \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:codecommit:ap-northeast-1:012345678910:${lookup(each.value, \u0026#34;repo_name\u0026#34;)}\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;event\u0026#34;: [\u0026#34;referenceCreated\u0026#34;, \u0026#34;referenceUpdated\u0026#34;], \u0026#34;referenceType\u0026#34;: [\u0026#34;branch\u0026#34;], \u0026#34;referenceName\u0026#34; : [\u0026#34;master\u0026#34;] } } EOT } ######################################## # EventBridge target ######################################## resource \u0026#34;aws_cloudwatch_event_target\u0026#34; \u0026#34;pln-rule\u0026#34; { for_each = var.","title":"Terraform loop処理の応用編(3) - Event rule"},{"content":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\nでも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns/","summary":"\u0026ldquo;SNS\u0026quot;は\u0026quot;Social Networking Service\u0026quot;の略だ。この言葉の上では、プラットフォーム自体がサービスなのだ。しかし、そこに参加した途端に、自分自身が他者にサービスせざるを得なくなる。俗に言う、フォロバとかいいね返しとか、そういうことだ。\nそういうのは嫌いだ、しかしそこに参加している限り、鍵垢でもない限り、その渦から完全に逃れることはできない、この、人付き合いが嫌いな俺様であってもだ、しかし嫌いなものは嫌いなんだ、反応に対していちいち反応してたら自分のやりたいことができないし、余計にエネルギーを使うことになる。つまり、反応した相手の投稿をチェックするという作業自体が余剰作業なのだ、他人にサービスするためにやってるんじゃないからね。\nこれは、SNSの面倒で嫌いな部分だが、いいこともある、「反応に対する反応」により、センスがいいナイスなアカウントを発見することも多々あるからだ。tumblrの場合、ナイスなポストがあればreblogするし、この人は光る何かを持っている、とピピっときたらフォローせざるを得ない。相手が素晴らしいセンスの持ち主だと、サービスを通り越して夢中になってしまうこともある。\nでも最近疲れてきたな、夢中になりすぎて疲れたのか、疲れたから夢中になれなくなったのか知らんが、あまり楽しくない。結局「お付き合い」の比重が多くなると、本来の目的からずれてしまうんだ、リアルワールドでやることのプライオリティが上がっているせいもあるな。\nしかしよく考えると、SNSとの付き合いなんてそれくらいか、それより低程度がいいのである、本来は。リアルワールドで重要なことが多いほど、SNSにかまけていられる時間やエネルギーは減る。つまり、「あんまり楽しくない」程度に捉えている方が自然なのである。\nそういう意味では、俺もやっと自然に戻れたんだろうか。","title":"ソーシャルな反応に対する反応とか"},{"content":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\ncicd.tf\n#################################### # CodeCommit #################################### resource \u0026#34;aws_codecommit_repository\u0026#34; \u0026#34;codecommit_repos\u0026#34; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026#34;repository_name\u0026#34;) description = lookup(each.value, \u0026#34;description\u0026#34;) } #################################### # CodeDeploy Application #################################### resource \u0026#34;aws_codedeploy_app\u0026#34; \u0026#34;codedeploy\u0026#34; { for_each = var.deploy_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) compute_platform = \u0026#34;Server\u0026#34; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026#34;aws_codedeploy_deployment_group\u0026#34; \u0026#34;codedeploy_grp\u0026#34; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026#34;name\u0026#34;) deployment_group_name = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026#34;CodeDeployDefault.AllAtOnce\u0026#34; ec2_tag_set { ec2_tag_filter { key = \u0026#34;Name\u0026#34; type = \u0026#34;KEY_AND_VALUE\u0026#34; value = lookup(each.value, \u0026#34;value\u0026#34;) } } deployment_style { deployment_option = \u0026#34;WITHOUT_TRAFFIC_CONTROL\u0026#34; deployment_type = \u0026#34;IN_PLACE\u0026#34; } auto_rollback_configuration { enabled = true events = [\u0026#34;DEPLOYMENT_FAILURE\u0026#34;] } } #################################### # CodePipeline #################################### resource \u0026#34;aws_codepipeline\u0026#34; \u0026#34;pipeline\u0026#34; { for_each = var.pipeline_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) role_arn = var.pipeline_role artifact_store { location = var.bucket type = \u0026#34;S3\u0026#34; } stage { name = \u0026#34;Source\u0026#34; action { category = \u0026#34;Source\u0026#34; configuration = { BranchName = \u0026#34;master\u0026#34; PollForSourceChanges = \u0026#34;true\u0026#34; RepositoryName = lookup(each.value, \u0026#34;repository_name\u0026#34;) } input_artifacts = [] name = \u0026#34;Source\u0026#34; namespace = \u0026#34;SourceVariables\u0026#34; output_artifacts = [\u0026#34;SourceArtifact\u0026#34;] owner = \u0026#34;AWS\u0026#34; provider = \u0026#34;CodeCommit\u0026#34; region = var.region run_order = 1 version = \u0026#34;1\u0026#34; } } stage { name = \u0026#34;Deploy\u0026#34; action { category = \u0026#34;Deploy\u0026#34; configuration = { ApplicationName = lookup(each.value, \u0026#34;app_name\u0026#34;) DeploymentGroupName = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) } input_artifacts = [\u0026#34;SourceArtifact\u0026#34;] name = \u0026#34;Deploy\u0026#34; namespace = \u0026#34;DeployVariables\u0026#34; output_artifacts = [] owner = \u0026#34;AWS\u0026#34; provider = \u0026#34;CodeDeploy\u0026#34; region = var.region run_order = 1 version = \u0026#34;1\u0026#34; } } } cicd.auto.tfvars\n######################################## # codecommit repos vars ######################################## codecommit_param_list = { param1 = { repository_name = \u0026#34;repo001\u0026#34; description = \u0026#34;desciption for repo001\u0026#34; } param2 = { repository_name = \u0026#34;repo002\u0026#34; description = \u0026#34;desciption for repo002\u0026#34; } param3 = { repository_name = \u0026#34;repo003\u0026#34; description = \u0026#34;desciption for repo003\u0026#34; } } ######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026#34;deploy_app001\u0026#34; deployment_group_name = \u0026#34;deploy_grp001\u0026#34; value = \u0026#34;ec2-tag001\u0026#34; } param2 = { name = \u0026#34;deploy_app002\u0026#34; deployment_group_name = \u0026#34;deploy_grp002\u0026#34; value = \u0026#34;ec2-tag002\u0026#34; } param3 = { name = \u0026#34;deploy_app003\u0026#34; deployment_group_name = \u0026#34;deploy_grp003\u0026#34; value = \u0026#34;ec2-tag003\u0026#34; } } ######################################## # codedeploy vars ######################################## pipeline_param_list = { param1 = { name = \u0026#34;pipeline001\u0026#34; app_name = \u0026#34;deploy_app001\u0026#34; deployment_group_name = \u0026#34;deploy_grp001\u0026#34; repository_name = \u0026#34;repo001\u0026#34; } param2 = { name = \u0026#34;pipeline002\u0026#34; app_name = \u0026#34;deploy_app002\u0026#34; deployment_group_name = \u0026#34;deploy_grp002\u0026#34; repository_name = \u0026#34;repo002\u0026#34; } param3 = { name = \u0026#34;pipeline003\u0026#34; app_name = \u0026#34;deploy_app003\u0026#34; deployment_group_name = \u0026#34;deploy_grp003\u0026#34; repository_name = \u0026#34;repo003\u0026#34; } } ######################################## # CI/CD IAM role vars ######################################## deploy_role = \u0026#34;arn:aws:iam::[aws-account-id]:role/CodeDeployRole\u0026#34; pipeline_role = \u0026#34;arn:aws:iam::[aws-account-id]:role/PipelineRole\u0026#34; ######################################## # S3 vars ######################################## bucket = \u0026#34;codepipeline-bucket-name\u0026#34; variables.tf （宣言のみ）\n################# # main ################# variable \u0026#34;region\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################# # IAM ################# variable \u0026#34;deploy_role\u0026#34; { type = string description = \u0026#34;\u0026#34; } variable \u0026#34;pipeline_role\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################# # S3 ################# variable \u0026#34;bucket\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################# # codecommit ################# variable \u0026#34;codecommit_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } ################# # codedeploy ################# variable \u0026#34;deploy_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } ################# # codepipeline ################# variable \u0026#34;pipeline_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } cicd.tfのPollForSourceChangesはトリガーの定義だが、EventBridgeルール経由でやるのが望ましいから本来はfalseにする想定。ルールを別途作成する必要があるが、それが面倒なので一旦trueにしておいた。（関連付けたルールが存在しない場合、勝手に作成される）\nこれで実行したところ、一応期待値になった。ルールは、各パイプラインとルールがペアになるように個別に作成する。ルールが使用するIAMロールは共通のひとつでよい。このIAMの権限はコードパイプラインをスタートするだけなのだが、リソースを*にして共通で使えばよい。\nところでtfvarsでloop処理が参照するmap変数をサービス毎に分割しているが、分ける必要ないんじゃね？と思った。重複している値が複数あって、冗長だ。key名を適当に変えれば、同じparam_listで全部賄えそうな気がしてきた。次回の課題。\n追記\n後日param_listを全部まとめるバージョンでやってみたところ、期待値になった。だからリソース毎に個別にリストを作成する必要はない。ただし、それは参照されるリストの要素の数が全部揃っている場合。\n例えばloopで作成するCodeCommitリポジトリの数が10でCodeDeploy、CodePipelineの数は8、とかだったら共通のリストにすると失敗する。このようなケースでは、CodeCommitのリストとCodeDeploy/CodePipeline用のリストは別に分ける必要がある。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-3/","summary":"前回投稿Terraform loop処理の応用編 の続き。CodeDeployを作成するTerraformコードに、CodeCommit, CodePipelineを追加して通して作ってみる。\ncicd.tf\n#################################### # CodeCommit #################################### resource \u0026#34;aws_codecommit_repository\u0026#34; \u0026#34;codecommit_repos\u0026#34; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026#34;repository_name\u0026#34;) description = lookup(each.value, \u0026#34;description\u0026#34;) } #################################### # CodeDeploy Application #################################### resource \u0026#34;aws_codedeploy_app\u0026#34; \u0026#34;codedeploy\u0026#34; { for_each = var.deploy_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) compute_platform = \u0026#34;Server\u0026#34; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026#34;aws_codedeploy_deployment_group\u0026#34; \u0026#34;codedeploy_grp\u0026#34; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026#34;name\u0026#34;) deployment_group_name = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.","title":"Terraform loop処理の応用編(2) - CI/CD"},{"content":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026#34;aws_codedeploy_app\u0026#34; \u0026#34;codedeploy\u0026#34; { for_each = var.deploy_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) compute_platform = \u0026#34;Server\u0026#34; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026#34;aws_codedeploy_deployment_group\u0026#34; \u0026#34;codedeploy_grp\u0026#34; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026#34;name\u0026#34;) deployment_group_name = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) service_role_arn = var.deploy_role deployment_config_name = \u0026#34;CodeDeployDefault.AllAtOnce\u0026#34; ec2_tag_set { ec2_tag_filter { key = \u0026#34;Name\u0026#34; type = \u0026#34;KEY_AND_VALUE\u0026#34; value = lookup(each.value, \u0026#34;value\u0026#34;) } } deployment_style { deployment_option = \u0026#34;WITHOUT_TRAFFIC_CONTROL\u0026#34; deployment_type = \u0026#34;IN_PLACE\u0026#34; } auto_rollback_configuration { enabled = true events = [\u0026#34;DEPLOYMENT_FAILURE\u0026#34;] } } cicd.auto.tfvars（cicd.tfが参照する変数）\n######################################## # codedeploy vars ######################################## deploy_param_list = { param1 = { name = \u0026#34;deploy_app001\u0026#34; deployment_group_name = \u0026#34;deploy_grp001\u0026#34; value = \u0026#34;ec2-tag001\u0026#34; } param2 = { name = \u0026#34;deploy_app002\u0026#34; deployment_group_name = \u0026#34;deploy_grp002\u0026#34; value = \u0026#34;ec2-tag002\u0026#34; } param3 = { name = \u0026#34;deploy_app003\u0026#34; deployment_group_name = \u0026#34;deploy_grp003\u0026#34; value = \u0026#34;ec2-tag003\u0026#34; } } ######################################## # CodeDeploy IAM role var ######################################## deploy_role = \u0026#34;arn:aws:iam::[my-account-id]:role/CodeDeployRole\u0026#34; variables.tf （宣言のみ行う）\n################# # main ################# variable \u0026#34;region\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################# # IAM ################# variable \u0026#34;deploy_role\u0026#34; { type = string description = \u0026#34;\u0026#34; } ################# # codedeploy ################# variable \u0026#34;deploy_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } この状態で、plan実行時はエラーなし。しかしapplyしたところ、以下のエラーになった。参照するアプリケーション\u0026quot;deploy_app001\u0026quot;がないよ、と。\nNo application found for name: deploy_app001\nこの時点でマネコンから確認すると、アプリケーションは出来ているが配下のデプロイメントグループが存在しない状態。実際にはdeploy_app00*は作成されているのだが、terraform実行時にうまく参照できていないらしい。当初、特別な記述をしなくてもTerraformがよしなにやってくれるもんだと思っていたんだけどなぁ。\n│ Error: Error creating CodeDeploy deployment group: ApplicationDoesNotExistException: No application found for name: deploy_app001 │ │ with aws_codedeploy_deployment_group.codedeploy_grp[\u0026quot;param1\u0026quot;], │ on cicd.tf line 16, in resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot;: │ 16: resource \u0026quot;aws_codedeploy_deployment_group\u0026quot; \u0026quot;codedeploy_grp\u0026quot; { │ この後でもう一回applyすると、今度はデプロイメントグループ（deploy_app00*）が作成された。しかし初回にエラーになるのはよろしくない。ありがちな事象だから何らかのソリューションはあるだろう、と調べる。\n以下はツールGraphvizにより出力した、この時点におけるTerraformリソースの依存関係を表したグラフ。aws_codedeploy_appとaws_codedeploy_deployment_groupが並列になっていて、互いに関連を持たないように見える。（記事では削っているが実はCodeCommitの記述も含まれているため、グラフに表現されている）\nTerraformの依存関係の定義には「暗黙的な依存関係定義」と「明示的な依存関係定義」の2種類がある。後者は、前者が利用できないケースで使用するべき、とのこと。\n暗黙的な依存関係定義は、公式ドキュメントにもよく登場する role_arn = aws_iam_role.role001.arnといった記述で、意識せずとも普段から書いているやつ。今回みたく参照リソースがloopの場合、個別の値はaws_codedeploy_app.codedeploy[\u0026quot;param1\u0026quot;].idのような記述になるが、参照する側もloopだからこの方式では書けない。\n一方、明示的な依存関係はdepends_onを利用する。\ndepends_on = [aws_iam_role.role001] 以下の記事を読むとloop処理の場合は別の記述方法が要るようなこと書いてあった。面倒くさそうだなぁ〜、と引いてしまう。（こちらはloop処理をcountで実行）\nTerraformリソース間の依存関係を確認する\nしかし以下フォーラムによれば、for_eachの場合これだけでいけそうではある。\nFor_each depends_on\nと、いうことでやってみる。一旦destroyしてクリーンにしてから、cicd.tfにdepends_on = [aws_codedeploy_app.codedeploy] 1行を追記。\nこの時点で、グラフを出力すると以下の通りに変化した。一応参照関係が描かれているように見える。\n再びapplyしたところ成功。loop処理でも、for_eachはdepends_on記述だけでOKと判明した。やれやれ。\n更新版のcicd.tf\n#################################### # CodeDeploy Application #################################### resource \u0026#34;aws_codedeploy_app\u0026#34; \u0026#34;codedeploy\u0026#34; { for_each = var.deploy_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) compute_platform = \u0026#34;Server\u0026#34; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026#34;aws_codedeploy_deployment_group\u0026#34; \u0026#34;codedeploy_grp\u0026#34; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026#34;name\u0026#34;) deployment_group_name = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) depends_on = [aws_codedeploy_app.codedeploy] service_role_arn = var.deploy_role deployment_config_name = \u0026#34;CodeDeployDefault.AllAtOnce\u0026#34; ec2_tag_set { ec2_tag_filter { key = \u0026#34;Name\u0026#34; type = \u0026#34;KEY_AND_VALUE\u0026#34; value = lookup(each.value, \u0026#34;value\u0026#34;) } } deployment_style { deployment_option = \u0026#34;WITHOUT_TRAFFIC_CONTROL\u0026#34; deployment_type = \u0026#34;IN_PLACE\u0026#34; } auto_rollback_configuration { enabled = true events = [\u0026#34;DEPLOYMENT_FAILURE\u0026#34;] } } ちなみにec2_tag_filterは、apply実行時に指定したタグを持つEC2インスタンスが存在しなくても成功する。あとはこれに、前半にCodeCommit, 後半にCodePipelineを追加して、一気にCI/CDリソース作成目指したい。\n余談：Graphvizインストール 参照した記事に記載があって気になったので入れてみた。本来はdot言語で記述したテキストデータをグラフで表現してくれるもので、terraform以外でも使える。現状深掘りしてる余裕はないけど別の機会に遊んでみよう。\nテキストデータをグラフ画像に変換するツール「Graphviz」ことはじめ\nGraphvizとdot言語でグラフを描く方法のまとめ\n$ brew install graphviz （すっげぇ膨大な依存関係ライブラリが一緒に入ってくる...） $ dot -V dot - graphviz version 2.49.3 (20211023.0002) Terraform作業ディレクトリ内で、以下のようなコマンドを実行してグラフを出力する。\n$ terraform graph | dot -Tpng \u0026gt; cicd_graph.png ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example-2/","summary":"過去記事Terraform loop処理の超シンプルな例 の続き。loopで作成したTerraformリソースの参照方法を検証したらやはりハマったので記録書いておく。\n前回はCodeCommitリポジトリを作成したが、今回はそれ抜きでCodeDeployのリソースを作成した。CodeDeployは (1)アプリケーションと、(2)デプロイメントグループの2つのリソースを作成する。(2)は(1)に依存している。\n作業ディレクトリ構成\nwork_dir ├── cicd.auto.tfvars ├── cicd.tf ├── config.tf #初期化用config ├── terraform.tfvars #regionのみ定義 └── variables.tf cicd.tf （リソース作成用コード）\n#################################### # CodeDeploy Application #################################### resource \u0026#34;aws_codedeploy_app\u0026#34; \u0026#34;codedeploy\u0026#34; { for_each = var.deploy_param_list name = lookup(each.value, \u0026#34;name\u0026#34;) compute_platform = \u0026#34;Server\u0026#34; } #################################### # CodeDeploy Deployment Group #################################### resource \u0026#34;aws_codedeploy_deployment_group\u0026#34; \u0026#34;codedeploy_grp\u0026#34; { for_each = var.deploy_param_list app_name = lookup(each.value, \u0026#34;name\u0026#34;) deployment_group_name = lookup(each.value, \u0026#34;deployment_group_name\u0026#34;) service_role_arn = var.deploy_role deployment_config_name = \u0026#34;CodeDeployDefault.AllAtOnce\u0026#34; ec2_tag_set { ec2_tag_filter { key = \u0026#34;Name\u0026#34; type = \u0026#34;KEY_AND_VALUE\u0026#34; value = lookup(each.","title":"Terraform loop処理の応用編"},{"content":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 Python - Jinja2テンプレートで連続データを処理したい\n実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv codecommit.tmpl\nparam{{ num }} = { repository_name = \u0026#34;{{ repo_name }}\u0026#34; description = \u0026#34;{{ des }}\u0026#34; } data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026#34;my-repo001\u0026#34;,\u0026#34;my-repo001の説明\u0026#34; 2,\u0026#34;my-repo002\u0026#34;,\u0026#34;my-repo002の説明\u0026#34; 3,\u0026#34;my-repo003\u0026#34;,\u0026#34;my-repo003の説明\u0026#34; create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;./\u0026#39;, encoding=\u0026#39;utf8\u0026#39;)) tmpl = env.get_template(template) # CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, header=0 ) # CSVデータをJSONに変換 df.to_json(\u0026#39;data.json\u0026#39;) df_js = pd.read_json(\u0026#34;data.json\u0026#34;) # 代入処理。テンプレートにデータを投入後、変数ファイル(xxx.auto.vars)に書き出す。 def loop(): pre = n + \u0026#39;_param_list = {\u0026#39; + \u0026#39;\\n\u0026#39; end = \u0026#39;}\u0026#39;+ \u0026#39;\\n\u0026#39; with open(varsfile, \u0026#39;w\u0026#39;) as f: f.write(pre) for i in range(len(df_js)): data = df_js.iloc[i] config = tmpl.render(data) f.write(config) f.write(\u0026#39;\\n\u0026#39;) f.write(end) loop() if __name__ == \u0026#34;__main__\u0026#34;: args = sys.argv if len(args) == 2: n = args[1] template = n + \u0026#39;.tmpl\u0026#39; varsfile = n + \u0026#39;.auto.tfvars\u0026#39; main() else: print (\u0026#39;Usage: Specify one of AWS resource name. e.g. s3,iam,cloudwatch...etc.\u0026#39;) sys.exit() CSVファイルのヘッダー列の値と、xxxx.tmplファイル内の代入箇所の値は一致させる。すると代入処理時に特に指定しなくてもうまいことやってくれる。pandasのヘッダー行の扱いがよくわからなくてはまったが、一応上記で期待値になった。CSV読み込み時はheaderを指定しなくても勝手に判断してこれもうまいことやってくれるらしいが、一応作法としてheader=0を指定。\nヘッダーあり・なしで挙動が変わり、認識させるために複数の方法があるが、あれこれ考えるの面倒だから、CSVにヘッダ入れておくのが一番簡単だろうと思った。ちなみに当初はこんな記述にしてた。namesがカラム名となるのだが、これを定数ではなく自動で取得したいというモチベーションにより、結果的に上記の通りになった。\n変更前のCSV読み込み処理（この時点ではCSVのヘッダーなし）\n# CSV読み込み df = pd.read_csv(\u0026#34;data.csv\u0026#34;, encoding=\u0026#39;utf-8\u0026#39;, names=(\u0026#34;num\u0026#34;,\u0026#34;repo_name\u0026#34;,\u0026#34;des\u0026#34;) ) CSVのヘッダ仕様については以下参考にした。\nCSVファイルから読み込みを行うには（pandas編）\nread_csv でヘッダあり・なしCSVの読み込み\n代入処理ではループの都度ファイルに書き出している。当初、一度値を全部配列に格納してそれを書き出そうかと思ったが、フォーマットが崩れるからそれを整形したりとか面倒だからやめた。\n繰り返し代入処理の部分は以下記事が参考になった。助かった。\n【jinja2】テンプレートエンジンでデータの連続差し込み\n実行時は引数として作成対象のAWSリソース名を指定する。テンプレート（今回の場合codecommit.tmpl）のファイル名に合わせる。ここで指定した値が[リソース名].auto.tfvarsのリソース名になる。\n$ python3 create_vars.py codecommit 生成されたcodecommit.auto.tfvars。\ncodecommit_param_list = { param1 = { repository_name = \u0026#34;my-repo001\u0026#34; description = \u0026#34;my-repo001の説明\u0026#34; } param2 = { repository_name = \u0026#34;my-repo002\u0026#34; description = \u0026#34;my-repo002の説明\u0026#34; } param3 = { repository_name = \u0026#34;my-repo003\u0026#34; description = \u0026#34;my-repo003の説明\u0026#34; } } tfvars生成後は不要となるが、参考までに中間地点で生成されたJSONの中身。\ndata.json\n{\u0026#34;num\u0026#34;:{\u0026#34;0\u0026#34;:1,\u0026#34;1\u0026#34;:2,\u0026#34;2\u0026#34;:3},\u0026#34;repo_name\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\u0026#34;},\u0026#34;des\u0026#34;:{\u0026#34;0\u0026#34;:\u0026#34;my-repo001\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;1\u0026#34;:\u0026#34;my-repo002\\u306e\\u8aac\\u660e\u0026#34;,\u0026#34;2\u0026#34;:\u0026#34;my-repo003\\u306e\\u8aac\\u660e\u0026#34;}} こんな短いコードだがめっちゃ紆余曲折した。まーでも、これでひと安心。これはサンプルだから3アイテムだけだけど、AWSリソースの単位で十数個とか数十個とかアイテムがあって、さらにそれが複数重なったら手動で記述なんてやってられない。いや、3アイテムだけでも十分面倒だし、ミスる可能性ありありだ。\n今回のやり方はAWSリソース毎にCSVを分けて作っていく必要あるけど、それくらいならいいだろう。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform_auto_create_tfvars/","summary":"過去記事からの派生案件で、Terraformで使うtfvarsファイルについて、繰り返しデータを多数投入する想定のため、これを自動生成したいと考えた。\nTerraform loop処理の超シンプルな例 Python - Jinja2テンプレートで連続データを処理したい\n実際に使用するファイル群は過去記事に記載しているがこんな想定で。（もちろん実際は他にもいろいろ必要）自動生成したいのは、以下の*印をつけたcodecommit.auto.tfvarsである。（この時点では手動で値を記述したもの）\nwork_dir/ ├── codecommit.auto.tfvars * ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf これとは別に、tfvars自動生成作業用ディレクトリの作業前はこの状態。以下3つのファイルを用意する。codecommit.tmplはテンプレートとなる。このファイル名はスクリプトから呼び出すので名称に注意。対象のAWSリソースによって変えるが、tfファイルの名称に合わせておけばよい。\nscript_dir/ ├── codecommit.tmpl ├── create_vars.py └── data.csv codecommit.tmpl\nparam{{ num }} = { repository_name = \u0026#34;{{ repo_name }}\u0026#34; description = \u0026#34;{{ des }}\u0026#34; } data.csv （今回の例ではヘッダーありの前提）\nnum,repo_name,des 1,\u0026#34;my-repo001\u0026#34;,\u0026#34;my-repo001の説明\u0026#34; 2,\u0026#34;my-repo002\u0026#34;,\u0026#34;my-repo002の説明\u0026#34; 3,\u0026#34;my-repo003\u0026#34;,\u0026#34;my-repo003の説明\u0026#34; create_vars.py\nimport sys import pandas as pd from jinja2 import Environment, FileSystemLoader def main(): # テンプレート読み込み env = Environment(loader=FileSystemLoader(\u0026#39;.","title":"Terraformのtfvarsファイルを自動生成する"},{"content":" Some say luck is when preparation meets opportunity.\n- Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\nわかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？\n","permalink":"https://ecnedaced-seirots.github.io/post/a/quotes-tarantino-movie-1/","summary":"Some say luck is when preparation meets opportunity.\n- Once Upon a Time in Hollywood\u0026quot;の小説版 (Quentin Tarantino) より。\nわかる、その発想好きだ。リアルワールドにおいてシャロン・テートを斬殺したチャールズ・マンソンのモノローグとして登場する言葉ってのがアレだけど\u0026hellip;\n個人的な経験からしても、preparation（準備）はopportunity（好機）を引き寄せるのは実感として理解できる。だから “preparation gets opportunity” とも言えるんじゃないか？","title":"Quotes - タランティーノ小説より(1)"},{"content":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた ","permalink":"https://ecnedaced-seirots.github.io/post/a/jinja2-python/","summary":"Jinja2テンプレートで連続データを処理したい。元データはCSVとかで。いや、Jinja2でなくてもいいかもしれないけど、ちょっと思いつかないな\u0026hellip;\nとりあえず参考リンク。最初のリンクは、CSVをJSONに変換しているんだよな、CSVのままでやりたいんだけど。しかし例は分かりやすい。\n【jinja2】テンプレートエンジンでデータの連続差し込み PythonのテンプレートエンジンJinja2を使ってみた ","title":"Python - Jinja2テンプレートで連続データを処理したい"},{"content":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\nやったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf 以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;3.66.0\u0026#34; } } } terraform { required_version = \u0026#34;1.0.11\u0026#34; backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;my-terraform-poc-repository\u0026#34; key = \u0026#34;poc/poc.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026#34;codecommit_param_list\u0026#34; { type = map(map(string)) default = { param1 = { repository_name = \u0026#34;repo001\u0026#34; description = \u0026#34;desciption for repo001\u0026#34; } param2 = { repository_name = \u0026#34;repo002\u0026#34; description = \u0026#34;desciption for repo002\u0026#34; } param3 = { repository_name = \u0026#34;repo003\u0026#34; description = \u0026#34;desciption for repo003\u0026#34; } } } codecommit.tf\nresource \u0026#34;aws_codecommit_repository\u0026#34; \u0026#34;codecommit_repos\u0026#34; { for_each = var.codecommit_param_list repository_name = lookup(each.value, \u0026#34;repository_name\u0026#34;) description = lookup(each.value, \u0026#34;description\u0026#34;) codecommit.tfの\u0026quot;codecommit_repos\u0026quot;は任意の名称。2行目、for_eachでvariables.tfのcodecommit_param_listを呼び出している。今回の場合はリポジトリ名がrepo001, repo002\u0026hellip;となる。この状態でplanを実行すると以下の出力になる。\n: Terraform will perform the following actions: # aws_codecommit_repository.codecommit_repos[\u0026#34;param1\u0026#34;] will be created + resource \u0026#34;aws_codecommit_repository\u0026#34; \u0026#34;codecommit_repos\u0026#34; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026#34;desciption for repo001\u0026#34; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026#34;repo001\u0026#34; + tags_all = (known after apply) } # aws_codecommit_repository.codecommit_repos[\u0026#34;param2\u0026#34;] will be created + resource \u0026#34;aws_codecommit_repository\u0026#34; \u0026#34;codecommit_repos\u0026#34; { + arn = (known after apply) + clone_url_http = (known after apply) + clone_url_ssh = (known after apply) + description = \u0026#34;desciption for repo002\u0026#34; + id = (known after apply) + repository_id = (known after apply) + repository_name = \u0026#34;repo002\u0026#34; + tags_all = (known after apply) } (repo003も同様） Plan: 3 to add, 0 to change, 0 to destroy. terraform applyを実行。期待値になった。（repo003だけ時間がずれているのは、1点間違いがあってやり直したから）\nやれることはわかったのでこいつ達は削除する。\nリポジトリを削除する。しかしいきなりdestroyすると別途作ったvpcまで消えてしまう。同じ階層にvpc.tfがあるのでそれはそのまま、codecommit.tfを作業ディレクトリから退避。この状態でapplyするとcodecommitリポジトリは消えてvpcは残る。以下でやっていることはapplyでもdestroyなので注意。\n$ terraform apply : aws_codecommit_repository.codecommit_repos[\u0026#34;param3\u0026#34;]: Destroying... [id=repo003] aws_codecommit_repository.codecommit_repos[\u0026#34;param1\u0026#34;]: Destroying... [id=repo001] aws_codecommit_repository.codecommit_repos[\u0026#34;param2\u0026#34;]: Destroying... [id=repo002] aws_codecommit_repository.codecommit_repos[\u0026#34;param1\u0026#34;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026#34;param3\u0026#34;]: Destruction complete after 0s aws_codecommit_repository.codecommit_repos[\u0026#34;param2\u0026#34;]: Destruction complete after 0s Apply complete! Resources: 0 added, 0 changed, 3 destroyed. 課題 コツは掴めたけど、コード本体に書く値がvariablesに移動しただけという気もする。パラメータが増えるほど、結局variablesが肥大化することになる。変数定義を分割できないか？\nこの課題については、変数定義をさらにtfvarsに外出しすることで解決可能。変数定義ファイルが増えることにはなるが、1ファイルが肥大化するよりいい。今回やった分だけでいうと、以下の構成になる。\nwork_dir/ ├── codecommit.auto.tfvars ├── codecommit.tf ├── config.tf ├── terraform.tfvars ├── variables.tf └── vpc.tf xxxxx.auto.tfvarsに個別に分割した要素の値を記述すると、apply実行時に自動で呼び出される。\ncodecommit.tfはこれまでと同じ。\nvariables.tfには値は記述せず、宣言だけ記述する。\nterraform.tfvarsにはリージョンなど全てに共通の値、IAMなど他のリソースから共通で参照されるリソースの値を記述。\nvariables.tf\n# main variable \u0026#34;region\u0026#34; { type = string description = \u0026#34;\u0026#34; } # codecommit variable \u0026#34;codecommit_param_list\u0026#34; { type = map(map(string)) description = \u0026#34;\u0026#34; } codecommit.auto.tfvars\n# codecommit repos definition codecommit_param_list = { param1 = { repository_name = \u0026#34;repo004\u0026#34; description = \u0026#34;desciption for repo004\u0026#34; } param2 = { repository_name = \u0026#34;repo005\u0026#34; description = \u0026#34;desciption for repo005\u0026#34; } param3 = { repository_name = \u0026#34;repo006\u0026#34; description = \u0026#34;desciption for repo006\u0026#34; } } terraform.tfvars\nregion = \u0026#34;ap-northeast-1\u0026#34; codecommit.auto.tfvarsは例なのでこれだけだが、例えばネットワーク周り、アプリ系リソース、監視、ジョブ等の大枠に分割して、その枠毎にtfvarsを用意すれば小回りが効く構成になるんじゃないかと。て、なんかloop処理のことを書くつもりが変数周りのネタメインになった気がする。ま、いいか。\n課題2 loopで作成したリソースの参照方法はどうすればいいのか？が気になって調査してみた。今回だと、Terraformで作成したCodeCommitリポジトリ名をCodePipeline作成時のコードで参照するケースとか。リポジトリrepo001を参照するなら以下の記述になる。\ncodecommit_repository.codecommit_repos[\u0026#34;param1\u0026#34;].id 参照名はcodecommit_repository.codecommit_repos[\u0026quot;param1\u0026quot;].repository_nameではないことに注意。それはいいとして、CodePipeline自体もloopで作成するとしたらこの記述は使えないから、結局同じtfvarsの値を参照して作ることになるかな。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-example/","summary":"前回投稿で言及したTerraformのループ処理を、めっちゃシンプルなパターンでやってみた。\n前回投稿\nTerraform loop処理のリンク集\n参考記事\nTerraformで配列をloopする時はfor_eachを使った方がいい\nやったこと Terraformのセットアップは割愛。作業ディレクトリには以下のtfコードがある。\nwork_dir/ ├── codecommit.tf ├── init.tf ├── variables.tf └── vpc.tf 以下は初期化ファイル。terraform init で初期化実行すみである。VPCも別途サクッと作ってある。ひとりPoCだからremote_stateにする必要もないのだが、なんとなくtfstateをS3に保管するためbackendの定義がある。\ninit.tf\nterraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;3.66.0\u0026#34; } } } terraform { required_version = \u0026#34;1.0.11\u0026#34; backend \u0026#34;s3\u0026#34; { bucket = \u0026#34;my-terraform-poc-repository\u0026#34; key = \u0026#34;poc/poc.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; } } で、肝心のloop処理。最初なので脳に優しく、超シンプルなパターンでいく。CodeCommitリポジトリの作成はパラメータが少ないので、参考記事を参照し、これで試した。他にもパラメータが少ないやつならなんでもいいけど。今回セットする値はrepository_nameとdescriptionの2点だけ。\nvariable.tf\nvariable \u0026#34;codecommit_param_list\u0026#34; { type = map(map(string)) default = { param1 = { repository_name = \u0026#34;repo001\u0026#34; description = \u0026#34;desciption for repo001\u0026#34; } param2 = { repository_name = \u0026#34;repo002\u0026#34; description = \u0026#34;desciption for repo002\u0026#34; } param3 = { repository_name = \u0026#34;repo003\u0026#34; description = \u0026#34;desciption for repo003\u0026#34; } } } codecommit.","title":"Terraform loop処理の超シンプルな例"},{"content":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\nfor_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\nTerraformで配列をloopする時はfor_eachを使った方がいい 以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\nTerraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法 これはcountを使う方法。多分使わないけど比較用にメモ。\nTerraformで超サクッとループでリソースを用意する方法 上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;3.66.0\u0026#34; } } } 以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\nTerraform職人再入門2020 ","permalink":"https://ecnedaced-seirots.github.io/post/a/terraform-loop-memo/","summary":"Terraformでループ処理ってどうするんだっけ\u0026hellip;と調べたらいろいろ出てきた。読んでも全然頭に入らないがとりあえず参考リンクをメモ。パッと見る限りcountよりfor_eachの方がお勧め？ひとつのリソースに2個以上のパラメータをセットする場合は以下記事の「for_eachを使った書き方（その2）」を参考にすればいいかな。\nfor_eachを知らずにcountを使って作成したところ、追加や削除の際に色々と意図しない挙動になったので、回避策について備忘録を残しておきたいと思います。\nTerraformで配列をloopする時はfor_eachを使った方がいい 以下もちゃんと読めば有益そうなのだが、マニアックすぎて理解が追いつかない。\nTerraformでのloop処理の書き方（for, for_each, count） Terraformのループ処理(for_each,for)について Terraformでimportを使う理由とfor_eachをつかったリソース定義に実リソースをimportする方法 これはcountを使う方法。多分使わないけど比較用にメモ。\nTerraformで超サクッとループでリソースを用意する方法 上記記事のリンクにあったこっちの記事の方にピピっときた。IntelliJでTerraformね、これはやってみよう。仕事じゃ使えないけど。\n新記法対応！ IntelliJ IDEAを使ってTerraformを書いてみた IntelliJはさておき、久しぶりに使ってみたらプロバイダの記述方法が変わっていてハマった。今現在は以下の方式で書く。\nterraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;3.66.0\u0026#34; } } } 以下記事に最近変わった細かい規則とかいろいろ書いてある。ロックファイルとか面倒くせぇな、なくていいのに。\u0026hellip;と思ったが、ドキュメント読む限り気にしなくてよさげ。\nTerraform職人再入門2020 ","title":"Terraform loop処理のリンク集"},{"content":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ\nとういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\nlambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.amazonaws.com evt_usr = dtl[\u0026#39;userIdentity\u0026#39;][\u0026#39;arn\u0026#39;] # 実行ユーザ 例：arn:aws:iam::012345678910:user/hoge_user evt_ip = dtl[\u0026#39;sourceIPAddress\u0026#39;] # ソースIPアドレス #123.123.123.123 # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) # イベントリクエスト 例：{\u0026#39;bucketName\u0026#39;: \u0026#39;hoge-test-bucket-0001\u0026#39;, \u0026#39;Host\u0026#39;: \u0026#39;s3-ap-northeast-1.amazonaws.com\u0026#39;} evt_req_d = e[\u0026#39;detail\u0026#39;][\u0026#39;requestParameters\u0026#39;] req_str = json.dumps(evt_req_d) evt_req = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, req_str) # 件名整形 subject_str = \u0026#34;本番環境イベント監視 \u0026#34; + evt_name + \u0026#34; - \u0026#34; + evt_src # メッセージ本文整形 fix_msg = \u0026#34;以下のイベントが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; type_msg = \u0026#34;イベントタイプ:\u0026#34; + \u0026#34;\\n\u0026#34; + e_type time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str ename_msg = \u0026#34;イベント名:\u0026#34; + \u0026#34;\\n\u0026#34; + evt_name esrc_msg =\u0026#34;イベントソース:\u0026#34; \u0026#34;\\n\u0026#34; + evt_src ereq_msg =\u0026#34;イベントリクエスト:\u0026#34; \u0026#34;\\n\u0026#34; + evt_req eusr_msg =\u0026#34;実行ユーザ:\u0026#34; \u0026#34;\\n\u0026#34; + evt_usr eip_msg =\u0026#34;ソースIPアドレス:\u0026#34; \u0026#34;\\n\u0026#34; + evt_ip msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + type_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + ename_msg + \u0026#34;\\n\\n\u0026#34; + esrc_msg + \u0026#34;\\n\\n\u0026#34; + ereq_msg + \u0026#34;\\n\\n\u0026#34; + eusr_msg + \u0026#34;\\n\\n\u0026#34; + eip_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) テスト用にサンプルデータを貼り付けて、エラーが出ない状態にまでもっていった。これでもういいかと思ったがやはりちゃんとしたメールが届くのが見たい\u0026hellip;ということで、再びCloudTrailを有効にしてイベントを発生させることにした。前回無効にしたCloudTrailログ用の残骸バケットが残っていたのでそれを削除したら、まさにその行為がイベントとして検知され、メールが届いた。よしよし。\n上記はテストデータ残骸の内容が表示されているが、実際のイベント発生時のメールも別途ちゃんと届いている。上記画面では「APIタイプ」が含まれているがこれはいらないと判断したため、この後コードから削除した。\nちなみに、JSON生データからkey:valueの抽出を行うときはこんなんでやった。JSONデータをファイルに保存してから：\n\u0026gt;\u0026gt;\u0026gt; import json \u0026gt;\u0026gt;\u0026gt; event_file = open(\u0026#39;event_msg_sample.json\u0026#39;,\u0026#39;r\u0026#39;) \u0026gt;\u0026gt;\u0026gt; event = json.load(event_file) \u0026gt;\u0026gt;\u0026gt; for k,v in event.items(): ... print(k,v) （追記）以下でもよい。先にこれをやって、階層が深くて分かりにくい場合は上記を併用すればいいかと。\n\u0026gt;\u0026gt;\u0026gt; msg = json.dumps(event, indent=3) \u0026gt;\u0026gt;\u0026gt; print(msg) ","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail-2/","summary":"以下過去記事の続き。この時はメール本文がJSON生データで送信された。これを、人間が状況を判別可能な状態までもっていきたい。\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ\nとういことで、再度検証。使用したAWS各種サービスのリソースは前回と同様で、Lambda関数のコードだけ入れ替え。何度も同じようなことをやっていて何がなんだか分からなくなっているがもうヤケクソ。\nlambda_function.py （イベント監視メール通知用）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 dtl = e[\u0026#39;detail\u0026#39;] #詳細(detail)を定義 e_type = e[\u0026#39;detail-type\u0026#39;] # イベントタイプ 例：\u0026#39;AWS API Call via CloudTrail\u0026#39; t = e[\u0026#39;time\u0026#39;] # 発生時刻 evt_name = dtl[\u0026#39;eventName\u0026#39;] # イベント名 例：DeleteBucket evt_src = dtl[\u0026#39;eventSource\u0026#39;] # イベントソース 例：s3.","title":"AWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)"},{"content":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\nCloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr = \u0026#39;2021-10-24T09:35:10Z\u0026#39; utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00 当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\nlambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] # 時刻変換 JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr_parsed = parser.parse(t) ux_time = utcstr_parsed.timestamp() epoch = int(ux_time) # unixタイムスタンプをJSTに変換。dtはこの時点でdatetime.datetime型 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) # dtを整形 dt_str = dt.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) # 件名に投入するアラーム名を抽出 alm_list = alarm[0].split(\u0026#39;:\u0026#39;) alm_name = alm_list[-1] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境アラーム \u0026#34; + alm_name + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻(JST):\u0026#34; + \u0026#34;\\n\u0026#34; + dt_str alm_msg = \u0026#34;アラームARN:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 上記コードにてLambdaを再デプロイしてec2インスタンスでCPU負荷発生させたところ、一応期待値となるメールが届いた。画面下の「理由」に記載の時刻はUTCとなっているが、「発生時刻(JST)」は日本時刻表記である。（ほぼ実際にCPU負荷をかけた時間）\n参考\n[Python]UNIX秒(UTC)をISO8601(JST)に変換する\nPythonで日付をunixtimeに変換する方法【初心者向け】\nまぁこんなことやったところで誰も感謝もしてくれないがね。映画\u0026quot;Taxi Driver\u0026quot;のトラヴィスの気持ちも分かるってもんだ。（\u0026hellip;若干くされ気分）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-3/","summary":"表題のテーマ、過去にもCloudWatchアラーム通知メールのカスタマイズについて書いたが、表示時刻がUTCなのでJSTに変換しようと考えた。\n過去記事\nCloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\nCloudWatchアラームから渡されるeventの、元データの時刻表示は例えば'2021-10-24T09:35:10Z\u0026rsquo;となっている。これをJSTにするのに手っ取り早いのはpytzを使う方法だが、諸事情により標準ライブラリの範囲でやる必要がある。\nで、試行錯誤。当初datetime型にしてからJSTに変換しようとしたがいいやり方が見つからなかったため「unixタイムスタンプに変換後、JSTに変換」とすることにした。\nfrom datetime import datetime, timezone, timedelta from dateutil import parser JST = timezone(timedelta(hours=+9), \u0026#39;JST\u0026#39;) utcstr = \u0026#39;2021-10-24T09:35:10Z\u0026#39; utcstr_parsed = parser.parse(utcstr) #UNIXタイムスタンプに変換 ux_time = utcstr_parsed.timestamp() #int型にする epoch = int(ux_time) #JSTに変換 dt = datetime.fromtimestamp(epoch).replace(tzinfo=timezone.utc).astimezone(tz=JST) print(dt) 2021-10-25 03:35:10+09:00 当初JSTに変換した後の時間が変だ+18時間になってる何故だ、と悩んだが、拠点にした時間から+18時間になるのはおそらく実行環境がJSTだから。UTCの環境でやれば+9時間になるんだろう。くそ、こんなことで数時間週末を無駄にした。俺の休息時間はいつなんだ？\nともあれ、修正したのが以下。コメントの「時刻変換」と、「件名に投入するアラーム名を抽出」を追加した。前回はメール件名規則を「任意の文字列 + 発生契機 + 対象リソース(dimention)」としていたが、発生契機はいらないから代わりにアラーム名にした。\nlambda_function.py （時刻表示JSTバージョン）\nimport boto3 import json import os import re from botocore.exceptions import ClientError from datetime import datetime, timezone, timedelta from dateutil import parser print(\u0026#39;Loading function\u0026#39;) sns_arn = os.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(3)"},{"content":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より\n","permalink":"https://ecnedaced-seirots.github.io/post/a/english-into-the-bargain/","summary":"into the bargain = in addition\n\u0026ldquo;Zazie in the Metro\u0026rdquo;(Raymond Queneau) / 地下鉄のザジ（レーモン・クノー）より","title":"英語メモ - into the bargain"},{"content":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\nlambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) マネコン上でテストしたらいくつかエラー出たので対処して、エラー出ないところまでもってきた。で、ec2インスタンスに負荷をかけてアラームステータスにしたが\u0026hellip;メールが届かない。あぁ。\n明日以降考えよ。\n追記\n翌日Lambdaの画面からなんとなくEventBridgeルールのリンクを辿ったら、なんとルールがdisableになっていた！そりゃ何も起こらないわけだ。enableに変更して、改めてインスタンスで負荷をかけたところ、カスタムメールが届いた！大したことじゃないけど、こういうのはいつまでたっても嬉しいもんだ。\nしかしよく見ると日付が変だ。Lambdaテスト用に使った過去データの値みたいだ。な、なんでこうなるんだ。でももう遅いから寝る\u0026hellip;\n追記2\nさらにその翌日、テストデータ削除して再試行してみたところ、期待値となるまともなメールが届いた。\n時間はUTC表記。これどうするかな。以下でやれるのはわかったけど。\n\u0026gt;\u0026gt;\u0026gt; from pytz import timezone \u0026gt;\u0026gt;\u0026gt; from dateutil import parser \u0026gt;\u0026gt;\u0026gt; time = \u0026#34;2021-11-03T10:17:51Z\u0026#34; \u0026gt;\u0026gt;\u0026gt; utc_string = time \u0026gt;\u0026gt;\u0026gt; jst_time = parser.parse(utc_string).astimezone(timezone(\u0026#39;Asia/Tokyo\u0026#39;)) \u0026gt;\u0026gt;\u0026gt; print(jst_time) 2021-11-03 19:17:51+09:00 参考\nPythonの UTC ⇔ JST、文字列(UTC) ⇒ JST の変換とかのメモ\nしかし、今日はもう寝たいんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda-2/","summary":"表題の件、過去記事ではメール件名カスタマイズが主題だったが、メール本文を人間が判読可能なフォーマットにすべく、Lambdaコードを改良してみた。これがSNSに渡り、整形された本文がメール送信される想定である。前回はメール件名を環境変数にしたが今回はコード内から値を取り出している。\n類似の過去記事\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする\nlambda_function.py\nimport boto3 import json import os import re from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] def lambda_handler(event, context): data = event s = json.dumps(data) e = json.loads(s) print(e) # eventから項目を抽出 t = e[\u0026#39;time\u0026#39;] trig = e[\u0026#39;detail-type\u0026#39;] alarm = e[\u0026#39;resources\u0026#39;] #これはリスト。文字列にするにはalarm[0] # 「理由」となる詳細抽出 reason = e[\u0026#39;detail\u0026#39;][\u0026#39;state\u0026#39;][\u0026#39;reason\u0026#39;] # リソース（ここではインスタンスID)を抽出し、文字列整形 resource = e[\u0026#39;detail\u0026#39;][\u0026#39;configuration\u0026#39;][\u0026#39;metrics\u0026#39;][0][\u0026#39;metricStat\u0026#39;][\u0026#39;metric\u0026#39;][\u0026#39;dimensions\u0026#39;] res_str = json.dumps(resource) res = re.sub(r\u0026#34;[{}\\\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;, res_str) # 件名整形 subject_str = \u0026#34;本番環境 - アラーム \u0026#34; + trig + \u0026#34; - \u0026#34; + res # メッセージ本文整形 fix_msg = \u0026#34;以下のアラームが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; trig_msg = \u0026#34;発生契機:\u0026#34; + \u0026#34;\\n\u0026#34; + trig time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + t alm_msg = \u0026#34;アラーム:\u0026#34; + \u0026#34;\\n\u0026#34; + alarm[0] res_msg =\u0026#34;対象リソース:\u0026#34; \u0026#34;\\n\u0026#34; + res dtl_msg =\u0026#34;理由:\u0026#34; \u0026#34;\\n\u0026#34; + reason msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + trig_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + alm_msg + \u0026#34;\\n\\n\u0026#34; + res_msg + \u0026#34;\\n\\n\u0026#34; + dtl_msg try: sns = boto3.","title":"CloudWatchアラーム + SNSからのメール本文をカスタマイズする(2)"},{"content":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e) 参考\nCloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版\n変更後：lambda_function.py(2)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): # ロググループ名取得 log_group = data_json[\u0026#39;logGroup\u0026#39;] # ログストリーム名取得 log_stm = data_json[\u0026#39;logStream\u0026#39;] # LogEvents取得 log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) #UNIX時間→時刻/JST変換 datetime_utc = log_json[\u0026#39;timestamp\u0026#39;] / 1000.0 datetime_utc = datetime.datetime.fromtimestamp(datetime_utc).strftime(\u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_utc = datetime.datetime.strptime(datetime_utc, \u0026#39;%Y/%m/%d %H:%M:%S\u0026#39;) datetime_jst = datetime_utc + datetime.timedelta(hours = 9) # メール件名整形 subject_str = \u0026#34;本番環境 - ログアラート \u0026#34; + log_group # メッセージ本文整形 fix_msg = \u0026#34;以下のアラートが発生しました\u0026#34; + \u0026#34;\\n\u0026#34; log_group_msg = \u0026#34;ロググループ名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_group log_stm_msg = \u0026#34;ログストリーム名:\u0026#34; + \u0026#34;\\n\u0026#34; + log_stm time_msg = \u0026#34;発生時刻:\u0026#34; + \u0026#34;\\n\u0026#34; + str(datetime_jst) log_msg = \u0026#34;メッセージ:\u0026#34; + \u0026#34;\\n\u0026#34; + log_json[\u0026#39;message\u0026#39;] msg = fix_msg + \u0026#34;\\n\\n\u0026#34; + log_group_msg + \u0026#34;\\n\\n\u0026#34; + log_stm_msg + \u0026#34;\\n\\n\u0026#34; + time_msg + \u0026#34;\\n\\n\u0026#34; + log_msg try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = msg, Subject = subject_str ) except Exception as e: print(e) 参考\n【AWS】CloudWatch Logsからシステムログをメール通知する。\n改良後のコードでは本文整形の他、メール件名を環境変数決め打ちからコード内でeventの情報から取得、に変更している。ログ種別は多義に渡るしログ監視以外のメール送信もあるから、動的に対応できる方が望ましいということで。本文冒頭に決め打ちメッセージ追加と変数名を変えたくらいで基本は参考元とほぼ同じ。タイムスタンプ変換まで書いてもらって非常にありがたい。\n最終的に、送信されたメールはこんな感じ。\n参考サイトさんのおかげですんなりできて助かった。（2度目）ちなみに、当初自力で応用しようとしてハマってた。Logs(サブスクリプションフィルタ)からLambdaに渡されるデータ構造が不明だったからだ。しかし以下公式にちゃんとサンプルと説明があったということを、最後に知った。\nCloudWatch Logs サブスクリプションフィルターの使用\n以下、データサンプルの抜粋\n{ \u0026#34;owner\u0026#34;: \u0026#34;111111111111\u0026#34;, \u0026#34;logGroup\u0026#34;: \u0026#34;CloudTrail\u0026#34;, \u0026#34;logStream\u0026#34;: \u0026#34;111111111111_CloudTrail_us-east-1\u0026#34;, \u0026#34;subscriptionFilters\u0026#34;: [ \u0026#34;Destination\u0026#34; ], \u0026#34;messageType\u0026#34;: \u0026#34;DATA_MESSAGE\u0026#34;, \u0026#34;logEvents\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221568\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221569\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; }, { \u0026#34;id\u0026#34;: \u0026#34;31953106606966983378809025079804211143289615424298221570\u0026#34;, \u0026#34;timestamp\u0026#34;: 1432826855000, \u0026#34;message\u0026#34;: \u0026#34;{\\\u0026#34;eventVersion\\\u0026#34;:\\\u0026#34;1.03\\\u0026#34;,\\\u0026#34;userIdentity\\\u0026#34;:{\\\u0026#34;type\\\u0026#34;:\\\u0026#34;Root\\\u0026#34;}\u0026#34; } ] } そして上記ページにたどり着いたのは以下記事のコメントによる。\ncloudwatchlogs -\u0026gt; lambda -\u0026gt; SNSを試してみた\n先に記載したコードはこのコメントで言及されている「複数イベントへの対処」が行われているバージョンとなる。改めて、先駆者の方々のおかげで非常に助かった。（3度目）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail-2/","summary":"表題の件、以下の過去記事に書いたが、この時点では送信される本文ががログメッセージだけとなっていて、通知メールとしては不十分なため本文もカスタマイズしてみた。\nCloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信\n各種設定は冒頭の過去記事と同様のため割愛するとして、コードは変更前・後両方載せておく。\n変更前：lambda_function.py(1)\nimport base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e) 参考","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信(2)"},{"content":"elaborate 複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の 他動詞としては「〜を詳しく調べる」\nIrvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/english-elaborate/","summary":"elaborate 複雑な、入り組んだ 精巧な、精密な 入念な、苦心の末の 他動詞としては「〜を詳しく調べる」\nIrvine Welshの\u0026quot;Trainspotting\u0026quot;読書中に登場した単語だと思うが、何ページかはもう覚えていない。","title":"英語メモ - elaborate"},{"content":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n監視方式大枠 ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。 CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\nprocstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる\n以下は途中まで参照したところ（後半は有料サービスの案内）、アラームを作成するところまでわかりやすかった。であれば、閾値監視と同様にEBルールを挟んでLambdaをターゲットに指定 ー＞ SNSトピックに渡されてメール送信、でいけるはず。\nCloudWatchでプロセス監視する手順をLinuxとWindowsともに詳しく紹介\nイベント監視\nイベント発生 ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※1. 2. のアラームがイベントに置き換わるだけで、後続のフローは同様となる想定。\n上記の中で、私的には4.のプロセス監視が一番面倒な気がする。プロセス監視の詳細は保留として、全体の登場人物を整理しておこう。\n登場人物整理 整理したらこうなった。方式をどうするかによって変わる部分もあるが、今のところこの想定。すべての監視でLambdaを使うのは、メール件名や本文をカスタマイズしたいため。\nノード監視 閾値監視 ログ監視 プロセス監視 イベント監視 CloudWatchAlarm ● ● - ● - CloudWatchLogs - - ● - - SSM(Systems Manager) - - - ● - EventBridge rule ● ● - ● ● Lambda ● ● ● ● ● SNS topic ● ● ● ● ● 次のステップとして、これらの各アイテムにおいて「共通化できるもの / 個別に作成するもの」に分類する必要がある。\nその他メモ メール件名のカスタマイズ\nメール件名のカスタマイズをLambdaの環境変数でやるかコード本体でやるか。\nイベントの中身を拾って詳細に設定するならLambdaコード内でやるしかないが、そんな体力はない。そもそもイベントの中身が元ネタによって異なるからメッセージ内容別に大幅な差分が発生するはず。やれなくもないがそんな体力は(ry)。となると、カッコ悪いかもしれないがほぼ決め打ちの値で環境変数にセット、でいく方がいい。 メッセージ本文のカスタマイズ\n① Lambdaコード内で実装\n② EventBridgeルールの入力トランスフォーマーで実装 ②を試したが期待値ならず。深追いしている時間はない。どっちにしろログ監視では本文をLambdaに渡しているからそっちに寄せる方がいい。ここでやってるマッピングがLambdaコードにも適用できるか検討しようと思ったが、スキーマレジストリとかよくわからん。\naws configの通知をどうするか\nconfigのログはS3にしか飛ばせない。ログ監視ではなく、イベント監視でやる。検知を制御したい時はイベント検知無効化で対応とか。 Amazon CloudWatch Events を使用すると、AWS Config イベントのステータスで変更を検出し対応することができます。\nAWS Config でのログ記録とモニタリング\nConfigの変更はCloudTrailにつながるから、下手すると監視が重複するかもしれない。が、考えてる時間が(ry) 以下はCloudTrailの設定で直接SNSを指定しているっぽいが、これもEventBridgeに渡す、に統一させた方がよさげ。\nCloudTrail が、新しいログファイルを Amazon S3 バケットに発行するときに通知を受け取ることができます。\nCloudTrail の Amazon SNS 通知の設定\n以下は通知事例の記載はないが一応メモ\nAWSリソースの設定変更履歴を管理する「AWS Config」とは？実際に使用してみた\n果てしない旅路。\n（追記）\nSSM(Systems Manager)は使わずにprocstatプラグインだけでもなんとかなりそう。SSMを使えばもっと楽になるらしいが、よくわかっていない。ちゃんと調べればいいんだが、時間がないんだ\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-monitoring-idea/","summary":"AWSで過去普通にやってた監視実装も、2,3年経つと（或いはそれより短い周期で）陳腐化する。以前は限られたサービスのリソース範囲でやれることをやっていればよかったが、今はSSM(Systems Manager)、Lambda、EventBridgeなどの「登場人物」が増えて、カスタマイズが可能になったからだ。やれることが増えた分、実装が複雑になる。その分チャレンジングな分野になって楽しめると言えないこともないが\u0026hellip;、時間が足りないんだ。頭痛ぇな、まったく。絡み合った糸をほぐすためにまとめてみる。\n監視の種別としては大枠としてノード監視、閾値監視、ログ監視、プロセス監視、イベント監視と想定する。それぞれの実装方式が若干異なってくるため整理したい。\n監視方式大枠 ノード監視\nCloudWatchアラーム(ステータスチェック) ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※ハード障害等でインスタンスが落ちた時に発動される想定。手動で落とした時は発動しないので通知は来ない。\n閾値監視\nCloudWatchアラーム（閾値チェック） ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※EC2インスタンスのCPU使用率、ディスク使用率を想定。メモリ監視は別途カスタムメトリクスの実装がいる。\nログ監視\nCloudWatchLogsでログ出力（サブスクリプションフィルタキーワード検知）ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※これだけEventBridgeを使用しない。\nプロセス監視\nEC2インスタンス上のプロセス数監視に相当する。検索すると「プロセス落ちていたらインスタンス再起動」アクションの事例が多いが、今回やりたいのはメール通知だけ。一応メモっておくけど。 CWエージェント + SSM + インスタンス停止、Lamabdaなし\nEC2上のプロセスを監視し自動復旧する\nCWエージェント + SSM + 自動再起動、Lamabdaなし\nAWSでプロセス監視を実装したい\nCWエージェント + Lamabda + SSM + 自動再起動\nEC2のプロセス監視と自動再起動\nprocstat事例\n以下はSSMを使用せず、procstatプラグインを使用してプロセス監視する例。記事には監視設定以降の通知イベント事例はなし。\nCloudWatch Agent でProcstatプラグインの利用が可能になりました\nSSMを使わずCloudwatchでEC2上のプロセス監視をしてみる\n以下は途中まで参照したところ（後半は有料サービスの案内）、アラームを作成するところまでわかりやすかった。であれば、閾値監視と同様にEBルールを挟んでLambdaをターゲットに指定 ー＞ SNSトピックに渡されてメール送信、でいけるはず。\nCloudWatchでプロセス監視する手順をLinuxとWindowsともに詳しく紹介\nイベント監視\nイベント発生 ー＞ (EventBridgeルール) ー＞ Lambda ー＞ SNSトピック ー＞ メール送信 ※1.","title":"AWS監視の方式を整理したい"},{"content":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\nタウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\nタウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\nタウリンを多く含む食材\n貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚 タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\nタウリン摂取時の注意\n食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む） \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/healthcare-taurine/","summary":"タウリンの効果。過去に見つけたネタをバラバラにメモっていたのをまとめておく。\nタウリンとは、一言で言うと。\nタウリンは分子量124の含硫アミノ酸。タンパク質の構成成分にはならないが、細胞内の遊離アミノ酸としてはグルタミンと並んでもっとも高濃度に存在し、かつグルタミンに類似する成分。またタウリンは脳内のアミノ酸の中では2番目に多く存在する。\nタウリンは疲れが溜まっていると多く消費される、年齢を重ねると減少、男性より女性が不足しがち、とも言われている。\nタウリンの効果としてはアセトアルデヒトの代謝促進による肝機能サポートがよく知られているが、記憶力や認知能力の改善、目の網膜の保護、便通の改善等、意外な効能もある様子。\nそんなタウリンの効果について、とりあえず箇条書きで。\n神経伝達、海馬の増強や安定化をサポート。 記憶力に関与するグリア細胞の活性化を促進する。(注1) アルコールや有害物質から発生するアセトアルデヒトの代謝を促進する。 心筋を強くして疲労回復を促す。（ただし即効性はないらしい？） 心臓のポンプ作用を高めて筋肉により多くの血液を送り込み、持久力を高める。（ドイツの研究より） 細胞のミトコンドリアの数を増やす（ミトコンドリアのタンパク質合成に必須）(注2) 目の網膜や角膜を保護する。 腸管の抗炎症作用 血圧や血糖値のバランスをサポート。 肝臓・心臓の機能強化 胆汁を生成し、コレステロールや中性脂肪の代謝をコントロール インスリン分泌促進 便の水分を増やし、便秘を改善する。 ニューロンのカリウム除去をサポートし、ニューロンが過度に活発化することを防ぐ。 タウリンはレシチンと併用することで細胞の細胞膜を丈夫にし、細胞が正常な形状を保つようにサポートをする。 髪の毛の成長にも不可欠なタンパク質IGF-1(インスリン様成長因子)を増やす (注1) 記憶を司ると言われる海馬にはグリア細胞が多く存在する。\nまた以下のように認知機能の改善を示す研究がある。\n迷路試験（Y-maze test）と受動的回避試験（passive avoidance test）で、タウリンを摂取したマウスの認知機能が正常な状態に回復することが確認された。さらに、アルツハイマー病の症状である大脳皮質の炎症が抑えられたほか、脳の海馬から分泌されるアミロイドベータの量も減り、記憶力に深く関与するグリア細胞の活性化が促進されることが確認された。\n注目すべき特徴は、タウリンの脳機能改善効果がアルツハイマー病において選択的に表れるということだ。従来の治療薬物が正常のマウスでは脳機能の異常を来たしたのに対し、タウリンは正常のマウスで脳機能の異常を来たすことはなかった。タウリンの持つもう一つの特性は、タウリンが脳の血管壁を透過しやすいため、口から摂取しても脳にうまく吸収されることだ。別途の複雑な投与過程を経る必要がなく、飲料水などの食物からタウリンを摂っても効果が高い。\nタウリンがアルツハイマー病治療に有効だと判明\n(注2) 「ただしタウリンが細胞内のエネルギー生産組織であるミトコンドリアの数を増やすのは、タウリン サプリを継続的に数か月～半年ほど摂取した場合に限られます。」（参照リンクは消滅）\nタウリンを多く含む食材\n貝・甲殻類（サザエ、牡蠣、帆立、蛤、あさり、しじみ、タコ、イカ、カニ等） ブリやカツオの血合い 鯵や鯖などの近海魚 タウリンを多く含む食材としてはタコ・イカのイメージが強かったのだが、ダントツで多いのは牡蠣だった。100g中1180mg。サザエの方が100g1500mgで含有量としては多いが、摂取量・摂取回数は一般的に考えて少ない。\n余談だが牡蠣は亜鉛も多く含んでいて、その亜鉛はグルタミン酸興奮毒性（神経細胞死の一因）から脳を守る機能を果たす。また、記憶を司る海馬には最高濃度の亜鉛が存在する。脳の海馬をサポートするタウリンと亜鉛を両方含む牡蠣は、最強ブレインフードだった！\nタウリンを多く含む食品一覧 ポイントは魚介類と血合肉\nタウリン摂取時の注意\n食間・空腹時の摂取が有効。 アスピリンと併用しないこと。（薬理作用を増強させてしまうため余計な負担がかかる。バファリンは原材料としてアスピリンを含む） \u0026hellip;と、万能選手的なタウリンではあるが、日本国内ではタウリン単体のサプリメントは販売されていない。このためタウリンのサプリはiHerbで時々購入しているが、在庫切れのことが多く割と入手困難ではある。日本の薬事法に規制があって、一回で購入可能な量・個数が制限されているから、まとめ買いもできないのだ。（おそらく鷲のマークの製薬会社の圧力）\niHerb独自ブランドのタウリンサプリが安価で嬉しいけど、数ヶ月前から在庫切れ状態が続いている。しょうがないから、今日別の高いやつをポチってしまった。","title":"タウリン(Taurine)の効能いろいろ"},{"content":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\nベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n処理概要 CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知 作業概要 SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認 検証に使用したアイテム アイテム 名称 SNSトピック alarm-notification-topic CloudWatchアラーム CPU_Utilization_Test Lambda関数 cw-alarm-sns-function EventBridgeルール cw-alarm-rule やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026#34;CPU_Utilization_Test\u0026#34; \\ --metric-name \u0026#34;CPUUtilization\u0026#34; \\ --namespace \u0026#34;AWS/EC2\u0026#34; \\ --statistic \u0026#34;Maximum\u0026#34; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026#34;GreaterThanThreshold\u0026#34; \\ --dimensions \u0026#34;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026#34; EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる\n$ AWSREGION=ap-northeast-1 $ AWSACCOUNT=my-account-id $ aws events put-rule --name \u0026#34;cw-alarm-rule\u0026#34; \\ --event-pattern \u0026#34;{\\\u0026#34;source\\\u0026#34;: [\\\u0026#34;aws.cloudwatch\\\u0026#34;],\\\u0026#34;detail-type\\\u0026#34;: [\\\u0026#34;CloudWatch Alarm State Change\\\u0026#34;],\\\u0026#34;resources\\\u0026#34;: [{\\\u0026#34;prefix\\\u0026#34;: \\\u0026#34;arn:aws:cloudwatch:${AWSREGION}:${AWSACCOUNT}:alarm:CPU_Utilization_\\\u0026#34;}],\\\u0026#34;detail\\\u0026#34;: {\\\u0026#34;state\\\u0026#34;: {\\\u0026#34;value\\\u0026#34;: [\\\u0026#34;ALARM\\\u0026#34;]}}}\u0026#34; 以下の様にルールが作成された。\n{ \u0026#34;source\u0026#34;: [\u0026#34;aws.cloudwatch\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;CloudWatch Alarm State Change\u0026#34;], \u0026#34;resources\u0026#34;: [{ \u0026#34;prefix\u0026#34;: \u0026#34;arn:aws:cloudwatch:ap-northeast-1:0123456789102:alarm:CPU_Utilization_\u0026#34; }], \u0026#34;detail\u0026#34;: { \u0026#34;state\u0026#34;: { \u0026#34;value\u0026#34;: [\u0026#34;ALARM\u0026#34;] } } } しかしこの段階ではまだターゲットが存在しない。前回はコマンドでターゲット指定したが、今回はマネコンからやった。対象のルールを選択して「Edit」ー＞ 「Select targets」で作成済みのLambda関数を指定して、「Update」\nすると、以下の様にLambda側のトリガーとして、セットしたルールが設定される。\nここまでやったら、以下の流れでメール通知される、はず。\n① EC2インスタンスのCPU使用率を上げてアラーム発行させる ② EventBridgeルールでターゲットに指定したLambdaに渡される ③ Lambdaで設定したSNSに渡される\nちなみにCPU使用率UP時はこんなのをshellにしてバックグラウンドで複数実行させた。アラームの設定で閾値10%にしたが、これをt3.microマシン上で3回くらい同時に回せば軽く90%くらいになる。\nCNT=0; while [ $CNT -lt 100000 ]; do CNT=$(( CNT + 1 ));done\n少し経つとアラームのステータスが変わって、カスタム件名のメールが届いた！しかし本文がひどい\u0026hellip;\nサンプルコードではMessage=json.dumps(event) としているから、JSONデータをそのまま吐き出しているだけ。本文をカスタマイズする場合はこのeventをいじる必要がある。冒頭のクラメソさんの事例もはっきりいって面倒くさそうだったが、コードでやるのも面倒だなぁ、何せサンデープログラマだから。\neventに相当するJSONデータ\n{\u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;86fa8a3f-7470-8c16-ef56-aaba9821771e\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;CloudWatch Alarm State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.cloudwatch\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;123456789101\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2021-11-03T10:17:51Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;resources\u0026#34;: [\u0026#34;arn:aws:cloudwatch:ap-northeast-1:123456789101:alarm:CPU_Utilization_Test\u0026#34;], \u0026#34;detail\u0026#34;: {\u0026#34;alarmName\u0026#34;: \u0026#34;CPU_Utilization_Test\u0026#34;, \u0026#34;state\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;ALARM\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Threshold Crossed: 1 out of the last 1 datapoints [100.0 (03/11/21 10:11:00)] was greater than the threshold (10.0) (minimum 1 datapoint for OK -\u0026gt; ALARM transition).\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:17:51.018+0000\\\u0026#34;,\\\u0026#34;startDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[100.0],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:11:00.000+0000\\\u0026#34;,\\\u0026#34;sampleCount\\\u0026#34;:5.0,\\\u0026#34;value\\\u0026#34;:100.0}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:17:51.020+0000\u0026#34;}, \u0026#34;previousState\u0026#34;: {\u0026#34;value\u0026#34;: \u0026#34;INSUFFICIENT_DATA\u0026#34;, \u0026#34;reason\u0026#34;: \u0026#34;Insufficient Data: 1 datapoint was unknown.\u0026#34;, \u0026#34;reasonData\u0026#34;: \u0026#34;{\\\u0026#34;version\\\u0026#34;:\\\u0026#34;1.0\\\u0026#34;,\\\u0026#34;queryDate\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:51.019+0000\\\u0026#34;,\\\u0026#34;statistic\\\u0026#34;:\\\u0026#34;Maximum\\\u0026#34;,\\\u0026#34;period\\\u0026#34;:60,\\\u0026#34;recentDatapoints\\\u0026#34;:[],\\\u0026#34;threshold\\\u0026#34;:10.0,\\\u0026#34;evaluatedDatapoints\\\u0026#34;:[{\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;2021-11-03T10:13:00.000+0000\\\u0026#34;}]}\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-11-03T10:13:51.023+0000\u0026#34;}, \u0026#34;configuration\u0026#34;: {\u0026#34;metrics\u0026#34;: [{\u0026#34;id\u0026#34;: \u0026#34;4cbe7286-d70f-fcb9-4a0a-758612d568db\u0026#34;, \u0026#34;metricStat\u0026#34;: {\u0026#34;metric\u0026#34;: {\u0026#34;namespace\u0026#34;: \u0026#34;AWS/EC2\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;CPUUtilization\u0026#34;, \u0026#34;dimensions\u0026#34;: {\u0026#34;InstanceId\u0026#34;: \u0026#34;i-0b22a89b0bb3faf49\u0026#34;}}, \u0026#34;period\u0026#34;: 60, \u0026#34;stat\u0026#34;: \u0026#34;Maximum\u0026#34;}, \u0026#34;returnData\u0026#34;: true}]}}} と、ここで別途最近実施した、特別カスタマイズをしないアラーム + SNS送信検証時のメールを見たら、英語のみとはいえこっちの方がまだ全然見やすい。そりゃわかりにくいけど、JSON生データよりマシ。もう本文はこれでいいんじゃね？という気もするんだが。件名も、アラーム名が件名に入るんだから識別・フィルタしやすいアラーム名にすればどうにかなりそうな気もする。\u0026hellip;と、減速気味になってきた。\n\u0026hellip;が！以下の補足事項を思い出した。アラーム単体では無効化・有効化の制御ができない。となると、やはりEventBridgに組み込む方がいいんだよな。うーむ\u0026hellip;。頭痛いから明日考えよう。明後日かもしれない。\n補足 アラームを一時無効化したい場合は、Rule側で制御する。マネコンで対象のルールを選択して、「Distable/無効にする」ボタンを押下。（アラーム単体ではこの機能がない）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-lambda/","summary":"CloudWatchアラーム + SNSトピックでメール飛ばす時の件名を変更したい。ということで、過去記事 AWS EventBridge + SNSからのメール件名をカスタマイズする でイベントからのメール通知でやったことを、アラームに変えてやってみた。アラームのトリガーはEC2インスタンスCPU使用率閾値超えとする。\nベースの参照は以下クラメソさんネタ。ただしこちらは本文のカスタマイズであり、件名は変えていない。またLambdaも使用していない。これに先の過去記事パターンを合体させてやってみた。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\n処理概要 CloudWatchアラームのステータスがALARMに変わる。 Lambda関数起動 SNSに連携される メール通知 作業概要 SNSトピック作成〜サブスクライブ CloudWatchアラーム作成 Lambda関数作成（Lambda用IAMロールは既存流用） EventBridgeルール作成 EventBridgeルールのターゲットに3.のLambda関数を設定する 対象EC2インスタンスのCPU負荷を上げてアラームステータスにする メール通知確認 検証に使用したアイテム アイテム 名称 SNSトピック alarm-notification-topic CloudWatchアラーム CPU_Utilization_Test Lambda関数 cw-alarm-sns-function EventBridgeルール cw-alarm-rule やったこと SNSトピック作成、Lambda関数作成は冒頭のリンク過去記事でもやったので省略。Lambda関数の環境変数でSNSトピック、メール件名を指定している。一応後半にスクショあり。\nCLIよりCloudWatchアラーム作成。少ない負荷でもアラームステータスになるように閾値は10%にしてある。\n$ aws cloudwatch put-metric-alarm --alarm-name \u0026#34;CPU_Utilization_Test\u0026#34; \\ --metric-name \u0026#34;CPUUtilization\u0026#34; \\ --namespace \u0026#34;AWS/EC2\u0026#34; \\ --statistic \u0026#34;Maximum\u0026#34; \\ --period 60 \\ --evaluation-periods 1 \\ --datapoints-to-alarm 1 \\ --threshold 10 \\ --comparison-operator \u0026#34;GreaterThanThreshold\u0026#34; \\ --dimensions \u0026#34;Name=InstanceId,Value=i-0xxxxxxxxxxx9\u0026#34; EventBridgeルールの作成。以下の場合、\u0026ldquo;CPU_Utilization_\u0026ldquo;を含むアラームと関連付けられる","title":"CloudWatchアラーム + SNSからのメール件名をカスタマイズする"},{"content":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n（以降軽くNSFW画像あり。閲覧注意）\n記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す 上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\nハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\nキーワード 質問例 What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？ Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？ When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？ Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？ Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？ Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？ How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？ 自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。\n人はだれでも、自分に助言を求めてくる人の見識を高く評価する\n（We all admire the wisdom of people who come to us for advice.）\nー 19世紀のイギリスの作家 アーサー・ヘルプスの言葉\n最後の「教えてください」。これは相手を間接的に褒める手法だそうだ。ほぉぉ。\nブリガム・ヤング大学助教授で、組織の対人関係を研究するケイティ・リルエンクイスト氏らは、「助言を求められることは、基本的に嬉しいことだ」と言います。 なぜなら、助言を求める行為には、暗黙に「あなたの考えや価値観を支持している」というメッセージが含まれるから。 「教えてください」とアドバイスを求めることは、相手を立てることと同様の意味をもつのです。\nこれはわかる気がするな、同じ助言の依頼でも「教えてくれくれ」的に無作法または横暴に聞かれると不愉快でしかないが、リスペクトの気持ちを込めた依頼は、相手の気分をよくすることができる。\nそこには「あなたは私が知らない知見/情報を持っていると思う、あなたのその知恵を私に分けて貰えたら非常にうれしい」という、メタメッセージが込められているんだ。そういうメッセージを受け取って悪い気分になる人間は滅多にいない。\nまぁ自分今もいろいろ思うことがあってこの記事を書いているわけだが\u0026hellip;.、まったく関係なく、ふと別の言葉を思い出した。\n村上龍の小説「5分後の世界」に登場するミズノ少尉は、「絶対に最悪の事態を想像するな」と言った。俺はミズノ少尉のような器ではない。けど、ミズノ少尉のような存在をリスペクトするし、こういう人物と一緒に仕事ができたら嬉しいし、（それこそ、いてくれるだけでいい）少なくとも自分もミズノ少尉に近づけるように努めたいとは思う。\n何か主旨が散逸してしまい、「いてくれるだけでいい人」の理由は解明されていない気がする。まぁ理由は他にもいろいろあるよね、ということで。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/skill-in-communication/","summary":"職場とか、いろんなチーム・グループの中で、「この人がいてくれると安心」「いてくれるだけでいい」と思える人が稀にいる。本当に、稀に、だが。そういう人と、その他の人々の違いは一体何なのか、とモヤっと不思議に思っていた。若干解明できそうなのが、以下の記事。ここに書かれている要因だけではないと思うが、理由の一部としては納得できる。\n「いるだけでチームの雰囲気をよくする人」の口癖4つ。“ど” から始まるあの言葉がかなり使える\n（以降軽くNSFW画像あり。閲覧注意）\n記事では「いるだけでチームの雰囲気をよくする人」の4つの要素を述べている。\n「ちょうどよかった」悪い状況にある時でもポジティブに捉える 「ありがとう」を言う時に別途感謝の言葉を添える どの、どのように、どちらか、等「ど」ではじまる質問で相手の話を引き出す 「教えてください」で相手へのリスペクトの気持ちを表す 上記のうち、1.と2.は他の自己啓発系コンテンツでもよく目にする話なので割愛する。まぁ「感謝の言葉を出し惜しみしない」、これは確かに大事だよ、俺も実践してる。相手によるけどね。\n3.は、俺はこれは実践する気ないけど、要するに聞き上手になって相手の気分をよくしてやれ、つうことだ。\nハーバード大学の研究論文（2012年）によると、自分の話をしているとき、おいしい食事をするときや収入を得るときと同じように脳の報酬系という部位が活性化したことが、 約300人の脳をfMRIでスキャンした結果からわかったのだそう。私たちが聞き上手な人に好感を抱くのは、「自分の話をするのが好き！」という人間の本能を満たしてくれるからなのかもしれません。\n「上手に質問をすれば共感力が上がり、相手に好感を抱かせることができる」につながる、と。俺は「聞き上手ボランティア」をやる気はさらさらないが、興味深いのは先の引用にある「自分の話をするのが好き！という人間の本能」だ。よくいるよな、人の話は全然聞かないで、延々と自分のことを話したがるやつ。（ま、経験上女に多いという傾向は、ある）\n俺は今までそういうやつのことを、ただ自己愛が強くて、その自己愛を充足させるために他人に自分話を押売りして聞かせているもんだと思っていた。しかし上記引用で、「自分の話をしているときに脳の報酬系が活性化する」というのを読んで「そうか！」とひらめいた。脳の報酬系とはドーパミンのことである。ドーパミンは快楽を司る神経伝達物質だ。つまり自分のことを話すのは、人類共通の快感だったのだ！\nまぁ確かに、自分だってそういう面があるのは認めるよ。よく「話を聞いてもらってスッキリした」って言うもんな。何で話すだけでスッキリするのかって、ちゃんと理由があったんだな。しかしこれも度がすぎると聞かされる相手が迷惑だし、みっともないという自覚はある。自分のことを延々と話す人は、その制御が効かなくて、自らの快感原則に従って暴走しているんだろう。プラス自己愛もあるだろうけどね、どっちにしろこの手の人間とは遠い距離を置きたいものである。相手だけ満足して、自分はエネルギー吸い取られるだけだからな\u0026hellip;\n話が大分脱線した、本来の主旨に戻る。うまい質問の仕方。「ど」で始まる疑問符がキーらしいが、具体的には記事の引用を俺なりにアレンジすると以下のようになる。（仕事関連の想定じゃないとピンと来ないもんで\u0026hellip;）\nキーワード 質問例 What ー＞「どう、どんな」 どんな理由でこの仕事を始めたんですか？ Who ー＞「どの人、どんな人」 どんな人と仕事してみたいですか？ When ー＞「どんなとき、どのタイミング」 どんなときに達成感を感じますか？ Where ー＞「どこに、どこで」 どこでその分野を学んだのですか？ Why ー＞「どうして」 どうしてその製品に人気が集中するんでしょうね？ Which ー＞「どれ、どっち」 どちらのアイデアが気に入りましたか？ How ー＞「どうやって、どのように」 どのようにしてその課題を解決したんですか？ 自己愛満々野郎の自分話を聞かされるのはゴメンだが、まともな相手とのコミュニケーション手法としては頭の片隅においておこう。\n人はだれでも、自分に助言を求めてくる人の見識を高く評価する\n（We all admire the wisdom of people who come to us for advice.）\nー 19世紀のイギリスの作家 アーサー・ヘルプスの言葉\n最後の「教えてください」。これは相手を間接的に褒める手法だそうだ。ほぉぉ。\nブリガム・ヤング大学助教授で、組織の対人関係を研究するケイティ・リルエンクイスト氏らは、「助言を求められることは、基本的に嬉しいことだ」と言います。 なぜなら、助言を求める行為には、暗黙に「あなたの考えや価値観を支持している」というメッセージが含まれるから。 「教えてください」とアドバイスを求めることは、相手を立てることと同様の意味をもつのです。\nこれはわかる気がするな、同じ助言の依頼でも「教えてくれくれ」的に無作法または横暴に聞かれると不愉快でしかないが、リスペクトの気持ちを込めた依頼は、相手の気分をよくすることができる。\nそこには「あなたは私が知らない知見/情報を持っていると思う、あなたのその知恵を私に分けて貰えたら非常にうれしい」という、メタメッセージが込められているんだ。そういうメッセージを受け取って悪い気分になる人間は滅多にいない。\nまぁ自分今もいろいろ思うことがあってこの記事を書いているわけだが\u0026hellip;.、まったく関係なく、ふと別の言葉を思い出した。\n村上龍の小説「5分後の世界」に登場するミズノ少尉は、「絶対に最悪の事態を想像するな」と言った。俺はミズノ少尉のような器ではない。けど、ミズノ少尉のような存在をリスペクトするし、こういう人物と一緒に仕事ができたら嬉しいし、（それこそ、いてくれるだけでいい）少なくとも自分もミズノ少尉に近づけるように努めたいとは思う。\n何か主旨が散逸してしまい、「いてくれるだけでいい人」の理由は解明されていない気がする。まぁ理由は他にもいろいろあるよね、ということで。","title":"「いてくれるだけでいい人」の理由"},{"content":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n参考\nCloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例 以下は今後の参考用\nCloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例 処理概要 CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知 作業概要 SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認 ※ログストリーム作成は検証時のみ。通常は自動生成される。\n今回の検証に使用したアイテム（個人メモ） アイテム 名称 SNSトピック log-monitor-topic Lambda用IAMロール send-log-filter-role Lambda関数 send-log-filter-function サブスクリプションフィルタ send-log-filter やったこと SNSトピック作成〜サブスクライブ\n過去記事:AWS EventBridge + SNSからのメール件名をカスタマイズするに書いたので省略。ここではCLIでやってるけどマネコンでも特にハマるところはない。アクセスポリシーはデフォルトにした。 Lambda用IAMロール作成\nとりあえず以下のマネージドポリシーをアタッチ。 CloudEatchLogsFullAccess AmazonSNSFullAccess Lambda関数作成\n(1) 参考ブログのコード貼り付け import base64 import json import zlib import datetime import os import boto3 from botocore.exceptions import ClientError print(\u0026#39;Loading function\u0026#39;) def lambda_handler(event, context): data = zlib.decompress(base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]), 16+zlib.MAX_WBITS) data_json = json.loads(data) log_entire_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;], ensure_ascii=False)) log_entire_len = len(log_entire_json) print(log_entire_json) for i in range(log_entire_len): log_json = json.loads(json.dumps(data_json[\u0026#34;logEvents\u0026#34;][i], ensure_ascii=False)) try: sns = boto3.client(\u0026#39;sns\u0026#39;) #SNS Publish publishResponse = sns.publish( TopicArn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;], Message = log_json[\u0026#39;message\u0026#39;], Subject = os.environ[\u0026#39;ALARM_SUBJECT\u0026#39;] ) except Exception as e: print(e) (2) 環境変数をセット(Configration/設定タブ ー＞ 左ペインのEnvironment variables/環境変数)\nKey Value SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:log-monitor-topic CUSTOM_SUBJECT エラーログ送信テスト ロググループ/ログストリーム作成\nマネコンから普通にできるので省略。 サブスクリプションフィルタ作成\nロググループの画面から作成する。 配信先として先に作成したLambda関数を指定する。ログフォーマットは当初OtherにしたがJSONでいいらしい。（まだよくわかっていない\u0026hellip;）\n事前にメッセージを投入しておけばここでテストできる。メッセージが何もない場合はスキップ。\n最後に[Start streaming]押下で完了。\n作成後のサブスクリプションフィルタ。作成後に変更したい場合はマネコンからはできないため、CLIから設定する。詳細は後述の補足事項に記載。\nテストログ送信〜メール通知確認\nこのテストログ送信方法については、クラメソさんや他の記事ではCLIからput-log-eventsを実行しているが、正直面倒くさい。マネコンからやる方が簡単なのでここではその手順を記載。 対象のログストリーム画面から、[Actions(アクション)] ー＞ [Create log event（ログイベントの作成）]と遷移し、テストイベントを発行する。\nメール通知を確認。届いた！\n\u0026hellip;と、ここまで普通にできたっぽく書いているが、実際には何かとハマって手こずってしまった。当初メールが届かなくてね。複数の記事を参考にしているが、それぞれ微妙に手順や実装が異なるから、少しどこかをいじるとNGになったりする。\nメールが届かないのはSNSが原因と思ったけど（Lambdaでエラー出ていないから）、Lambda自体のログにテストイベントのメッセージが何も出力されていないことに気づいて、Lambdaがイベントを取得できていなくてSNSにメッセージが渡っていないことが原因とわかった。コードも若干入れ替えたり編集したりしたんで。自分は紆余曲折しておかしなことになったが、最初はクラメソさんのコードをそのまま使って手順通りにやればできるはず。応用はその後。\n補足事項 サブスクリプション作成後の変更\nサブスク作成後はマネコンからは直接変更できないが、CLIで編集可能。aws logs put-subscripution-filterで同じサブスク名を指定すれば設定が上書きされる。 $ aws logs put-subscription-filter ¥ --log-group-name [your log group name] ¥ --filter-name [your subscription filter name] ¥ --filter-pattern [your filter pattern] ¥ --destination-arn [your destination arn] ※今回の場合Lambda関数のARN フィルタパターン編集\nフィルタパターンでOR条件するには、キーワード間はスペース区切りとし、各キーワードの先頭に?をつける。除外フィルタはまた別に必要で複雑になる。Lambda関数内で設定することも可能なので、要件に応じて検討。 フィルタパターンOR条件例\nこれを作成済みのサブスクに適用したい場合は、上記1.のCLIコマンドの--filter-patternオプションの値として指定すればよい。\n\u0026#34;?error ?Error ?ERROR ?fail ?Fail ?FAIL\u0026#34; 除外キーワードをセットするのはちょっと面倒で、こんな風になる。以下の場合、メッセージが\u0026quot;error event\u0026quot;の場合は検知され、\u0026ldquo;error test\u0026quot;の場合は検知されない。\n\u0026#34;[( msg=¥\u0026#34;*error*¥\u0026#34; || msg=¥\u0026#34;*Error*¥\u0026#34; ) \u0026amp;\u0026amp; ( msg!=¥\u0026#34;*test*¥\u0026#34; \u0026amp;\u0026amp; msg!=¥\u0026#34;*Test*¥\u0026#34; \u0026amp;\u0026amp; msg!=¥\u0026#34;*TEST*¥\u0026#34; )]\u0026#34; Lambdaコード内で除外キーワード定義することも可能だが、検知キーワードと除外キーワードが別れるのもどうなんかと思うし、迷うところ。\nAPIから実装する際の追加作業\nサブスクリプションフィルタ作成時、マネコンだと自動で付与される権限がCLIでは付与されないため、事前にLambda側で権限を追加する。--statement-idは適当な文字列でいいと思われる。多分。 $ aws lambda add-permission ¥ --function-name [your function name] ¥ --statement-id \u0026#34;your statement id\u0026#34; ¥ --principal \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; ¥ --action \u0026#34;lambda:InvokeFunction\u0026#34; ¥ --source-arn \u0026#34;arn:aws:logs:ap-northeast-1:[your account id]:log-group:*:*\u0026#34; ¥ --source-account [your account id] TerraformやCFnから作成する場合も同じ作業が必要になるはずだから要注意。\n参考: add-permission\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-send-filter-mail/","summary":"AWSでのログ監視メール送信はサブスクリプションフィルタ + Lambda + SNSを使用するのがスタンダード。みんなやっていそうなことだが未経験だったのでやってみた。基本参考にしたのは王道クラメソさんの記事だったが、ちょっとわかりにくいところがあったので他の記事も合わせて参照して若干やり方変えつつ検証した。\n今回はマネコン作業メインでやったが、CLIやTerraformなどAPI経由で実装する場合追加作業が発生するため注意が必要。(後述 補足事項に記載)\n参考\nCloudWatch Logs を文字列検知してログ内容をメールを送信してみた サブスクリプションフィルター版 【AWS】CloudWatch Logsからシステムログをメール通知する。 CloudWatch Logs のサブスクリプションフィルタを使って特定文字列を検知したログをEメール通知する ※CLI実装例 以下は今後の参考用\nCloudWatchLogsの内容をフィルタリングしてLambdaで通知させたい ※除外キーワードをコードで記述する例 CloudWatchLogsからLambda経由でログメッセージを通知する ※Terraform実装例 処理概要 CWLにログが出力される CWLのサブスクリプションフィルタでキーワード検知 Lambda関数起動 SNSに連携される メール通知 作業概要 SNSトピック作成〜サブスクライブ Lambda用IAMロール作成 Lambda関数作成 ロググループ/ログストリーム作成 ロググループにサブスクリプションフィルタ作成 （配信先に3.のLambda関数を指定） テストログ送信〜メール通知確認 ※ログストリーム作成は検証時のみ。通常は自動生成される。\n今回の検証に使用したアイテム（個人メモ） アイテム 名称 SNSトピック log-monitor-topic Lambda用IAMロール send-log-filter-role Lambda関数 send-log-filter-function サブスクリプションフィルタ send-log-filter やったこと SNSトピック作成〜サブスクライブ\n過去記事:AWS EventBridge + SNSからのメール件名をカスタマイズするに書いたので省略。ここではCLIでやってるけどマネコンでも特にハマるところはない。アクセスポリシーはデフォルトにした。 Lambda用IAMロール作成\nとりあえず以下のマネージドポリシーをアタッチ。 CloudEatchLogsFullAccess AmazonSNSFullAccess Lambda関数作成\n(1) 参考ブログのコード貼り付け import base64 import json import zlib import datetime import os import boto3 from botocore.","title":"CloudWatchLogsのログ監視 - サブスクリプションフィルタ + Lambdaでメール送信"},{"content":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n\u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\nそれから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\nここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\nDo not go gentle into that good night,\nRage, rage against the dying of the light.\nあぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/stockholm-syndrome/","summary":"昨年の過去ツイのスレッドでちょっと気になるのを見つけたので、若干手を入れてここにまとめて書いておく。\n暴力の加害者に対して被害者が好意を抱く「ストックホルム症候群」と567脳、マスク厨の心理は似てないか？側から見ると、あの人たちは自由や人権を奪われている今の状況を愛しているように見える。\nその裏では「認知的不協和の解消」が発生している可能性がある。これは、自分の内部の矛盾に一貫性を持たせようとする機能。「新しい生活様式」だの、自粛しろマスクつけろだの、不自由で不本意な状況を強いられているが、それを受け入れている自分に葛藤が生じているはずなのだ。\nだからマナーだの何だの言って正当化している。または無意識に自分を麻痺させている。どちらにしても認知に修正を加えて不協和（矛盾）を解消しようとしているわけで、つまり認知に歪みが発生している。だから苦痛さえ感じなくなっているのではないかと想像する。\nそれから、「沖縄から貧困がなくならない本当の理由」（樋口耕太郎著）からの引用なのだが、こういった自己防衛の心理も働いているかとも。\n人間は激しい痛みを感じると、自分の感覚を鈍らせて自己防衛を図る性質があるが、それは絶望の耐え難い痛みを和らげるために、自分自身に打つ麻酔のようなものだ。\n自分に麻酔を打って思考や身体感覚を麻痺させたり、自ら認知を歪ませれば、見かけ上は苦痛が和らぐ。しかし同時に生きる上でのあらゆる喜びもまた、感じることができなくなる。そして本来あるべき自分の自由と権利を、忘却の彼方に押しやっている。それは虚構の世界を生きているだけなのだ。\n\u0026hellip;と、まぁ当時はこんなことを思いつくままに呟いてみたが、大半の世間のコロナ恐怖脳はここまで複雑な心理の綾などなく、自分で調べたり考察することもなくひたすら垂れ流される情報を鵜呑みにして怖いね怖いねと決まり文句を言ってるだけのように見える、それが世間の掟だから。\nもちろん、マスク・アルコール消毒・検温や在宅勤務を強制または半強制されることに疑問を抱くこともない。一切の疑問も抱かずに、受け入れているのだ。昼の外食時に周りから聞こえてくる会話を聞いていると呆れる、それなりに一流と呼ばれる企業に勤めていてある程度の地位についていそうな人たちが、そんな具合なのである。\nまぁ何にせよ、認知の歪みが生じていることは確か、40度近い真夏日に病気でもないのにマスクとか異常でしかないよ。\nそれから「家庭内ストックホルム症候群」という言葉もある。児童虐待やDVを受けている被害者が、自分を虐待・無視などで苦しめる親や配偶者（多くの場合夫）に不満や憎しみを抱きつつも、見捨てられたらどうしようと、過剰な不安や恐怖心が芽生える。そこで無意識の内に親や配偶者が気に入られるように「良い子」「良い妻」を演じてしまう\u0026hellip;ということらしい。\nいやでもこれって別に、ストックホルム症候群という名称を持ち出すまでもなく、より普遍的な事象だと思うな、人間が暴力・抑圧・嫌がらせに対して自分の心を麻痺させて適応を試みる心理が働くのは、きっと人間のデフォルト機能なんだよ、悲しい機能だけど。\nDVの他に大学内の教授と生徒の間に発生する「アカハラ」、職場のパワハラでも同様の状態になるよね、理不尽なハラスメントを受けているのに、それを客観視できない状態にあると、相手に気に入られようとして相手に従い、相手の意に沿うように行動してしまうんだ。\nこれには2つの要因がある、生き延びるための生存本能と、他者に愛されたい、承認されたいという、ヒトとしての社会的本能。しかしそれで相手がハラスメントを辞めるかと言ったら逆だ、「こいつはいじめれば何でも言うことをきく」と思われてエスカレートするだけだ、全く本質的な解決にはならず、状況が悪化するだけなんだよ。\nここまでの文章は、今年2021年の1月に別のブログに投稿した内容を編集・加筆したものだ。そこに置いておいても塩漬けになるだけだからこっちに持ってきた。文章中に登場するツイは、とうにアカウント削除したので今は存在しない。「家庭内ストックホルム症候群」から先は今回追記したもの。主旨が途中からずれている気がするが、まぁ気にしない。\nTwitterなんか最低のクソメディアだと思うが、ふと思いついて書いたことでも後でこうして振り返って考察することもあるから、そういう意味では少しはやる価値あったかな。\n結局何が言いたいのかってね、多くの人間は、ハラスメントを受けている最中は、状況を客観視できないんだよ、かつ、生存本能と社会的本能のためにその状況に適応しようとして、自分を押し殺してハラスメントをする相手や周囲に従ったり、意に沿わない行動をとったりしがちなんだ。これは自覚しないといけないし、あらゆるハラスメントには声をあげ、全力で抵抗しなけりゃいけないんだ、それこそ、羊や奴隷ではなく、主権を持った人間として生きるために。\n過去記事にも書いたDylan Thomasの詩の一部。本来の詩の主旨は違うけど、今のこの世界に対して、全く同じことを言いたいね。\nDo not go gentle into that good night,\nRage, rage against the dying of the light.\nあぁまったく、俺はやっぱりこのまま死ぬわけにはいかねぇ、大人しく従ってちゃダメなんだ、激怒して、憤怒して、死にもの狂いで抵抗しなくちゃいけないんだ。","title":"「ストックホルム症候群」の心理はヒトのデフォルト機能だった"},{"content":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3 $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9) pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026#34;/usr/local/lib/python3.9/site-packages:\u0026#34; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software. Future versions of macOS will not include Python 2.7. Instead, it is recommended that you transition to using \u0026#39;python3\u0026#39; from within Terminal. Python 2.7.16 (default, Aug 30 2021, 14:43:11) [GCC Apple LLVM 12.0.5 (clang-1205.0.19.59.6) [+internal-os, ptrauth-isa=deploy on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; python3を実行するにはpython3とタイプ。\n$ python3 Python 3.9.7 (default, Oct 13 2021, 06:45:31) [Clang 13.0.0 (clang-1300.0.29.3)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; boto3が消えていたのでこれも再インストールした。\n$ pip3 install boto3 $ pip3 freeze boto3==1.18.63 botocore==1.21.63 Jinja2==2.11.2 jmespath==0.10.0 MarkupSafe==1.1.1 python-dateutil==2.8.2 PyYAML==5.3.1 s3transfer==0.5.0 six==1.16.0 urllib3==1.26.7 全く無関係に在りし日の記録。（2019年）\nはるばるアルゼンチンから、こんなに大勢の人が日本に来てくれたんだよ、あの頃は。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-python3-re-install/","summary":"Mac上のpython3。しばらく前にhomebrewと一緒に削除してしまったので入れ直した。\n$ brew install python3 $ which python3 /usr/local/bin/python3 $ python3 -V Python 3.9.7 $ pip3 -V pip 21.2.4 from /usr/local/lib/python3.9/site-packages/pip (python 3.9) pythonだけで実行するとゴニョゴニョ言われる。\n$ python Your PYTHONPATH points to a site-packages dir for Python 3.x but you are running Python 2.x! PYTHONPATH is currently: \u0026#34;/usr/local/lib/python3.9/site-packages:\u0026#34; You should `unset PYTHONPATH` to fix this. $ unset PYTHONPATH で、この後pythonを実行すると2系になってしまう。\n$ python WARNING: Python 2.7 is not recommended. This version is included in macOS for compatibility with legacy software.","title":"MacにPython3を再インストール"},{"content":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\nうん、そのつもりでやっていくしかねぇ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1027/","summary":"あー、マジやべぇ、息が詰まりそうだ、いろいろと、勘弁してくれよもう的な動きが多くてさ、めっちゃやり辛い。まじで、10月入ってからすげえやり辛くなった。鬱屈がたまってどうしようもねぇ。\nしばらく前から通勤時に英文小説読む余力もないし、Tumblrやり過ぎるとDVT症候群で頭痛と目眩がするし、イヤホンで大音量で音楽聴きすぎて耳がイカレそうだし、もう何を支えにしていいかわからないな、オレは生き延びることができるんだろうか？\nそりゃ仕事があるだけありがたい立場だってことは忘れちゃいけないけどね、もし今「戦争」状態じゃなかったらいつでも出ていけるんだからな、なにせ俺様能力高いからな。\nうん、そのつもりでやっていくしかねぇ。","title":"ひとり言 - 10月27日"},{"content":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\nもうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.\n","permalink":"https://ecnedaced-seirots.github.io/post/a/life-1025/","summary":"10月25日の明け方に見た夢。コンサート会場みたいなところ。そこはロンドンである。観客が大勢いて賑わっている。そしてノーマスク。「あぁ、マスク圧解禁されたのか！」と嬉しい。よく見ると数人はマスクしている、でもほぼノーマスク。あぁ。\nもうずっとリアル世界で不快なものしか見てないから、せめてここだけでも。これくらいいいだろ\u0026hellip;.","title":"Eye Candyがいるんだ"},{"content":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\nアイテム 名称 SNSトピック custom-event-notification Lambda用IAMロール custom-event-mail-role Lambda関数 custom-mail-function eventルール custom-mail-rule ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026#34;SubscriptionArn\u0026#34;: \u0026#34;pending confirmation\u0026#34; } 指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。\ntrust-policy.json\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } $ aws iam create-role --role-name custom-event-mail-role --assume-role-policy-document file://trust-policy.json ロールにAWSマネージドポリシーをアタッチ。\n$ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole $ aws iam attach-role-policy --role-name custom-event-mail-role --policy-arn arn:aws:iam::aws:policy/AmazonSNSFullAccess ここまでで、IAMロール完成。次に、以下内容のLambda関数のコードを用意する。\ncustom-mail.py\nimport boto3 import json import os sns_arn = os.environ[\u0026#39;SNS_TOPIC_ARN\u0026#39;] custom_subject = os.environ[\u0026#39;CUSTOM_SUBJECT\u0026#39;] def lambda_handler(event, context): print(sns_arn) client = boto3.client(\u0026#34;sns\u0026#34;) resp = client.publish(TargetArn=sns_arn, Message=json.dumps(event), Subject=custom_subject) これをzipにする。\n$ zip custom-mail.zip custom-mail.py IAMロールとzipファイルを指定してLambda関数を作成。\n$ aws lambda create-function --function-name custom-mail-function --role arn:aws:iam::my-account-id:role/custom-event-mail-role --runtime python3.8 --handler custom-mail.lambda_handler --zip-file fileb://custom-mail.zip 環境変数をセット。ここでSNSトピックARNと、送信したいメール件名を定義している。\n$ aws lambda update-function-configuration --function-name custom-mail-function --environment Variables=\u0026#39;{SNS_TOPIC_ARN=\u0026#34;arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification\u0026#34;,CUSTOM_SUBJECT=\u0026#34;カスタムメールタイトル送信テスト\u0026#34;}\u0026#39; 変数名 値 SNS_TOPIC_ARN arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification CUSTOM_SUBJECT カスタムメールタイトル送信テスト トリガーとなるイベントルールを作成。本当はec2のCPU使用率のアラームでメール飛ばしたいがここは参考ページの通りにする。\nevent-pattern.json\n{ \u0026#34;source\u0026#34;: [ \u0026#34;aws.s3\u0026#34; ], \u0026#34;detail-type\u0026#34;: [ \u0026#34;AWS API Call via CloudTrail\u0026#34; ], \u0026#34;detail\u0026#34;: { \u0026#34;eventSource\u0026#34;: [ \u0026#34;s3.amazonaws.com\u0026#34; ], \u0026#34;eventName\u0026#34;: [ \u0026#34;CreateBucket\u0026#34;, \u0026#34;DeleteBucket\u0026#34; ] } } eventsのルールを作成する。\n$ aws events put-rule --name custom-mail-rule --event-pattern file://event-pattern.json { \u0026#34;RuleArn\u0026#34;: \u0026#34;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\u0026#34; } Lambdaにルールの実行権限を追加。\n$ aws lambda add-permission --function-name custom-mail-function --statement-id 1 --principal events.amazonaws.com --action \u0026#39;lambda:InvokeFunction\u0026#39; --source-arn arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule { \u0026#34;Statement\u0026#34;: \u0026#34;{\\\u0026#34;Sid\\\u0026#34;:\\\u0026#34;1\\\u0026#34;,\\\u0026#34;Effect\\\u0026#34;:\\\u0026#34;Allow\\\u0026#34;,\\\u0026#34;Principal\\\u0026#34;:{\\\u0026#34;Service\\\u0026#34;:\\\u0026#34;events.amazonaws.com\\\u0026#34;},\\\u0026#34;Action\\\u0026#34;:\\\u0026#34;lambda:InvokeFunction\\\u0026#34;,\\\u0026#34;Resource\\\u0026#34;:\\\u0026#34;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\\\u0026#34;,\\\u0026#34;Condition\\\u0026#34;:{\\\u0026#34;ArnLike\\\u0026#34;:{\\\u0026#34;AWS:SourceArn\\\u0026#34;:\\\u0026#34;arn:aws:events:ap-northeast-1:my-account-id:rule/custom-mail-rule\\\u0026#34;}}}\u0026#34; } Lambda関数をルールのターゲットとしてセットする。\n$ aws events put-targets --rule custom-mail-rule --targets \u0026#34;Id\u0026#34;=\u0026#34;Target1\u0026#34;,\u0026#34;Arn\u0026#34;=\u0026#34;arn:aws:lambda:ap-northeast-1:my-account-id:function:custom-mail-function\u0026#34; { \u0026#34;FailedEntryCount\u0026#34;: 0, \u0026#34;FailedEntries\u0026#34;: [] } バケットを作成して通知テスト\n$ aws s3 mb s3://custom-mail-sending-test-xxxx \u0026hellip;しかしメール届かない。て、CloudTrailが無効になっているんだから当然である。で、CloudTrailを有効にしてから先ほど作成したバケットを消してみる。したら、\u0026hellip;設定した件名「カスタムメールタイトル送信テスト」で通知メールが届いた！\nLambda関数の画面ではトリガーがEventBridgeになっているが、移行期間中はカッコでCloudWatche Eventsも併記されるっぽい。\nEvents側でもルールとLambda関数が紐付いていることがわかる。ちなみにこれはCloudWatche Eventsの画面から見ているが、同じルールがEventBridgeの画面にも存在するはずである。\nメール本文。JSONの生データそのまんま。「人間」の感覚としてはこんなん送られてもなぁ\u0026hellip;としか思えないが、\u0026ldquo;DeleteBucket\u0026quot;の記録があることは一応わかる。\nCloudTrailはもういらんので削除。\u0026hellip;で、SNSからのメールは件名カスタマイズできるのはわかったが、アラームと組み合わせるとなるとまた別の調整が必要。その辺がわからん。次回の課題。\n（追記）後日改良版にトライした\nイベント監視 メール本文カスタマイズ版\nAWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ(2)\nリソース監視 アラーム通知版\nCloudWatchアラーム + SNSからのメール件名をカスタマイズする 本文のカスタマイズ例。これはLambda使ってないけど、今回のコードをアレンジすればできるっぽいからそっちに寄せたい感じ。\nCloudWatch アラームの通知メールを少しでも読みやすくしたい\nEventBridgeって結局元CloudWatchEventsのことなんだが、まだよくわかっていないのでこの辺も調べておく。\nAmazon EventBridgeとは何か\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-events-custom-mail/","summary":"表題の件、通知メールの件名はわかりやすいのにしたいよねというニーズに対応すべく、以下参考に試してみた。やったことはほぼこちらの記事の通り。\nAmazon SNS で送られる CloudWatch Events ルールの通知内容をカスタマイズする\n上記の通りやっていけばできるんだけれど、整理するためにも自分用に記録残す。ちなみに2021年10月現在、CloudWatch EventsはEventBridgeになっている。移行期間中だからまだ違和感があるが、この記事では名称は「EventBridge」とする。それと後半で書いているが、今回の事例ではCloudTrailが有効になっていることが前提なので、現状無効の場合は有効にしておく。\n各種リソースに類似の名称が多くて混乱するので、これも自分用に整理。以下、今回作成したリソース名称。\nアイテム 名称 SNSトピック custom-event-notification Lambda用IAMロール custom-event-mail-role Lambda関数 custom-mail-function eventルール custom-mail-rule ではここから作業内容の記録に入る。\nSNSトピック作成\n$ aws sns create-topic --name custom-event-notification サブスク（サブスクリプション）作成\n$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification --protocol email --notification-endpoint [my mail address] { \u0026#34;SubscriptionArn\u0026#34;: \u0026#34;pending confirmation\u0026#34; } 指定したアドレスにメールが届くので、リンク押下してconfirmする。その後マネコンのSNS画面を見るとサブスクのステータスがconfirmedになっているはず。\nまたは、以下確認コマンド\n$ aws sns list-subscriptions-by-topic --topic-arn arn:aws:sns:ap-northeast-1:my-account-id:custom-event-notification ここからLambdaの作業に入る。最初にLambda用のIAMロールを作成。以下の内容で信頼ポリシー用のJSONファイルを用意し、それを指定してロール作成実行。\ntrust-policy.json\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;lambda.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } $ aws iam create-role --role-name custom-event-mail-role --assume-role-policy-document file://trust-policy.","title":"AWSイベント監視 - CloudTrail + EventBridge + Lambdaでメールカスタマイズ"},{"content":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。バケットにオブジェクトロックがかかっていると動作しないので注意。\nバケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] } 上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行 エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n上記に書いた作業は必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するだろう。\n追記\nということで、Lambdaによるログエクスポートの記事書いた。\nCloudWatch LogsからS3にエクスポート(Lambda/Python) ","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatchlogs-s3-export/","summary":"CloudWatchLogsからS3へログをエクスポートする。基本的に以下の通りにやればできるのだが、説明が冗長だったりわかりにくいところがあるので自分用に書いておく。IAMユーザ作成の手順とかいらん。親切のつもりだろうけど、無駄に記事が長くなって読む気が失せる\u0026hellip;\nコンソールを使用してログデータを Amazon S3 にエクスポートする\n概要。ログストリームのエクスポートはログストリームの画面ではなく、ロググループの画面から行う。事前にログエクスポート専用S3バケットを用意し、ドキュメントの通りにバケットポリシーを設定しておく。適当なランダム値のプレフィクスを作成し、バケットポリシーに反映する。バケットにオブジェクトロックがかかっていると動作しないので注意。\nバケットポリシーサンプル\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } }, { \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34; , \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::my-app-logs/sjh6dert3a/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; } }, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.ap-northeast-1.amazonaws.com\u0026#34; } } ] } 上記前提条件が整った上で、以下実行する。カッコ内は英語表記の場合。\n対象のログストリーム画面上で、「アクション」(Actions)のプルダウンから、「データをAmazon S3に エクスポート」(Export data to Amazon S3)を選択。 次画面でバケット名、作成しておいたS3のプレフィクス名、ログストリーム、時間の範囲指定を行い、「エクスポート」実行 エクスポート先のS3では確かzip化された状態で格納されていたと思う。\nドキュメント中の表現一部「ランダムに生成されたプレフィクス」、これがわかりにくかった。ログエクスポート先のS3にランダム文字列のプレフィクスが存在するのが望ましいようだ。なぜ普通の文字列ではなくランダム値が望ましいのかはよくわからん。「生成されたランダム文字列」と書かれているもんだから、どこで生成してるんだ？と混乱した。これは自分で適当に決めた値でよい。\n上記に書いた作業は必要に応じてアドホック的に行う対応であり、定常的対応であればLambdaなりshellなりでバッチ化するだろう。\n追記\nということで、Lambdaによるログエクスポートの記事書いた。\nCloudWatch LogsからS3にエクスポート(Lambda/Python) ","title":"CloudWatchLogsからS3へログをエクスポートする"},{"content":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/github-actions/","summary":"GitHub ActionsでCIか。このブログについては今の時点でも不自由していないから無理にやらなくてもいい気がする、けど調べておこう。\nHugo + GitHub Pages + GitHub Actions で独自ドメインのウェブサイトを構築する\n今日はとうとう電車の中で堂々と中指を突き立てた俺様であったが、週末くらいは心穏やかに過ごそう、ふぅ。","title":"Github Actionsメモ"},{"content":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n\u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\nmiddle finger second finger the finger 侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\ngive the middle finger give the finger 以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\nflip the bird fly the bird しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/the-finger/","summary":"そして俺は相変わらず中指を1000本くらい突き立てたい気分の日々が継続中なのだ。日々アドレナリンが過剰放出されてしまい、心身によろしくない。けど怒りをそのままぶちまけるのは芸がないし、自分にとってプラスにならないからね、俺はプラスになることだけやりたいわけ、だから少しでも勉強になることを書く。\n\u0026ldquo;middle finger\u0026quot;って言ったらあれです、特別な意味を持つ「中指」。\n以下はすべて同じ意味。\u0026ldquo;the finger\u0026quot;でも同じ意味になるとは知らなかった。\nmiddle finger second finger the finger 侮蔑や怒りを示すジェスチャーとなる「中指を立てる」行為は以下の表現。\ngive the middle finger give the finger 以下も同じ意味。知らなかった。でもどれだけポピュラーなんだろう？\nflip the bird fly the bird しばらく前までは心の中だけで中指を突き立てていたが、最近もう耐えられなくなって物理的にも公の場で中指を立てている俺様なのだった。","title":"middle finger周辺の表現など"},{"content":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\nパッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\nDo not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.\nGood men, the last wave by, crying how bright\nTheir frail deeds might have danced in a green bay,\nRage, rage against the dying of the light.\nWild men who caught and sang the sun in flight,\nAnd learn, too late, they grieved it on its way,\nDo not go gentle into that good night.\nGrave men, near death, who see with blinding sight\nBlind eyes could blaze like meteors and be gay,\nRage, rage against the dying of the light.\nAnd you, my father, there on the sad height,\nCurse, bless me now with your fierce tears, I pray.\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\n(Dylan Thomas, Do Not Go Gentle Into That Good Night)\nこの詩は、ディランが死に瀕した父親へ向けて書いた詩である。（\u0026hellip;というのはもちろん拾った情報）\n詩を理解するのは難しい、言葉としての意味を理解するのと文脈を理解すること、さらにその裏に表現された暗喩を理解するのは別のことだ。しかも母国語以外で。\n俺の英語力はお粗末なので、言葉の意味と文脈はどうにか掴めても、その奥の本質までは手が届きそうで届かない。しかしこの時点で今までの自分の解釈がズレていたことに気づいた。\n俺はTumblrでこの引用を初めて目にしたとき、「大人しくなんかなるなよ、消えゆく灯りに激怒しろ、憤怒しろ」と文字通りの意味に捉えていた、作家がオスカー・ワイルドと思っていたせいもあり、今そこでまだエネルギーを保持して生きている人間が自分または他人をさらに奮い立たせる意図の言葉と解釈した。それで、何か心が「ザワザワッ」としたのである。そしてrageという単語を覚えたのである。\n話変わって数ヶ月後、村上龍の「ピアッシング」を英語翻訳版で読む機会があった。そしてそこでrageという単語に再会した。コールガールのChiakiが妄想に取り憑かれた男Kawashimaに客として出会い、ふとしたきっかけでrageな状態に至る。そのシーンで、先の引用を真っ先に思い出した。ピピピッときたよね。\nその後また別の英文小説を読んだら、そこでも単語rageが登場してピピピッときた。言葉というものは、こういうプロセスを経て自分の内部に取り込まれていくのである。だからそのプロセスは、人の数だけバリエーションが存在する。\nで、話は戻って俺の英語力ではこの詩の奥深い意味を捉えるのは無理めだったので日本語訳を探してみたところ、素晴らしい翻訳があった。全部載せるのはアレなので一部だけ引用させてもらうと。\nあんな風に「おやすみ」なんて言ってさっさと諦めるなよ\nもう若くなくたって，一日が人生が終わりそうなら，烈火のごとく怒り狂って，ギャアギャアそこで喚くんだ；\n太陽の光が薄れて消えていっても，死にものぐるいで抵抗しなきゃ\nDo Not Go Gentle Into That Night ディラン・トーマス (Dylan Thomas) より\n全文はリンク先で読んでもらうとして、訳者ご本人が認めているようにかなり意訳色が強い翻訳である。しかし素晴らしい、最高だ。気持ちがストレートに伝わってくる。そしてこのリンク記事が2020年の大晦日に投稿され、「暗いニュースばかりが目立ったこの一年ですが，最後をこの力強い詩で締めくくりたい」と記されていることにもグッときた。泣けてくるぜ\u0026hellip;\n他の訳も発見したが、同じ原文がこうも異なる訳になるのかと驚く。どれが正しいということではないのだが、自分はやはり上のが一番だな。\nDo Not Go Gentle Into That Night （正当古典派訳）\natheistの意味は? – Do not go gentle into that good night （中庸派的訳）\n話はあちこちに逸脱したが、この記事ではrageという単語がどのような経緯で自分に取り込まれたのかを書きたかったのである。何故書きたかったのか？まぁこうやって頭を整理しつつ記事を書くのも、一種のアンガー・マネジメントなのかもしれない。\n中指1000本突き立てても気が済まないくらいrageな日々を送っているが、整理して調べていく過程で先ほどの素晴らしい翻訳に出会うことができた。これは幸運の極みだよ、力強く美しい言葉は、人間に偉大な力を与えてくれるんだから。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/dylan-thomas/","summary":"\u0026ldquo;rage\u0026quot;という英単語がある。名詞としては「激情、激怒、憤怒」、自動詞として「怒る、暴れる」という意味だ。これを知ったきっかけは、Tumblrで見かけた以下の引用だった。\nDo not go gentle into that good night.\nRage, rage against the dying of the light.\nパッと見てすぐに意味は理解できなかったが何か心を捉えられた感があった。\u0026ldquo;rage\u0026quot;という単語を初めて見たので調べたところ、意味は先述の通り。\nこれはウェールズの詩人ディラン・トーマス(Dylan Thomas) の詩の一部である。でもTumblrの投稿にはOscar Wildeって書いたあったような記憶がある。それで最近までずっとこの引用元をOscar Wildeだと思い込んでいたんだから。間違いだったんだなあれは。\nそれはさておき、今日この詩について少し文献を調べてみたら、この引用に対して今までの自分の解釈が若干ズレていたことがわかった。以下は引用元の詩全体である。\nDo not go gentle into that good night,\nOld age should burn and rage at close of day;\nRage, rage against the dying of the light.\nThough wise men at their end know dark is right,\nBecause their words had forked no lightning they\nDo not go gentle into that good night.","title":"単語rageを覚えたきっかけはディラン・トーマスの詩だった"},{"content":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\nMac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date=\u0026#39;/usr/local/bin/gdate\u0026#39; やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d \u0026#39;2018/5/17 00:00:00\u0026#39; +\u0026#39;%s\u0026#39; 1526482800 参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-installe-gdate/","summary":"Mac OSで標準搭載されているdateコマンドはBSD版であり、Linux標準のGNU版と微妙に異なる。Linuxと実行結果が異なったり、使用できないオプションがあったりとか。それが困るから、自宅のMacでもGNU版のdateが使いたいのである。数年前に標準のdateを入れたのだが、その後Mac本体を買い替えたタイミングで消えてしまった。\nMac OSでgnu/dateを使いたい場合、brewから入れる。install dateではなく、coreutilsとする。（他のGNU系コマンド一式が含まれる）\n$ brew install coreutils /usr/local/bin/gdateにインストールされた。（正確にはシンボリックリンク）\nこのままだとコマンドがgdateなので、gdateを\u0026quot;date\u0026quot;で実行できるようにする。以下エイリアスを.bashrcに追記。\nalias date=\u0026#39;/usr/local/bin/gdate\u0026#39; やっとできた。以下は所定の日付時刻をエポックタイム(UNIXタイムスタンプ)に変換するコマンド。Mac版のdateだと使えないんだよこれが。\n$ date -d \u0026#39;2018/5/17 00:00:00\u0026#39; +\u0026#39;%s\u0026#39; 1526482800 参考\nMacでdateコマンドが違う件について\nUNIX時間に変換・UNIX時間を取得する方法","title":"MacにGNU版dateをインストール"},{"content":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\nconfigで設定 ~/.aws/configに以下記載する。\n[default] cli_pager= 環境変数で設定 $ export AWS_PAGER=\u0026#34;\u0026#34; 1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/awscli-pager/","summary":"AWS CLI v2でデフォルトになっているページャを無効化する方法は2種類ある。\nconfigで設定 ~/.aws/configに以下記載する。\n[default] cli_pager= 環境変数で設定 $ export AWS_PAGER=\u0026#34;\u0026#34; 1.の方が推奨されているようだが、k8s(Kubernetes)のPodの場合は、マニフェストのENVに2.の環境変数を書いておけば期待値になる。","title":"AWS CLIのページャを無効化する"},{"content":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\nここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\nここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1 スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1 この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026#34;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026#34; scaleoutpolicy=\u0026#34;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026#34; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026#34;test-web-scaleout-alarm\u0026#34; \\ --alarm-description \u0026#34;Alarm when CPU exceeds 70%\u0026#34; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026#34;test-web-asg\u0026#34; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1 スケールイン時のアラームも同様に作成する。\n以下備忘録。静観対応をどうするか\nCloudWatch アラームのダウンタイム（特定期間の発報抑止）を Metric Math を使用して実現してみた\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cloudwatch-alarm-memo/","summary":"AWSで、CloudWatchアラームのメッセージをSNSトピックかましてメール送信。昔からよくあるオーソドックスなパターンだが、しばらく縁がなかったので記憶がかすんでいる。過去に構築した時の記録を掘り返してみる。\n数年前、CloudFormation（CFn）で環境構築したのだが（主担当は別のメンバー）、CWアラーム作成はCFnで作るのに不向きということでAWS CLIで作成していた。何故CFnが不向きなのか、理由は何だったか思い出せない。以下の記事を見ると普通にCFnでアラーム作成しているから問題なさそうではあるのだが\u0026hellip;\nCloudFormationでCloudWatchAlermを作成する\nここで、書いていてうっすら思い出した。過去事例ではオートスケールのアラームだったが、その場合は他のアラームと異なるのかもしれない。（つまりオートスケールのアラームはポリシーを別出しにする）確かASG（オートスケーリンググループ）自体もCFnで作るのは不向きということでCLIで作成してた。CFnだと勝手に変な名前付けられるから、って理由だったかな。しかしハッキリとは思い出せない。\nもやもや感が払拭しきれないが、とりあえず過去のメモ書きをのせておく。\nここから。\nオートスケーリンググループのCloudWatchアラーム作成時のポイントは、先にSNSトピック、ポリシーを作成する。ポリシー作成のCLIを実行するとARNが出力されるので、その値を定義してアラームを作成する。SNSトピック自体はCFnで作成していた。サブスクリプション作成はコンソールからやったような。グダグダな記憶だが、メールアドレスをサブスクライブする時に手動での承認が発生するのは確か。（設定したメールアドレスに届いたメール内のリンクを押下すると承認が完了する）\nサブスクリプション承認は手動になるが、アラーム作成時に指定するのはトピックARN。承認しないと後続作業ができないわけではない、と思われる。（ただし承認対応は3日以内に実施すること）\n以下、ec2オートスケーリングのスケールアウト/インポリシー作成CLIの例。ec2のオートスケールってパターンもすでにオールドファッション化しているけど\u0026hellip;、数年前の事例なので。\nスケールアウトポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scaleout-policy \\ --scaling-adjustment 2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 300 \\ --region ap-northeast-1 スケールインポリシー\n$ aws autoscaling put-scaling-policy \\ --auto-scaling-group-name test-web-asg \\ --policy-name test-web-scalein-policy \\ --scaling-adjustment -2 \\ --adjustment-type ChangeInCapacity \\ --cooldown 600 \\ --region ap-northeast-1 この後、以下のCLIを実行。スケールアウトアラーム作成CLI例。--alarm-actions オプションで 先に作成しておいた$snstopic, $scaleoutpolicy の値を指定している。\nsnstopic=\u0026#34;arn:aws:sns:ap-northeast-1:[AWSアカウントID]:test-alert-mail\u0026#34; scaleoutpolicy=\u0026#34;arn:aws:autoscaling:ap-northeast-1:[AWSアカウントID]:scalingPolicy:[ランダム値]:autoScalingGroupName/test-web-asg:policyName/test-web-scaleout-policy\u0026#34; $ aws cloudwatch put-metric-alarm \\ --alarm-name \u0026#34;test-web-scaleout-alarm\u0026#34; \\ --alarm-description \u0026#34;Alarm when CPU exceeds 70%\u0026#34; \\ --metric-name CPUUtilization \\ --namespace AWS/EC2 \\ --statistic Average \\ --period 60 \\ --threshold 70 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=AutoScalingGroupName,Value=\u0026#34;test-web-asg\u0026#34; \\ --evaluation-periods 4 \\ --alarm-actions $scaleoutpolicy $snstopic \\ --unit Percent \\ --region ap-northeast-1 スケールイン時のアラームも同様に作成する。","title":"CloudWatchアラーム作成時のメモ（過去事例）"},{"content":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\nしかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\nで、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/sns-influence/","summary":"SNSって誰をフォローするかも大きいけど誰にフォローされるか、も相当影響でかいんだなと思う。\nもともとSNS嫌いだからほとんどやってないけど、Tumblrは例外で、ここしばらく依存症に近いくらい使っている。全然使っていなかった時期もあるんだけどね。今は諸事情によりヘビーユーザー。\n当初はフォロワー僅か、だったが逆に好き勝手なことが書けた。Tumblrってテキスト投稿には向いてないと思うけど、それすら気にせずに画像だろうが音声だろうがテキストだろうが、好きなように投稿する。それがTumblrの良さ。\n当初投稿するのは自分の写真が中心で、たまにテキストあり、リブログはあまりしていなかった。特にフォローしたいアカウントもなかったけどたまに癒し系とか懐かし系画像投稿したいから適当に複数アカウントフォローしてた。でも、楽しくはなかったんだよね。「たまにこっち系の画像ポストするのはいいけどそれメインでやりたいわけじゃないし、なんか違う気がするなぁ」と違和感を覚え始めて、フォロー解除した。\nしかしその後、何がきっかけか覚えていないのだが、あるアカウントとその周辺アカウントをフォロー開始してから、めっちゃ楽しくなってしまった。それらのアカウントは毎日投稿しているけど、リブログせずにいられないような、何かしらカッコイイポストが必ずある。経由されたポストやソースをポストしたアカウントを追うとこれまたセンスが良くて、芋づる式に夢中でlike,reblogしてしまうのである。\nTumblrのすごいところは、オリジナルのポスト作成者じゃなくても、センスのいいポストで構成されたブログが甚大な価値を持つことだ。「あなたのセンスは素晴らしい、本当に尊敬する！」と叫びたくなるようなアカウントが複数存在する。まだ出会えていないブログもあるかもしれない。実際最近になっても、「こんなセンスいいブログがあったんだ！」と新たに発見することがある。（もちろんそんなときに直接メッセージを送ったりはしない。1%程度の例外はあるだろうが、Tumblrでは誰もそんなこと望んでいないのだから）\nいいポストを集めたブログは自然にいいブログになる。オリジナルの作者かどうか、の区別はもはや意味をなさなくなる。いいものを発見してコレクションする、そのエネルギーが、見る人にインスピレーションや刺激を与えるのだ。それがTumblrの良さ。（二度目）\nこのことに気づいてから、俺は夢中になってしまった。Tumblr自体はずっと前からやっているのに、こんなに楽しいと感じたのは初めてといってもいい。\n以上は「誰をフォローするか」による影響の話。ここから先、「誰にフォローされるか」について書いてみる。\n少し前のある日、これまで細々とした件数だった、零細アカウントの俺の通知が飛躍的に伸びた。たまに特定のポストのリアクションが増加することはあったが、その日は過去にない規模の反響だった。「何かあったか？」と追ってみると、ある人気アカウントが自分のポストを複数リブログしてた。そこから雪だるま式にリアクションが増えたわけである。これにより、自分のブログのフォロワーも増加した。増加といってもその日に十人くらい、その後日に数人ずつ程度のペースだが。ちなみに先の人気アカウントにもフォローされていた。\nしかし、正直あまりうれしくないし、逆に困る。「ある誰かが自分の投稿を見ている」ことを意識していると、書きにくいことが出てくるのである。画像のポストだけでみても、フォロワーにインフルエンサーとそのフォロワーがいると「何を投稿するか」について、これまで以上に他人を意識せざるを得なくなってしまうのである。それまでは「とにかく自分がポストしたいものをポストする」スタンスだったのに、他人にサービスするようなポストを挟んでしまうとか。実際その日以降、しばらくそんな状況が続いた。引き摺られてはいけない、と自覚しつつも、どこかで引き摺られてしまうのだ。\nで、この状況はストレスなのである。つまり楽しくないのである。楽しくないTumblrなんかやりなくない。自分が楽しむためにやっているんだから、プライオリティの優位をそっちに戻す必要がある。\u0026hellip;と、そのことを明確に言語化するためのこの投稿を書いた。\n実はこの件と前後して、先の方に書いたセンス抜群のアカウントからフォローしてもらった。これは嬉しかったね。俺のポストはそんなにリブログしてもらってないけど、たまにリブログしてもらうとやはり反響がすごい。まぁこの反響ってのも良し悪しだけどね、まったく反応がないと寂しいけどデカすぎても疲れる、さっき書いたように、よくない影響受けることがあるからね。まぁこれって、リアルライフで人混みに出ると疲れるのと同じことだと思う。\nで、最終的に言いたいことは。\nリアルライフでもSNSでも、「自分の周囲に誰がいるか」の影響は非常に大きいのだ、と。\n人間は誰でもエネルギーを持っている。エネルギーは、良くも悪くも他者に影響を与える。ある人間が、良いエネルギーを放出している集団の中にいればおのずとよい影響を受ける。逆もまた然りである。リアルライフだとそのことを如実に実感するが、ネット上でもそれは同様だ。実際物事はそう単純ではないから、他者からの影響の方向や質はモザイクのように絡み合っているイメージではあるが\u0026hellip;\nTwitterとかFacebookみたいにガチで言葉の応酬をするようなSNSは当然その傾向が強いと思うが、Tumblrのように非常に関係性が薄いSNSでもそういうことがあるんだな、と今更ながら実感した次第。\n結論としては、Tumblrではいくつかのアカウントを本当にリスペクトしているけれど、自分の軸をずらさずにかつ一定の距離を保つ姿勢を貫くのが、長く楽しむコツだね。","title":"Tumblrについて、ひとり言"},{"content":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] } S3用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[アカウントAのS3バケット名]\u0026#34; ] } ] } 2-④ クロスアカウントデプロイ用IAMロール\nサービスをCodeDeployとしてロールを作成する。この時アカウントAにassumeする前提で以下設定を行う。以下図の矢印箇所にアカウントAのIDを入力して次へ進む。これ以降は通常のロール作成時と同じ。\nデプロイ用ロール信頼ポリシーのJSONは以下のようになる。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Condition\u0026#34;: {} }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;codedeploy.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } デプロイ用メインのカスタムポリシー。CodeDeployのパーミッションを定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } デプロイ用インラインポリシー。S3とCodeCommitのパーミッション定義。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject*\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:PutObjectAcl\u0026#34;, \u0026#34;codecommit:ListBranches\u0026#34;, \u0026#34;codecommit:ListRepositories\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; ] } ] } これとは別にec2周りのポリシーも割り当てる。検証時は取り急ぎマネージドのAmazonEC2ReadOnlyAccessでもアタッチしておけばいい。\nこれでやっとアイテムが出揃った。ここまで来たら、前回投稿の分も重複するがアカウントAの環境にて以下実行。（2. までは前回までの段階で完了しているとして、3.以降を実施）\nコンソールで単体アカウント用にパイプラインを作成 そのJSON定義を取得してクロスアカウント向けに編集 パイプラインをアップデート $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json アップデートしたパイプラインをスタート $ aws codepipeline start-pipeline-execution --name [パイプライン名] 特にエラーが出なければパイプラインは走っているが、その先でコケることはよくあるのでコンソール画面から状況を確認する。アカウントAのマネジメントコンソール画面から全体の状況は把握できる。デプロイステージの詳細はアカウントBのコンソールからしか見れない。\nというわけで、果てしなく続くと思われた長い旅路がようやく終わりましたよ。しかしいいかげんに普通の旅にも出たいもんだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-2/","summary":"前回投稿でAWS CodePipelineのクロスアカウント設定（前半）ではリソース配布元のアカウントAの内容中心に書いた。後半は配布先となるアカウントBの設定内容を書いていく。\n前回投稿\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）\n繰り返しになるけれども、前提条件をおさらいとして記載。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。 主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n主な構成要素 これも前回書いているが、こっちにも書いておかないとわけわからなくなるので再掲。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\n2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n上記アイテムを作成済みとして、作業概要は前回記事に記載した。以降、アカウントB側で用意するアイテムの内容を書く。\n2-① CodeDeploy定義\nアカウントBのコンソールにて、アプリケーションとデプロイメントグループを作成する。詳細は割愛。\n2-② ec2用のIAMロール\nKMSとS3用のインラインポリシーを作成する。AWS参考ページでは2つに分けていたが統合しても問題ないと思う。\nKMS用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:DescribeKey\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:Decrypt\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[Key ID]\u0026#34; #KMSのARN ] } ] } S3用インラインポリシー","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）"},{"content":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n制約事項\nクロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG） 主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名] アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。\nクロスアカウントパイプラインの処理中の見え方\nアカウントAのマネジメントコンソール：パイプライン全体の処理状況は見える。デプロイステージの詳細は見れない。\nアカウントBのコンソール : デプロイの詳細が見れる\n各種アイテムのサンプル AWS公式でも基本内容は網羅されているが自分用メモとしてここにも載せておく。\nアカウントA側アイテム\n1-② KMSキーポリシー\nアーティファクト用S3バケットの暗号化キーポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;[key-policy-name]\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Enable IAM User Permissions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;kms:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow access for Key Administrators\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;[KMSの暗号化キーの管理ユーザのARN]\u0026#34; #アカウントA側のキーのオーナーを指定 }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Create*\u0026#34;, \u0026#34;kms:Describe*\u0026#34;, \u0026#34;kms:Enable*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;kms:Put*\u0026#34;, \u0026#34;kms:Update*\u0026#34;, \u0026#34;kms:Revoke*\u0026#34;, \u0026#34;kms:Disable*\u0026#34;, \u0026#34;kms:Get*\u0026#34;, \u0026#34;kms:Delete*\u0026#34;, \u0026#34;kms:TagResource\u0026#34;, \u0026#34;kms:UntagResource\u0026#34;, \u0026#34;kms:ScheduleKeyDeletion\u0026#34;, \u0026#34;kms:CancelKeyDeletion\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow use of the key\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:Encrypt\u0026#34;, \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;kms:ReEncrypt*\u0026#34;, \u0026#34;kms:GenerateDataKey*\u0026#34;, \u0026#34;kms:DescribeKey\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;Allow attachment of persistent resources\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: [ \u0026#34;[アカウントAのパイプライン用サービスロールのARN]\u0026#34;, #(注1) \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; ] }, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:CreateGrant\u0026#34;, \u0026#34;kms:ListGrants\u0026#34;, \u0026#34;kms:RevokeGrant\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;kms:GrantIsForAWSResource\u0026#34;: \u0026#34;true\u0026#34; } } } ] } (注1) 構文\narn:aws:iam::[アカウントAのID]:role/[パイプラインロール名]\n1-③ S3バケットポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;SSEAndSSLPolicy\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;DenyUnEncryptedObjectUploads\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquals\u0026#34;: { \u0026#34;s3:x-amz-server-side-encryption\u0026#34;: \u0026#34;aws:kms\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;DenyInsecureConnections\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;Bool\u0026#34;: { \u0026#34;aws:SecureTransport\u0026#34;: false } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:Get*\u0026#34;, \u0026#34;s3:Put*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]/*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::[アカウントBのID]:root\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::[S3バケット名]\u0026#34; } ] } 1-④ CodePipelineが使用するサービスロール(IAM)\nこのロールには以下のポリシーを割り当てる。1.はロール作成前に作成可能。コンソールからロール作成する時に選択可能なサービスにCodePipelineがないので一旦CodeDeployで作成して、後から信頼ポリシー編集した。\n通常のCodePipeline作業用ポリシー アカウントBのassume用インラインポリシー 信頼ポリシー（編集） 以下CodePipeline作業用ポリシー。AWSが自動で付与するポリシーは他のパーミッションも多く含まれているがそこから削って最小限にしたのがこれ。autoscalingは使わないんだけど一応残す。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEqualsIfExists\u0026#34;: { \u0026#34;iam:PassedToService\u0026#34;: [ \u0026#34;ec2.amazonaws.com\u0026#34; ] } } }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codecommit:CancelUploadArchive\u0026#34;, \u0026#34;codecommit:GetBranch\u0026#34;, \u0026#34;codecommit:GetCommit\u0026#34;, \u0026#34;codecommit:GetUploadArchiveStatus\u0026#34;, \u0026#34;codecommit:UploadArchive\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;codedeploy:CreateDeployment\u0026#34;, \u0026#34;codedeploy:GetApplication\u0026#34;, \u0026#34;codedeploy:GetApplicationRevision\u0026#34;, \u0026#34;codedeploy:GetDeployment\u0026#34;, \u0026#34;codedeploy:GetDeploymentConfig\u0026#34;, \u0026#34;codedeploy:RegisterApplicationRevision\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; }, { \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;tag:*\u0026#34;, \u0026#34;logs:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } アカウントBのassume用インラインポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::[アカウントBのID]:role/*\u0026#34; ] } } 信頼ポリシー\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: [ \u0026#34;codepipeline.amazonaws.com\u0026#34;, \u0026#34;codedeploy.amazonaws.com\u0026#34;, \u0026#34;ec2.amazonaws.com\u0026#34; ] }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } 1-⑤ CodePiplelineのJSON定義\n冒頭のAWS公式ページにもポイントは記載されているが、今回のケースでまとめたのがこれ。繰り返しになるが、「1.コンソールで単体アカウント用にパイプラインを作成 2. そのJSON定義を取得してクロスアカウント向けに編集 3. パイプラインをアップデート」という流れになる。最初にパイプラインを作成するときにCodeDeploy用定義が必要なため、事前にアカウントA内で適当なCodeDeployアプリケーション/デプロイメントグループのペアを用意しておく。\n以下のJSON後半でアカウントB側のアイテム定義名をいくつか記載しており、当然アカウントB側に実体が存在する前提だが、編集時点では存在していなくても構わない。\n{ \u0026#34;pipeline\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;A_crossdeploy_pipeline\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, \u0026#34;artifactStore\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;S3\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;[S3バケット名]\u0026#34; \u0026#34;encryptionKey\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;arn:aws:kms:us-east-1:[アカウントAのID]:key/[キーのID]\u0026#34;, #KMSキーのARN \u0026#34;type\u0026#34;: \u0026#34;KMS\u0026#34; }, \u0026#34;stages\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Source\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeCommit\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;BranchName\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;OutputArtifactFormat\u0026#34;: \u0026#34;CODE_ZIP\u0026#34;, \u0026#34;PollForSourceChanges\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;RepositoryName\u0026#34;: \u0026#34;[ソースリポジトリ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントAのID]:role/[クロスアカウントパイプライン用IAMロール名]\u0026#34;, #冒頭で指定したIAMと同じ \u0026#34;inputArtifacts\u0026#34;: [], \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;SourceVariables\u0026#34; } ] }, { \u0026#34;name\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;actions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;ExternalDeploy\u0026#34;, #Deploy --＞ ExternalDeployに変更 \u0026#34;actionTypeId\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Deploy\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;AWS\u0026#34;, \u0026#34;provider\u0026#34;: \u0026#34;CodeDeploy\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;runOrder\u0026#34;: 1, \u0026#34;configuration\u0026#34;: { \u0026#34;ApplicationName\u0026#34;: \u0026#34;[アカウントBのコードデプロイアプリケーション名]\u0026#34;, \u0026#34;DeploymentGroupName\u0026#34;: \u0026#34;[アカウントBのコードデプロイデプロイメントグループ名]\u0026#34; }, \u0026#34;outputArtifacts\u0026#34;: [], \u0026#34;inputArtifacts\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;SourceArtifact\u0026#34; } ], \u0026#34;roleArn\u0026#34; : \u0026#34;arn:aws:iam::[アカウントBのID]:role/[アカウントBのクロスデプロイ用IAMロール名]\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;DeployVariables\u0026#34; } ] } ], \u0026#34;version\u0026#34;: 1 } } やっとここまできた\u0026hellip;長かった。しかしまだ道は続く。次回、アカウントB側の設定内容を書く。\n続き\nAWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-2）\n","permalink":"https://ecnedaced-seirots.github.io/post/a/aws-crossaccount-pipeline-1/","summary":"前回投稿ではパイプラインなしでAWS クロスアカウントデプロイをやった。次はパイプラインを使ってやってみる。長くなるので前半/後半に分ける。\nやりたいこと\nAWSの異なるアカウント間で、CodePipelineによりCodeDeployからec2インスタンスにリソースをデプロイする。ソースはリソース配布側のCodeCommit。この記事では配布元を開発環境/アカウントA、配布先を検証環境/アカウントBとして話を進める。（ec2はオートスケールもなくただ単に配布するだけなので単一アカウントだったら簡単な話なんだが、アカウント跨ぐとなるとめっちゃ面倒くさい\u0026hellip;）\n主な参考ページ\n他のリソースを使用するパイプラインを CodePipeline で作成するAWSアカウント\n基本的にこのページの通りにやればOK。アカウントA側で一度単一アカウント用の適当なパイプラインを作成して、そのJSON定義を取得。それをクロスアカウント用に編集してCLIからアップデートする。ちなみに上記リンクは日本語版だが機械翻訳の文章がまともな日本語ではなくイラッとくるので、ほぼオリジナルの英語版を参考にした。\n参考までに、以下クラメソさんの記事。当初これのBuildをDeployに置き換えてやってみたが失敗した。不足か誤りがあるんだろうがいきなりやったこともありわけがわからなすぎて頓挫。先述のAWS公式の方がやりたいことに近かったため仕切り直しした。\nクロスアカウントCodeBuild + パイプライン例\nCodePipelineでアカウントをまたいだパイプラインを作成してみる\n制約事項\nクロスアカウントのパイプラインはマネジメントコンソールから作成不可のため、aws cliから作成/更新する CodeDeployの定義とデプロイ先のec2は同一アカウントであること クロスアカウントでパイプラインを組む場合、アーティファクト格納用S3バケットの暗号化キーはKMSを使用する（AWS デフォルトの暗号化キーはNG） 主な構成要素 2アカウント間で各種アイテムを用意することになり、混乱しがちなのでまとめておく。前回投稿では配布先となるアカウントB側にS3バケットがある構成だったが、今回は逆。ただし構成的にはこちらの方が自然かと思う。\n1-資材配布元（アカウントA）\n① CodeCommitリポジトリ（ec2にローカルリポジトリを作成〜資材格納）\n② KMSキー (両方のアカウントにアクセス許可する)\n③ S3バケット (アカウントBにアクセス許可するバケットポリシーを付与）\n④ CodePipelineが使用するサービスロール\n⑤ CodePipleline定義（コンソールで作成したパイプライン定義JSONをCLIから更新）\nJSON取得コマンド\n$ aws codepipeline get-pipeline --name [パイプライン名] \u0026gt; [パイプライン名].json 2-資材配布先（アカウントB）\n① CodeDeploy定義（アプリケーション/デプロイメントグループ）\n② ec2用のIAMロール（CodeDeployがアカウントAのKMSキー、S3にアクセスするためのポリシーを付与）\n③ ②のIAMロールをアタッチしたデプロイ先ec2\n④ クロスアカウント用サービスロール（CodeDeployとS3操作にassumeする）\n作業概要 上記各リソースを作成済として、以下の作業を行う。\nアカウントAの作業用端末またはec2にログイン。1-⑤のパイプライン定義JSONを適当なパスに配置し、パイプラインをアップデートする\n$ cd /path/to/json $ aws codepipeline update-pipeline --cli-input-json file://[パイプライン名].json アップデートしたパイプラインを実行する\n$ aws codepipeline start-pipeline-execution --name [パイプライン名] アカウントBでは特に作業なし。デプロイステータスが成功になったら、ec2に資材がデプロイされていることを確認する。","title":"AWS CodeDeployでクロスアカウントデプロイ実行（パイプラインあり-1）"},{"content":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n作業内容 配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n配布先②アカウントにて、①がassumeするためのロールAを作成する。\nロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\nインラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } } (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] } ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。 ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。 この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。\n$ aws sts assume-role --role-arn \u0026#34;②配布先のアカウントID:role/ロールA\u0026#34; --role-session-name \u0026#34;deployment-test\u0026#34; すると以下の形式の認証情報が出力される。\n{ \u0026#34;Credentials\u0026#34;: { \u0026#34;AccessKeyId\u0026#34;: \u0026#34;[access key id]\u0026#34; \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;[secret access key id]\u0026#34;, \u0026#34;SessionToken\u0026#34;: \u0026#34;[token id]\u0026#34;, \u0026#34;Expiration\u0026#34;: \u0026#34;2021-09-20T15:08:00Z\u0026#34; } } 上記を環境変数にセットする。Windowsの場合はexportをsetに変更する。\n$ export AWS_ACCESS_KEY_ID=[access key id] $ export AWS_SECRET_ACCESS_KEY=[secret access key id] $ export AWS_SESSION_TOKEN=[token id] これでセッション保持期間の間（expireの時刻)は②アカウントのロールAの権限で作業が可能となる。セッション時間はデフォルトで1時間だが、伸ばしたい場合は--duration-secondsオプションを使う。（2時間なら7200、3時間なら10800と指定。ロールAの最大セッション期間がそれに応じた時間に設定されている前提）\nデプロイ実行 最初にやる時はデプロイ前にaws s3 cpを実行して、対象S3バケットへ読み書き可能かチェックしておくとよい。\nCLIでpush [オプション]を実行し、S3に資材を格納する。この時 3.で作成したアプリケーション名を指定する。（これによりただ単にS3に資材を配置するのではなく、資材をアプリケーションのリビジョンと関連付けることになる）sourceはここではCodeCommitのローカルリポジトリパスを指定しているが、指定するのはappspec.ymlを配置したディレクトリとなる。\n$ aws deploy push ¥ --application-name [aplication-name] ¥ --s3-location s3://[staging-app]/[staging-app-key] ¥ --ignore-hidden-files ¥ --source /path/to/source pushが成功すると資材がzip形式で格納される。ターミナル上ではE-Tagを含む実行コマンド情報が標準出力される。詳細は割愛するがこれを元にcreate-deploymentにてデプロイを実行する。この時 3.で作成したデプロイメントグループを指定する。成功すれば②配布先となるec2にS3から資材が配置される。ちなみにpushはコンソールから実行できないが、デプロイは可能である。しかしそのために実行画面を切り替えるのも面倒なので（コンソールでもassumeする）、ここは引き続きCLIでやる方が自然かと。\n(注1) 配布元①アカウントにバケットを作成してもよいが、また追加の設定が必要となる。今回は配布先②に作成した。\nその他ポイント 最初deployのコマンドは通ったがその先で失敗した。この時コンソール上では以下のエラーが表示されていた。\nThe overall deployment failed because too many individual instances failed deployment, too few healthy instances are available for deployment, or some instances in your deployment group are experiencing problems.\nこれだけではわからないのでログを確認してみたところ、こんなエラーが繰り返し吐かれていた。\n/var/log/aws/codedeploy-agent/codedeploy-agent.log\nInstanceAgent::Plugins::CodeDeployPlugin::CommandPoller: Missing credentials - please check if this instance was started with an IAM instance profile\n確かに配布先ec2にはIAMロールをアタッチしていなかったため、インスタンスプロファイルが存在しない。するとcodedepoloyエージェントが上記のログを吐くわけだ。配布先のec2にインスタンスプロファイルを割り当てるため、別途IAMロールを作成してIAMロールをアタッチしたところ成功した。\nIAMをアタッチしても同じエラーが出る場合、エージェントを再起動してみる。候補が表示されなかったりエラーになったりしてIAMのアタッチ自体が不可能な場合は、インスタンスを一旦停止して再試行してみる。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/cross-account-codedeploy/","summary":"AWS環境で、クロスアカウントでCI/CDしたい。とりあえずBuildフェーズはいらなくてDeployだけでいい。Deployの実行はパイプラインあり/なし両方可能。どちらも単一アカウント内なら複雑な設定もなく比較的容易にできることはわかっているが、クロスアカウントとなると何かと面倒だ。でもやってみる。ここではまずはパイプラインなしとする。\n参考\n異なる AWS アカウントでアプリケーションをデプロイする\n（上記ページにリンクあり。assumeロールの設定は以下参考）\nIAM チュートリアル: AWS アカウント間の IAM ロールを使用したアクセスの委任\n環境前提 配布元となるAWS開発環境(Dev)にCodeCommitのローカルリポジトリがあり、そこから別アカウントの検証環境(Stg)にデプロイする。その先には本番環境がある想定だが構成は同じになるはず。\n① 配布元(Dev)\n② 配布先(Stg)\n概要 ①配布元のアカウントから②配布先のec2にデプロイ可能とするため、②配布先アカウント側で①アカウントのassumeを可能とするIAMロールを作成する。（ロールAとする）① 配布元アカウント側でロールAにassumeし、デプロイを実行する。\n基本的に必要となるのはIAM周りの設定であり、ネットワーク系の特別な実装は必要ない。\n作業内容 配布先②アカウントにて、配置用のS3バケットを作成する。IAMロールのポリシーでバケットへのアクセス権限を定義するため、バケットポリシーは設定しなくても問題なし。(注1)\n配布先②アカウントにて、①がassumeするためのロールAを作成する。\nロールAで定義する内容 (1) 信頼ポリシーで②のアカウントIDを指定してassumeを許可する。このときrootか②側のIAMロールどちらかを指定する。\nrootに設定した場合は、①アカウントでデプロイを実行するユーザのグループにassume可能とするインラインポリシーを適用する。\nIAMに設定した場合は、①アカウントでデプロイを実行するec2にこのIAMロールを適用する。実行環境がec2の場合はこれでよいが、クライアント端末の場合はrootにする。\nインラインポリシー例 (①アカウントで設定) デプロイ実行ユーザが所属するグループの画面を開き、[アクセス許可] タブ \u0026ndash;\u0026gt; [アクセス許可の追加] \u0026ndash;\u0026gt; [インラインポリシーの作成] [JSON] タブ選択\n以下の内容を設定する。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:iam::②配布先のアカウントID:role/ロールA\u0026#34; } } (2) ①のアカウントが資材配置用のS3にアクセスするための権限を定義したポリシーを適用する。ちゃんと書いてないけど以下にcodedeploy, ec2の操作権限も追加する。codedeployの権限は何が必要かわからないのでとりあえず全許可にしておいた。ECSへのデプロイだとec2のterminate権限が必要みたいだが、今回の場合ec2は参照のみでOKだと思う。\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app\u0026#34; #検証環境の資材格納バケット名 }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::staging-app/*\u0026#34; } ] } ②配布先アカウントにて、deployのアプリケーションとデプロイメントグループを作成する。詳細は割愛。 ①配布元アカウントのec2（または同アカウントのcredentialsをセットした端末）にログインし、ロールAにスイッチする。ちなみにマネジメントコンソールでもスイッチして作業可能だが、deployのpushコマンドがCLIでしかできないため、ここではCLI前提で話を進める。 この時先で作成したロールAにスイッチするため、以下のコマンドを実行する。","title":"AWS CodeDeployでクロスアカウントデプロイの実行（パイプラインなし）"},{"content":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。 Mac command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先） 手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/browser-capture-all/","summary":"かつてブラウザで全画面キャプチャしたい時はChromeにアドオンを入れて使っていたがこのアドオンはキャプチャしたデータをどこかに送信しているという話をどこかで読んで、ちょっとなぁ、と思った。しかし最近になってChromeでもFirefoxでもアドオンなしで全画面キャプチャが可能になっていることを知った。自宅で見るブラウザはほぼFirefoxでChromeは滅多に使わないが、職場では事情が変わったりするので両方書いておく。\nFirefoxの場合 F12キーで開発ツール画面を表示する。ツール画面右上のカメラアイコンをクリック。これだけ。素晴らしい。画像はデフォルトでDwonloadディレクトリに保存される。\n\u0026hellip;が、画面左側に小さな字でさりげなく「画像が大きすぎたため、xxxxxのサイズに切り抜きました」と言われている。画面が長すぎると途中で切られてしまうわけだ。結果的には以下のようになった。矢印の箇所は実際にここで画面が切れている。自分の投稿記事でやってみたんだけどまぁ実際この記事は長すぎるね。\nChromeの場合 Chromeでやる場合は一手間増える。\nWindows Ctrl + Shift + I 同時押しで開発ツール画面を表示 Ctrl + Shift + P 同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。 Mac command + option + I 同時押しで開発ツール画面を表示 command + Shift + P同時押しで入力欄を表示させる 「full」と入力してreturn。少し待つとDwonloadディレクトリに保存される。\n（デフォルト保存先） 手間といっても大したことじゃないが、なにせものぐさなんで。それでもアドオンなしで全画面キャプチャ可能になったのはありがたい。\nしかしここでもやはり画面が長すぎておかしなことになっている。途中で一回途切れて（矢印箇所）、再度記事の初めから出力されるというループに陥っている。ま、とにかくFirefoxでもChromeでも長すぎるとダメつうことだ。","title":"Firefox/Chromeでアドオンなし全画面キャプチャ"},{"content":" 私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\nフルスクリーン解除 control+ command + F\nアプリケーションの強制終了 command + option + esc\nスクリーンショット command + shift + 3\nそれにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。\n3選といいつつ、思い出したらまた書くかもな\u0026hellip;\n","permalink":"https://ecnedaced-seirots.github.io/post/a/mac-shortcut/","summary":"私的にMacで必須のショートカットを3つ挙げるとしたらこんなところかな。\nフルスクリーン解除 control+ command + F\nアプリケーションの強制終了 command + option + esc\nスクリーンショット command + shift + 3\nそれにしてもフルスクリーンて、あれ何のためにあるん？意図的にフルスクリーンにすることなくて変な風にキーボード触ってしまった時になっちまうんだけど、迷惑極まりない\u0026hellip;\n追記\nもうひとつ迷惑なショートカット思い出したから追加。ターミナル画面が分割されるやつ。command + D同時押しでなってしまうらしい。絶対使わんのに。戻すには、command + Shift + D。\n3選といいつつ、思い出したらまた書くかもな\u0026hellip;","title":"Macで必須のショートカット3選"},{"content":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n「カラー」タブ 半角空白 「色分け/表示」にチェック ","permalink":"https://ecnedaced-seirots.github.io/post/a/sakura/","summary":"サクラエディタで半角スペースを可視化したい。環境が変わって入れ直した時とか都度やり直す羽目になるからメモ。\nメニューから[設定] 〜 [タイプ別設定] を選択。\n「カラー」タブ 半角空白 「色分け/表示」にチェック ","title":"サクラエディタで半角スペースを可視化"},{"content":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/inokashira-park/","summary":"小ネタでもいいからどんどんポストしたいと思っているけどそれもなかなかできないもんだな。写真だけ。2018年4月の東京・井の頭公園。","title":"井の頭公園 - 2018年4月"},{"content":"AWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。\nしかし、元々組み込みLinux用に開発されて軽量リソースで動作するFluent Bitの方がコンテナログ送信に向いていると思う。ということで、この記事ではFluent Bitに焦点を当てる。\n参照\nFluent Bit ドキュメント（設定詳細は画面左「DATA PIPELINE」配下のメニュー参照）\nFluent Bit Documentation\nContainer Insights全般\nAmazon EKS と Kubernetes での Container Insights のセットアップ\nFluent Bit on Container Insights\nCloudWatch Logs へログを送信する DaemonSet として Fluent Bit を設定する\nサンプルマニフェスト\nfluent-bit-compatible.yaml\n※AWSがサンプルとして提供しているFluent BitのマニフェストはFluent Bit最適化用とFluentd互換用がある。今回は過去にFluentd使用事例があることから、Fluentd互換用マニフェストをDLしてカスタマイズした。\n共通マニフェスト例 クラスタの全般的な設定と、アプリ個別のケースでマニフェストを二つに分けた。AWS公式では基本となるEKSクラスタの定義をコマンドでセットしているが、運用の際はマニフェストに落とし込むのが普通だと思う。以下のようなマニフェストを共通用として作成し、個別のマニフェストから参照させる。EKSクラスタ名はdata:cluster.nameで指定している。\nfluentbit-cluster.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluentbit-cluster namespace: amazon-cloudwatch selfLink: /api/v1/namespaces/amazone-cloudwatch/configmaps/fluentbit-cluster data: cluster.name: EKS-SAMPLE-CLUSTER log.region: ap-northeast-1 read.head: \u0026#34;On\u0026#34; read.tail: \u0026#34;Off\u0026#34; --- apiVersion: v1 kind: ServiceAccount metadata: name: fluent-bit namespace: amazon-cloudwatch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: fluent-bit-role rules: - nonResourceURLs: - /metrics verbs: - get - apiGroups: [\u0026#34;\u0026#34;] resources: - namespaces - pods - pods/logs verbs: [\u0026#34;get\u0026#34;, \u0026#34;list\u0026#34;, \u0026#34;watch\u0026#34;] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: fluent-bit-role-binding roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: fluent-bit-role subjects: - kind: ServiceAccount name: fluent-bit namespace: amazon-cloudwatch 個別マニフェスト例 「個別のマニフェスト」というのはアプリの種類が複数存在して、各種別ごとに送信先（ロググループ/ログストリーム）を振り分けたいケースを想定している。しかしAWS公式サンプルをそのまま使うと要件的に期待値にならない。現状ネットにわかりやすい事例がなく大分迷ったが、最終的に以下のような形に落とした。詳細は後述。\n最初に骨組みを説明すると、前半がFluent Bitの設定であるConfigMap、後半がワーカーノード上で起動するDaemonSetの定義となっている。冒頭の[SERVICE]で全体共通の設定を行う。@INCLUDEで3種類のConfig名を指定しているが名称は適当でよい。各Config内に[INPUT] [FILTER] [OUTPUT] を定義していく。\nconfの種類 containers.conf\nfluentbit, cloudwatch-agentやアプリ個別ログを定義。簡素化のため対象を絞っているが、aws-node, kube-proxy, corednsのログを送信する場合もここに含める。\nkube-systemd.conf\ndocker,kubeletのログを定義。\nhost.conf\nOS上のログ（基本的に/var/log/配下の各種ログ）を定義。簡素化のためここではmessagesのみ定義している。他に送信したい種別は同様に設定する。\nparsers.conf\nログフォーマットのパースの定義\nfluentbit-sample-app.yaml\napiVersion: v1 kind: ConfigMap metadata: name: fluent-bit-config namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample data: fluent-bit.conf: | [SERVICE] Flush 5 Log_Level info Daemon off Parsers_File parsers.conf storage.path /var/fluent-bit/state/flb-storage/ storage.sync normal storage.checksum off storage.backlog.mem_limit 5M @INCLUDE containers.conf @INCLUDE kube-systemd.conf @INCLUDE host.conf # containers.confの定義 containers.conf: | [INPUT] Name tail Tag fluentbit.* Path /var/log/containers/fluentbit* Parser docker DB /var/fluent-bit/state/flb_log.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag cloudwatch-agent.* Path /var/log/containers/cloudwatch-agent* Docker_Mode On Docker_Mode_Flush 5 Docker_Mode_Parser cwagent_firstline Parser docker DB /var/fluent-bit/state/flb_cwagent.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} [INPUT] Name tail Tag sample-app.* Path /var/log/containers/sample-app* Parser docker DB /var/fluent-bit/state/flb_sample-app.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # 各INPUTに対応するFILTERを定義する [FILTER] Name kubernetes Match fluentbit.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix fluentbit.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match cloudwatch-agent.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix cloudwatch-agent.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off [FILTER] Name kubernetes Match sample-app.* Kube_URL ${MASTER_URL} Kube_Tag_Prefix sample-app.var.log.containers. Merge_Log On Merge_Log_Key log_processed K8S-Logging.Parser On K8S-Logging.Exclude Off Annotations Off # アイテムの変換や不要なメタデータ送信抑止を定義 [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Nested. [FILTER] Name modify Match * Rename Nested.docker_id Docker.container_id [FILTER] Name nest Match * Operation nest Wildcard Nested.* Nested_under kubernetes Remove_prefix Nested. [FILTER] Name nest Match * Operation nest Wildcard Docker.* Nested_under docker Remove_prefix Docker. [FILTER] Name nest Match * Operation lift Nested_under kubernetes Add_prefix Kube. [FILTER] Name modify Match * Remove Kube.container_hash Remove Kube.container_image Remove Kube.pod_id [FILTER] Name nest Match * Operation nest Wildcard Kube.* Nested_under Kubernetes Remove_prefix Kube. # 送信時の定義 # ロググループ名例：/eks/stg/sample-app_fluentbit # ログストリーム名例：ip-10-1-2-3.ap-northeast-1.compute.internal_[Pod名]_[ネームスペース]_[コンテナ名] # $(tag[4])とした場合、上記のようなkubeのタグ定義が投入され、ユニークなログストリーム名になる。 [OUTPUT] Name cloudwatch Match fluentbit.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_fluentbit log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 [OUTPUT] Name cloudwatch Match cloudwatch-agent.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_cwagent log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # 個別アプリログ送信用定義 [OUTPUT] Name cloudwatch Match sample-app.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_application log_stream_name ${HOST_NODE_NAME}_$(tag[4]) auto_create_group true extra_user_agent container-insights Retry_Limit 5 # docker,kubenetesログ定義 kube-systemd.conf: | [INPUT] Name systemd Tag dockerlog.systemd.* Systemd_Filter _SYSTEMD_UNIT=docker.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [INPUT] Name systemd Tag kubelet.systemd.* Systemd_Filter _SYSTEMD_UNIT=kubelet.service DB /var/fluent-bit/state/systemd.db Path /var/log/journal Read_From_Head ${READ_FROM_HEAD} [FILTER] Name modify Match dockerlog.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [FILTER] Name modify Match kubelet.systemd.* Rename _HOSTNAME hostname Rename _SYSTEMD_UNIT systemd_unit Rename MESSAGE message Remove_regex ^((?!hostname|systemd_unit|message).)*$ [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_docker log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight [OUTPUT] Name cloudwatch Match kubelet.systemd.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_kubelet log_stream_name ${HOST_NODE_NAME}_$(tag[2]) auto_create_group true extra_user_agent container-insight # messages等、OSのログ定義 host-log.conf: | [INPUT] Name tail Tag host.messages Path /var/log/messages Parser syslog DB /var/fluent-bit/state/flb_messages.db Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 Read_from_Head ${READ_FROM_HEAD} # host.confの[OUTPUT]定義は、複数のINPUTがあっても1つでよい。 # $(tag[1]) にはこの場合messagesが入る。 [OUTPUT] Name cloudwatch Match host.* region ${AWS_REGION} log_group_name /eks/${ENVIRONMENT}/${NODEGROUP}_$(tag[1]) log_stream_name ${HOST_NODE_NAME}_$(tag[1]) auto_create_group true extra_user_agent container-insights Retry _Limit 5 parsers.conf: | [PARSER] Name docker Format json Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name syslog-rfc5424 Format regex Regex ^(?\u0026lt;time\u0026gt;[^ ]* {1.2}[^ ]* [^ ]*) (?\u0026lt;host\u0026gt;[^ ]*) (?\u0026lt;ident\u0026gt;[a-zA-Z0-9_¥/¥.¥-]*) (?:¥[?\u0026lt;pid\u0026gt;[-0-9]+)¥])?(?:[^¥:]*¥:)? * (?\u0026lt;message\u0026gt;.*)$ Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%L Time_Strict Off [PARSER] Name container_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\S(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ [PARSER] Name cwagent_firstline Format regex Regex (?\u0026lt;log\u0026gt;(?\u0026lt;=\u0026#34;log\u0026#34;:\u0026#34;)\\d{4}[\\/-]\\d{1,2}[\\/-]\\d{1,2}[ T]\\d{2}:\\d{2}:\\d{2}(?!\\.).*?)(?\u0026lt;!\\\\)\u0026#34;.*(?\u0026lt;stream\u0026gt;(?\u0026lt;=\u0026#34;stream\u0026#34;:\u0026#34;).*?)\u0026#34;.*(?\u0026lt;time\u0026gt;\\d{4}-\\d{1,2}-\\d{1,2}T\\d{2}:\\d{2}:\\d{2}\\.\\w*).*(?=}) Time_Key time Time_Format %Y-%m-%dT%H:%M:%S.%LZ --- apiVersion: apps/v1 kind: DaemonSet metadata: name: fluent-bit-sample namespace: amazon-cloudwatch labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: selector: matchLabels: k8s-app: fluent-bit-sample template: metadata: labels: k8s-app: fluent-bit-sample version: v1 kubernetes.io/cluster-service: \u0026#34;true\u0026#34; spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-NODELABEL-APP-001 containers: - name: fluent-bit-sample image: amazon/aws-for-fluent-bit:2.12.0 imagePullPolicy: Always env: - name: AWS_REGION valueFrom: configMapKeyRef: name: fluentbit-cluster key: logs.region - name: CLUSTER_NAME valueFrom: configMapKeyRef: name: fluentbit-cluster key: cluster.name - name: READ_FROM_HEAD valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.head - name: READ_FROM_TAIL valueFrom: configMapKeyRef: name: fluentbit-cluster key: read.tail - name: HOST_NODE_NAME valueFrom: fieldRef: fieldPath: spec.nodeName - name: CI_VERSION value: \u0026#34;k8s/1.3.8\u0026#34; # これ以降独自に設定追加。設定項目はユースケースに合わせてください。 - name: ENVIRONMENT value: \u0026#34;stg\u0026#34; - name: NODEGROUP value: \u0026#34;sample-app\u0026#34; - name: MASTER_URL value: \u0026#34;https://kubernetes.default.svc:443\u0026#34; resources: limits: cpu: 200m memory: 200Mi requests: cpu: 200m memory: 100Mi volumeMounts: # Please don\u0026#39;t change below read-only permissions - name: fluentbitstate mountPath: /var/fluent-bit/state - name: varlog mountPath: /var/log readOnly: true - name: varlibdockercontainers mountPath: /var/lib/docker/containers readOnly: true - name: fluent-bit-config mountPath: /fluent-bit/etc/ - name: runlogjournal mountPath: /run/log/journal readOnly: true - name: dmesg mountPath: /var/log/dmesg readOnly: true terminationGracePeriodSeconds: 90 volumes: - name: fluentbitstate hostPath: path: /var/fluent-bit/state - name: varlog hostPath: path: /var/log - name: varlibdockercontainers hostPath: path: /var/lib/docker/containers - name: fluent-bit-config configMap: name: fluent-bit-config - name: runlogjournal hostPath: path: /run/log/journal - name: dmesg hostPath: path: /var/log/dmesg serviceAccountName: fluent-bit tolerations: - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoExecute\u0026#34; - operator: \u0026#34;Exists\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; 補足説明 imageパスの指定\n上記ではコンテナイメージをインターネットを通って都度落とすようになっているが、業務利用時はECRに格納してプライベートな通信で完結させるのが望ましい。ECRに格納した場合は以下のように指定する。\nimage: [AWS-AccoundID].dkr.ecr.ap-northeast-1.amazon.com/[repo-name]:2.12.0 nodeAffinityで起動するノードを指定\n今回の事例では、sample-appのPodが起動するワーカーノード上にsample-appログ送信用のDaemonSetを起動させる必要がある。そのためnodeAffinityを定義する。EKSノードグループのラベルにkey:nodelabel values:STG-SAMPLE-APPを設定している前提の場合以下の様になる。sample-app用のマニフェストにも同様の記述をする。\nspec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: nodelabel operator: In values: - STG-SAMPLE-APP 停止時のGracePeriod\nDaemonSetがKillシグナル受信後に削除されるまでの猶予時間を指定。公式サンプル10秒だと、コンテナログを送信しきる前に削除されてしまう可能性がある。ここでは余裕を持たせて90秒。\nterminationGracePeriodSeconds: 90 syslogのPARSER\nAWS公式の設定だとTime_FormatがダメらしきエラーがでるのでFluent Bit公式の例を適用した。Fluent Bit公式ではsyslogではなくsyslog-rfc5424。ではINPUTのParserはsyslogではなくsyslog-rfc5424とするのが正ではないか？と思ったが、そうすると動作しない。謎だが深追いはしない。Time_StrictはOffにしておく。しかしそれでもまだエラーになるので調べると、Regexの正規表現が原因らしいのでそこも直した。参照サイトは失念。\nDaemonSetの起動〜ログ送信\n今回cloudwatch-agentについては触れていないが、cloudwatch-agentネームスペースが存在している状態でマニフェストをapplyする。この時点ではノードグループは停止中でもよい。\n$ kubectl apply -f fluentbit-cluster.yaml $ kubectl apply -f fluentbit-sample-app.yaml ノードグループが起動すると、各種ログがCloudWatchLogsに送信される。アプリ用マニフェストをapplyすればアプリログも送信される。\nあとresourceのcpuはデフォルトが500mになっていたが、そこまで割り当てなくてもちゃんと動作する。よほどのことがなければ100mでもいい気がする。メモリもFlunetdに比べて全然余裕。さすが軽量版。その他細かいチューニング項目もあるにはあるのだが、これ以上の長文は避けたいのでまた別の機会に投稿しようと思う。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/fluentbit-eks-setting/","summary":"\u003cp\u003eAWS EKSでPodからログを送信する場合、Container Insightsを組み込んでFluentdかFluent Bitを利用するのが一般的と思われる。そしてFluent BitよりFluentdの方がメジャーなのでまずはそこから入る事例が多いと想像する。\u003c/p\u003e","title":"EKS Container InsightsのFluent Bit設定"},{"content":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\nMarkdown 早見表 \u0026amp; 詳細\nかんたんMarkdownの記法\nMarkdown記法 チートシート\nGitHub Markdownの「シンタックスハイライト」に対応している言語一覧\n","permalink":"https://ecnedaced-seirots.github.io/post/a/markdown/","summary":"マークダウン記法の参考リンク。取り急ぎこれくらいあればいいかな。\nMarkdown 早見表 \u0026amp; 詳細\nかんたんMarkdownの記法\nMarkdown記法 チートシート\nGitHub Markdownの「シンタックスハイライト」に対応している言語一覧","title":"マークダウン記法"},{"content":"とりあえず最初の投稿。\n","permalink":"https://ecnedaced-seirots.github.io/post/a/first/","summary":"とりあえず最初の投稿。","title":"最初の投稿"}]